import { z as z$1 } from 'zod';

var _=z$1.object({apiKey:z$1.string().min(1),deploymentId:z$1.string().min(1),resourceName:z$1.string().min(1).optional(),baseUrl:z$1.string().optional()});var fa=e=>{let t=new WeakSet;return JSON.stringify(e,(o,s)=>{if(typeof s=="object"&&s!==null){if(t.has(s))return;t.add(s);}return s})},_a=e=>e==null?"unknown error":typeof e=="string"?e:e instanceof Error?e.message:fa(e),Ce="GatewayBaseError",$=class lt extends Error{constructor({info:t,cause:o},s){super(`[${s!=null?s:Ce}]: ${t}
Message: ${_a(o)}`),this.name=Ce,this.info=t,this.cause=o,this.name=s!=null?s:Ce,Object.setPrototypeOf(this,new.target.prototype);}static isGatewayBaseError(t){return t instanceof lt}toJSON(){return {name:this.name,info:this.info,cause:this.cause,message:this.message,stack:this.stack}}},ee="system",H="user",C="assistant",te="tool",ba=[ee,H,C,te],we=z$1.enum(ba),ya=[C],Ta=z$1.enum(ya),F="image",Ie="base64",Oa=["png","jpeg","webp","gif"],va=z$1.object({type:z$1.literal(Ie),base64:z$1.string(),media_type:z$1.enum(Oa)}),ke="url",Pa=z$1.object({type:z$1.literal(ke),url:z$1.string()}),xa=z$1.discriminatedUnion("type",[va,Pa]),Sa=["low","medium","high","auto"],Ma=z$1.enum(Sa),Ea=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(F),detail:Ma,value:xa,metadata:e}),v="text",mt=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(v),value:z$1.string(),metadata:e}),Ge="partial-text",dt=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(Ge),value:z$1.string(),metadata:e}),w="tool-call",pt=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(w),index:z$1.number().int().nonnegative(),id:z$1.string().min(1),name:z$1.string().min(1),arguments:z$1.string(),metadata:e}),je="partial-tool-call",ct=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(je),index:z$1.number().int().nonnegative(),id:z$1.string().optional(),name:z$1.string().optional(),arguments:z$1.string().optional(),metadata:e}),R="tool-response",Ca=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(R),index:z$1.number().int().nonnegative(),id:z$1.string().min(1),name:z$1.string().min(1),data:z$1.string(),metadata:e}),wa=[v,F,w,R],ut=z$1.enum(wa),Ia=(e=z$1.undefined(),t=z$1.undefined(),o=z$1.undefined(),s=z$1.undefined())=>z$1.discriminatedUnion("modality",[mt(e),Ea(t),pt(o),Ca(s)]),ka=[Ge,je];z$1.enum(ka);var Ga=(e=z$1.undefined(),t=z$1.undefined())=>z$1.discriminatedUnion("modality",[dt(e),ct(t)]);var Ae=(e=we,t=z$1.undefined(),o=z$1.undefined(),s=z$1.undefined(),i=z$1.undefined(),m=z$1.undefined())=>z$1.object({role:e,content:z$1.array(Ia(t,o,s,i)),metadata:m}),Re=(e=Ta,t=z$1.undefined(),o=z$1.undefined(),s=z$1.undefined())=>z$1.object({role:e,partialContent:Ga(t,o),metadata:s}),Le=e=>mt().parse({modality:v,value:e}),ht=(e,t,o,s)=>pt().parse({modality:w,index:e,id:t,name:o,arguments:s});var Be=(e,t)=>Re().parse({role:e,partialContent:dt().parse({modality:Ge,value:t})}),gt=(e,t,o,s,i)=>Re().parse({role:e,partialContent:ct().parse({modality:je,index:t,id:o,name:s,arguments:i})});var Ne=(e=z$1.record(z$1.string(),z$1.any()).optional())=>e,ja=["object","array","number","string","boolean","enum"],st=z$1.enum(ja),Aa=z$1.object({anyOf:z$1.array(z$1.any()).optional(),type:z$1.union([st,z$1.array(z$1.union([st,z$1.literal("null")]))]).optional(),default:z$1.any().optional(),title:z$1.string().optional(),description:z$1.string().max(4096).optional(),properties:z$1.record(z$1.any()).optional(),required:z$1.array(z$1.string()).optional(),minItems:z$1.number().int().min(0).optional(),maxItems:z$1.number().int().optional(),items:z$1.record(z$1.any()).optional(),enum:z$1.array(z$1.union([z$1.string(),z$1.number(),z$1.boolean(),z$1.null()])).optional(),minimum:z$1.number().optional(),maximum:z$1.number().optional(),minLength:z$1.number().int().min(0).optional(),maxLength:z$1.number().int().optional(),$ref:z$1.string().optional()}),Ra=z$1.object({type:z$1.enum(["object"]),required:z$1.array(z$1.string()),$defs:z$1.record(z$1.any()).optional(),properties:z$1.record(Aa),additionalProperties:z$1.literal(!1)}),ft=z$1.object({name:z$1.string().regex(/^[a-zA-Z0-9_]{1,64}$/).max(64),description:z$1.string().max(4096),strict:z$1.boolean().optional(),schema:Ra}).optional(),La="function";var Ba=z$1.enum(["object","array","number","string","boolean","null"]),Na=z$1.object({anyOf:z$1.array(z$1.any()).optional(),type:Ba.optional(),default:z$1.any().optional(),title:z$1.string().optional(),description:z$1.string().max(4096).optional(),properties:z$1.record(z$1.any()).optional(),required:z$1.array(z$1.string()).optional(),minItems:z$1.number().int().min(0).optional(),maxItems:z$1.number().int().optional(),items:z$1.record(z$1.any()).optional(),enum:z$1.array(z$1.union([z$1.string(),z$1.number(),z$1.boolean(),z$1.null()])).optional(),minimum:z$1.number().optional(),maximum:z$1.number().optional(),minLength:z$1.number().int().min(0).optional(),maxLength:z$1.number().int().optional()});z$1.object({type:z$1.enum(["object"]),title:z$1.string().optional(),$defs:z$1.record(z$1.any()).optional(),properties:z$1.record(Na).optional(),required:z$1.array(z$1.string()).optional()});var $a=z$1.object({name:z$1.string().regex(/^[a-zA-Z0-9_]{1,64}$/).max(64),description:z$1.string().max(4096),parameters:z$1.any(),strict:z$1.boolean().optional()});var Ua=z$1.enum(["function"]),qa=z$1.object({type:Ua,definition:z$1.object({schema:$a})}),Fa=[La];z$1.enum(Fa);var _t=(e=z$1.undefined())=>z$1.discriminatedUnion("type",[qa.extend({metadata:e})]),z="text",J="token",za=[z,J],bt=z$1.enum(za),Da=z$1.array(z$1.string().min(1)),Ka=z$1.array(z$1.array(z$1.number().int().nonnegative())),yt=(e=z$1.undefined())=>z$1.discriminatedUnion("modality",[z$1.object({modality:z$1.literal(z),metadata:e,requests:Da}),z$1.object({modality:z$1.literal(J),metadata:e,requests:Ka})]),$e="float",Ha=z$1.object({index:z$1.number().int().nonnegative(),embedding:z$1.array(z$1.number())}),Ue="base64",Va=z$1.object({index:z$1.number().int().nonnegative(),embedding:z$1.string().base64()}),it=z$1.object({totalTokens:z$1.number().int().nonnegative()});z$1.discriminatedUnion("encodingFormat",[z$1.object({encodingFormat:z$1.literal($e),embeddings:z$1.array(Ha),usage:it.optional()}),z$1.object({encodingFormat:z$1.literal(Ue),embeddings:z$1.array(Va),usage:it.optional()})]);var Tt=z$1.object({promptTokens:z$1.number().nonnegative(),completionTokens:z$1.number().nonnegative(),totalTokens:z$1.number().nonnegative()}),rt=z$1.object({token:z$1.string(),logProb:z$1.number(),bytes:z$1.array(z$1.number().int()).nullable()}),Ja=rt.extend({topLogProbs:z$1.array(rt)}),Ot=z$1.array(Ja);z$1.object({messages:z$1.array(Ae()),usage:Tt.optional(),logProbs:Ot.optional()});z$1.object({partialMessages:z$1.array(Re()),usage:Tt.optional(),logProbs:Ot.optional()});var Wa=Object.defineProperty,vt=Object.getOwnPropertySymbols,Ya=Object.prototype.hasOwnProperty,Qa=Object.prototype.propertyIsEnumerable,Pt=(e,t,o)=>t in e?Wa(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,oe=(e,t)=>{for(var o in t||(t={}))Ya.call(t,o)&&Pt(e,o,t[o]);if(vt)for(var o of vt(t))Qa.call(t,o)&&Pt(e,o,t[o]);return e},xt="ProviderError",qe=class Gt extends ${constructor({info:t,cause:o}){super({info:t,cause:o},xt),this.name=xt,this.info=t,this.cause=o;}static isProviderError(t){return t instanceof Gt}},St="ModelError",L=class jt extends ${constructor({info:t,cause:o}){super({info:t,cause:o},St),this.name=St,this.info=t,this.cause=o;}static isModelError(t){return t instanceof jt}},Mt="ModelResponseError",W=class At extends ${constructor({info:t,cause:o}){super({info:t,cause:o},Mt),this.name=Mt,this.cause=o,this.info=t;}static isModelResponseError(t){return t instanceof At}},Et="InvalidModelRequestError",Y=class Rt extends ${constructor({info:t,cause:o}){super({info:t,cause:o},Et),this.name=Et,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidModelRequestError(t){return t instanceof Rt}},Ct="InvalidConfigError",U=class Lt extends ${constructor({info:t,cause:o}){super({info:t,cause:o},Ct),this.name=Ct,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidConfigError(t){return t instanceof Lt}},wt="InvalidMessagesError",I=class Bt extends ${constructor({info:t,cause:o}){super({info:t,cause:o},wt),this.name=wt,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidMessagesError(t){return t instanceof Bt}},It="InvalidToolsError",Fe=class Nt extends ${constructor({info:t,cause:o}){super({info:t,cause:o},It),this.name=It,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidToolsError(t){return t instanceof Nt}},kt="InvalidEmbeddingRequestsError",$t=class Ut extends ${constructor({info:t,cause:o}){super({info:t,cause:o},kt),this.name=kt,this.info=t,this.cause=o,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidEmbeddingRequestsError(t){return t instanceof Ut}},ze="multi-string",qt=z$1.object({type:z$1.literal(ze),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),max:z$1.number().int().positive()}),Za=e=>z$1.array(z$1.string()).max(e).default([]).optional(),Ft=e=>({def:qt.parse(oe({type:ze},e)),schema:Za(e.max)}),De="object-schema",zt=z$1.object({type:z$1.literal(De),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),objectSchema:z$1.any()}),Xa=e=>e.optional(),Dt=e=>({def:zt.parse(oe({type:De},e)),schema:Xa(e.objectSchema)}),Ke="range",Kt=z$1.object({type:z$1.literal(Ke),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),min:z$1.number().int(),max:z$1.number().int(),step:z$1.number().positive(),default:z$1.number()}),en=(e,t,o,s)=>z$1.number().min(e).max(t).step(o).default(s).optional(),G=e=>({def:Kt.parse(oe({type:Ke},e)),schema:en(e.min,e.max,e.step,e.default)}),He="select-boolean",Ht=z$1.object({type:z$1.literal(He),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),default:z$1.boolean().nullable()}),tn=e=>z$1.boolean().nullable().default(e).optional(),Vt=e=>({def:Ht.parse(oe({type:He},e)),schema:tn(e.default)}),Ve="select-string",Jt=z$1.object({type:z$1.literal(Ve),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),default:z$1.string().min(1).nullable(),choices:z$1.array(z$1.string().min(1))}),on=(e,t)=>z$1.enum(t).nullable().default(e).optional(),ae=e=>({def:Jt.parse(oe({type:Ve},e)),schema:on(e.default,e.choices)}),an=[Ke,ze,Ve,De,He];z$1.enum(an);var Wt=z$1.discriminatedUnion("type",[Kt,qt,Jt,Ht,zt]),T=(e=we,t=ut)=>z$1.object({name:z$1.string().min(1),description:z$1.string().min(1),roles:z$1.record(e,z$1.string().min(1).optional()),modalities:z$1.array(t).nonempty(),maxInputTokens:z$1.number().int().positive().min(1),maxOutputTokens:z$1.number().int().positive().min(1),config:z$1.object({def:z$1.record(z$1.string().min(1),Wt),schema:z$1.instanceof(z$1.ZodObject)}).refine(o=>{var s,i;let m=Object.keys(o.def),r=Object.keys((i=(s=o.schema)==null?void 0:s.shape)!=null?i:{});return m.every(d=>r.includes(d))&&r.every(d=>m.includes(d))},{message:"Keys in 'config.def' must exactly match keys in 'config.schema'"})}),Q=(e=bt)=>z$1.object({name:z$1.string().min(1),description:z$1.string().min(1),modalities:z$1.array(e).nonempty(),maxInputTokens:z$1.number().int().positive().min(1),maxOutputTokens:z$1.number().int().positive().min(1),config:z$1.object({def:z$1.record(z$1.string().min(1),Wt),schema:z$1.instanceof(z$1.ZodObject)}).refine(t=>{var o,s;let i=Object.keys(t.def),m=Object.keys((s=(o=t.schema)==null?void 0:o.shape)!=null?s:{});return i.every(r=>m.includes(r))&&m.every(r=>i.includes(r))},{message:"Keys in 'config.def' must exactly match keys in 'config.schema'"})});z$1.record(z$1.string());z$1.record(z$1.union([z$1.boolean(),z$1.string(),z$1.number(),z$1.object({}),z$1.array(z$1.any()),z$1.null(),z$1.undefined()]));z$1.string().url();var nn={type:"range",title:"Temperature",description:"Adjusts the model's creativity level. With a setting of 0, the model strictly picks the most probable next word.     For endeavors that benefit from a dash of inventiveness, consider dialing it up to 0.7 or higher, enabling the model to produce text     that's unexpectedly fresh."},sn={type:"range",title:"Max tokens",description:"Specify the total tokens for generation, where one token approximates four English characters.     Setting this to 0 defaults to the model's maximum capacity."},rn=e=>({type:"multi",title:"Stop sequence",description:`Enter up to ${e} sequences that will halt additional text output.       The generated text will exclude these sequences.`}),ln={type:"range",title:"Top A",description:"Considers only the top tokens that have 'sufficiently high' probabilities relative to the most likely token,     functioning like a dynamic Top-P.     A lower Top-A value narrows down the token choices based on the highest probability token,     while a higher Top-A value refines the filtering without necessarily impacting the creativity of the output."},mn={type:"range",title:"Top P",description:"Selects a subset of likely tokens for generation, restricting choices to the top-P fraction of possibilities,     such as the top 10% when P=0.1.     This approach can limit the variety of the output. By default, it's set to 1, indicating no restriction.     It's advised to adjust this parameter or temperature to modulate output diversity, but not to modify both simultaneously."},dn={type:"range",title:"Top K",description:"Select only from the highest K probabilities for each following word, effectively eliminating the less likely 'long tail' options."},pn={type:"range",title:"Min P",description:"Specifies the minimum probability a token must have to be considered, in relation to the probability of the most likely token.     (This value varies based on the confidence level of the top token.)     For example, if Min-P is set to 0.1, only tokens with at least 1/10th the probability of the highest-ranked token will be considered."},cn={type:"range",title:"Frequency penalty",description:"Minimize redundancy.    By assigning a penalty to frequently used tokens within the text, the likelihood of repeating identical phrases is reduced.     The default setting for this penalty is zero."},un={type:"range",title:"Presence penalty",description:"Enhance the introduction of novel subjects by reducing the preference for tokens that have already appeared in the text,     thus boosting the chances of exploring fresh topics.     The standard setting for this is zero."},hn={type:"range",title:"Seed",description:"When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests.     Deterministic output isn't guaranteed.     Also, changing the model or parameter settings, such as the temperature,     can cause variations in the response even when you use the same seed value.     By default, a random seed value is used."},gn={type:"range",title:"Repetition penalty",description:"Reduces the likelihood of repeating tokens from the input.     Increasing this value makes the model less prone to repetition, but setting it too high may lead to less coherent output,     often resulting in run-on sentences missing smaller words.     The token penalty is scaled according to the original token's probability."},fn={type:"boolean",title:"Log probs",description:"Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned."},_n={type:"range",title:"Top log probs",description:"The number of most likely tokens to return at each token position, each with an associated log probability.     'logprobs' must be set to true if this parameter is used."},bn={type:"boolean",title:"Echo",description:"If true, the response will contain the prompt."},yn={type:"select",title:"Response format",description:"Choose the response format of your model. For JSON, you must include the string 'JSON' in some form within your system / user prompt."},Tn={type:"select",title:"Response format",description:"Choose the response format of your model. 'json_object' colloquially known as JSON mode, instructs the model to respond with a valid   JSON (must include the term 'json' in prompt). 'json_schema' colloquially known as structured outputs, allows you to specify a strict   response schema that the model will adhere to."},On={type:"object",title:"Response schema",description:"When response format is set to 'json_schema', the model will return a JSON object of the specified schema."},f={TEMPERATURE:nn,MAX_TOKENS:sn,STOP:rn,TOP_A:ln,TOP_P:mn,TOP_K:dn,MIN_P:pn,FREQUENCY_PENALTY:cn,PRESENCE_PENALTY:un,REPETITION_PENALTY:gn,SEED:hn,LOG_PROBS:fn,TOP_LOG_PROBS:_n,ECHO:bn,RESPONSE_FORMAT:yn,RESPONSE_FORMAT_WITH_SCHEMA:Tn,RESPONSE_SCHEMA:On};var Je=e=>Object.fromEntries(Object.entries(e).filter(([t,o])=>o!=null));var Yt=e=>e.split(";")[0].split("/")[1],Z=e=>e==null?void 0:e.replace(/\/$/,"");var vn=Object.defineProperty,Pn=Object.defineProperties,xn=Object.getOwnPropertyDescriptors,Qt=Object.getOwnPropertySymbols,Sn=Object.prototype.hasOwnProperty,Mn=Object.prototype.propertyIsEnumerable,En=(e,t)=>(t=Symbol[e])?t:Symbol.for("Symbol."+e),Zt=(e,t,o)=>t in e?vn(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,M=(e,t)=>{for(var o in t||(t={}))Sn.call(t,o)&&Zt(e,o,t[o]);if(Qt)for(var o of Qt(t))Mn.call(t,o)&&Zt(e,o,t[o]);return e},ne=(e,t)=>Pn(e,xn(t)),k=(e,t,o)=>new Promise((s,i)=>{var m=c=>{try{d(o.next(c));}catch(p){i(p);}},r=c=>{try{d(o.throw(c));}catch(p){i(p);}},d=c=>c.done?s(c.value):Promise.resolve(c.value).then(m,r);d((o=o.apply(e,t)).next());}),Cn=function(e,t){this[0]=e,this[1]=t;},Xt=(e,t,o)=>{var s=(r,d,c,p)=>{try{var h=o[r](d),g=(d=h.value)instanceof Cn,E=h.done;Promise.resolve(g?d[0]:d).then(y=>g?s(r==="return"?r:"next",d[1]?{done:y.done,value:y.value}:y,c,p):c({value:y,done:E})).catch(y=>s("throw",y,c,p));}catch(y){p(y);}},i=r=>m[r]=d=>new Promise((c,p)=>s(r,d,c,p)),m={};return o=o.apply(e,t),m[En("asyncIterator")]=()=>m,i("next"),i("throw"),i("return"),m},eo=G({param:"temperature",title:f.TEMPERATURE.title,description:f.TEMPERATURE.description,min:0,max:2,step:.01,default:1}),to=e=>G({param:"max_tokens",title:f.MAX_TOKENS.title,description:f.MAX_TOKENS.description,min:0,max:e,step:1,default:0}),oo=e=>Ft({param:"stop",title:f.STOP(e).title,description:f.STOP(e).description,max:e}),ao=G({param:"top_p",title:f.TOP_P.title,description:f.TOP_P.description,min:0,max:1,step:.01,default:1}),no=G({param:"frequency_penalty",title:f.FREQUENCY_PENALTY.title,description:f.FREQUENCY_PENALTY.description,min:-2,max:2,step:.01,default:0}),so=G({param:"presence_penalty",title:f.PRESENCE_PENALTY.title,description:f.PRESENCE_PENALTY.description,min:-2,max:2,step:.01,default:0}),io=G({param:"seed",title:f.SEED.title,description:f.SEED.description,min:0,max:1e6,step:1,default:0}),ro=Vt({param:"logprobs",title:f.LOG_PROBS.title,description:f.LOG_PROBS.description,default:!1}),lo=G({param:"top_logprobs",title:f.TOP_LOG_PROBS.title,description:f.TOP_LOG_PROBS.description,min:0,max:20,step:1,default:0}),mo=ae({param:"tool_choice",title:"Tool choice",description:"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.",default:"auto",choices:["auto","required","none"]}),We=(e,t)=>z$1.object({temperature:eo.schema,maxTokens:to(e).schema,stop:oo(t).schema,topP:ao.schema,frequencyPenalty:no.schema,presencePenalty:so.schema,seed:io.schema.transform(o=>o===0?void 0:o),logProbs:ro.schema,topLogProbs:lo.schema,toolChoice:mo.schema}),Ye=(e,t)=>({temperature:eo.def,maxTokens:to(e).def,stop:oo(t).def,topP:ao.def,frequencyPenalty:no.def,presencePenalty:so.def,seed:io.def,logProbs:ro.def,topLogProbs:lo.def,toolChoice:mo.def}),po=Dt({param:"response_schema",title:f.RESPONSE_SCHEMA.title,description:f.RESPONSE_SCHEMA.description,objectSchema:ft}),co=ae({param:"response_format",title:f.RESPONSE_FORMAT_WITH_SCHEMA.title,description:f.RESPONSE_FORMAT_WITH_SCHEMA.description,default:"text",choices:["text","json_object","json_schema"]}),uo=(e,t)=>ne(M({},Ye(e,t)),{responseFormat:co.def,responseSchema:po.def}),ho=(e,t)=>We(e,t).extend({responseFormat:co.schema,responseSchema:po.schema}),go=G({param:"temperature",title:f.TEMPERATURE.title,description:f.TEMPERATURE.description,min:1,max:1,step:.01,default:1}),fo=e=>G({param:"max_completion_tokens",title:f.MAX_TOKENS.title,description:f.MAX_TOKENS.description,min:0,max:e,step:1,default:0}),wn=(e,t)=>ne(M({},uo(e,t)),{temperature:go.def,maxTokens:fo(e).def}),In=(e,t)=>ho(e,t).extend({temperature:go.schema,maxTokens:fo(e).schema}),_o=ae({param:"response_format",title:f.RESPONSE_FORMAT.title,description:f.RESPONSE_FORMAT.description,default:"text",choices:["text","json_object"]}),kn=(e,t)=>ne(M({},Ye(e,t)),{responseFormat:_o.def}),Gn=(e,t)=>We(e,t).extend({responseFormat:_o.schema}),bo=ae({param:"encoding_format",title:"Encoding format",description:"Select the encoding format for the word embedding.",default:"float",choices:["float","base64"]}),yo=e=>G({param:"dimensions",title:"Dimensions",description:"Select the number of dimensions for the word embedding.",min:1,max:e,step:1,default:e}),To=()=>z$1.object({encodingFormat:bo.schema}),Oo=()=>({encodingFormat:bo.def}),jn=e=>To().extend({dimensions:yo(e).schema}),An=e=>ne(M({},Oo()),{dimensions:yo(e).def}),u={base:(e,t)=>({def:Ye(e,t),schema:We(e,t)}),responseFormat:(e,t)=>({def:kn(e,t),schema:Gn(e,t)}),responseSchema:(e,t)=>({def:uo(e,t),schema:ho(e,t)}),oSeries:(e,t)=>({def:wn(e,t),schema:In(e,t)})},q={base:()=>({def:Oo(),schema:To()}),dimensions:e=>({def:An(e),schema:jn(e)})},P=z$1.enum([ee,H,C,te]),x={system:ee,user:H,assistant:C,tool:te},Qe=z$1.enum([H,C]),Ze={user:H,assistant:C},j=[v,F,w,R],A=z$1.enum([v,F,w,R]),Xe=[v],et=z$1.enum([v]),D=[v,w,R],K=z$1.enum([v,w,R]),me=z$1.object({token:z$1.string(),logprob:z$1.number(),bytes:z$1.array(z$1.number()).nullable()}),vo=z$1.object({content:z$1.array(me.extend({top_logprobs:z$1.array(me)})).nullable().optional(),refusal:z$1.array(me.extend({top_logprobs:z$1.array(me)})).nullable().optional()}).nullable(),Rn=z$1.array(z$1.object({id:z$1.string().min(1),type:z$1.enum(["function"]),function:z$1.object({name:z$1.string(),arguments:z$1.string()})})),Ln=z$1.object({id:z$1.string(),object:z$1.literal("chat.completion"),created:z$1.number(),model:z$1.string(),system_fingerprint:z$1.string().nullable(),choices:z$1.array(z$1.object({index:z$1.number(),message:z$1.object({role:z$1.string(),content:z$1.string().nullable().optional(),tool_calls:Rn.optional(),refusal:z$1.string().nullable().optional()}),logprobs:vo.optional(),finish_reason:z$1.string()})),usage:z$1.object({prompt_tokens:z$1.number(),completion_tokens:z$1.number(),total_tokens:z$1.number()})}),Bn=z$1.array(z$1.object({index:z$1.number().int(),id:z$1.string().min(1).optional(),type:z$1.enum(["function"]).optional(),function:z$1.object({name:z$1.string().min(1).optional(),arguments:z$1.string().optional()}).optional()})),Nn=z$1.object({id:z$1.string(),object:z$1.string(),created:z$1.number(),model:z$1.string(),system_fingerprint:z$1.string().nullable(),choices:z$1.array(z$1.object({index:z$1.number(),delta:z$1.object({content:z$1.string().nullable().optional(),tool_calls:Bn.optional(),refusal:z$1.string().nullable().optional()}).or(z$1.object({})),logprobs:vo,finish_reason:z$1.string().nullable()})),usage:z$1.object({prompt_tokens:z$1.number(),completion_tokens:z$1.number(),total_tokens:z$1.number()}).nullable().optional()}),$n=z$1.object({type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1),description:z$1.string().min(1).optional(),strict:z$1.boolean().optional(),parameters:z$1.any()})}),Un=z$1.enum(["none","auto","required"]),qn=z$1.object({type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1)})}),Fn=z$1.object({type:z$1.enum(["text","json_object"])}).or(z$1.object({type:z$1.literal("json_schema"),json_schema:z$1.object({name:z$1.string().min(1),description:z$1.string().min(1).optional(),strict:z$1.boolean().optional(),schema:z$1.any()})})),tt=z$1.object({text:z$1.string().min(1),type:z$1.literal("text")}),zn=z$1.object({type:z$1.literal("image_url"),image_url:z$1.object({url:z$1.string().url().min(1),detail:z$1.enum(["low","high","auto"]).optional()})}),Dn=z$1.object({id:z$1.string().min(1),type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1),arguments:z$1.string().min(1)})}),Kn=z$1.object({role:z$1.literal("system"),content:z$1.string().min(1).or(z$1.array(tt).min(1))}),Hn=z$1.object({role:z$1.literal("user"),content:z$1.string().min(1).or(z$1.array(z$1.union([tt,zn])).min(1))}),Vn=z$1.object({role:z$1.literal("assistant"),content:z$1.string().min(1).or(z$1.array(tt).min(1)).optional(),tool_calls:z$1.array(Dn).min(1).optional()}),Jn=z$1.object({role:z$1.literal("tool"),tool_call_id:z$1.string().min(1),content:z$1.string().min(1)}),Wn=z$1.union([Kn,Hn,Vn,Jn]),Po=z$1.object({model:z$1.string().min(1).optional(),messages:z$1.array(Wn).min(1),frequency_penalty:z$1.number().min(-2).max(2).nullable().optional(),logprobs:z$1.boolean().nullable().optional(),top_logprobs:z$1.number().min(0).max(20).nullable().optional(),max_tokens:z$1.number().min(0).nullable().optional(),presence_penalty:z$1.number().min(-2).max(2).nullable().optional(),response_format:Fn.optional(),seed:z$1.number().nullable().optional(),stop:z$1.string().or(z$1.array(z$1.string()).max(4)).nullable().optional(),temperature:z$1.number().min(0).max(2).nullable().optional(),top_p:z$1.number().min(0).max(1).nullable().optional(),tools:z$1.array($n).optional(),tool_choice:Un.or(qn).optional()}),Yn=Po.omit({max_tokens:!0}).extend({max_completion_tokens:z$1.number().min(0).nullable().optional()}),Qn="openai",ot=class{constructor(){this.version="v1",this.name=Qn,this.chatModelFactories={[Mo]:{model:is,modelOptions:ss,modelSchema:ue},[xo]:{model:es,modelOptions:Xn,modelSchema:pe},[So]:{model:as,modelOptions:os,modelSchema:ce},[Eo]:{model:ms,modelOptions:ls,modelSchema:Co},[wo]:{model:cs,modelOptions:ps,modelSchema:he},[Io]:{model:gs,modelOptions:hs,modelSchema:ge},[ko]:{model:bs,modelOptions:_s,modelSchema:fe},[Go]:{model:Os,modelOptions:Ts,modelSchema:jo},[Ao]:{model:xs,modelOptions:Ps,modelSchema:Ro},[Lo]:{model:Es,modelOptions:Ms,modelSchema:_e},[No]:{model:js,modelOptions:Gs,modelSchema:ye},[Uo]:{model:$s,modelOptions:Ns,modelSchema:Oe},[qo]:{model:Fs,modelOptions:qs,modelSchema:ve},[$o]:{model:Ls,modelOptions:Rs,modelSchema:Te},[Bo]:{model:Is,modelOptions:ws,modelSchema:be},[Ho]:{model:Qs,modelOptions:Ys,modelSchema:Vo},[Jo]:{model:ei,modelOptions:Xs,modelSchema:Wo},[Yo]:{model:ai,modelOptions:oi,modelSchema:Qo},[Fo]:{model:Ks,modelOptions:Ds,modelSchema:zo},[Do]:{model:Js,modelOptions:Vs,modelSchema:Ko}},this.embeddingModelFactories={[Zo]:{model:mi,modelOptions:li,modelSchema:xe},[Xo]:{model:ci,modelOptions:pi,modelSchema:Se},[ea]:{model:gi,modelOptions:hi,modelSchema:Me}};}chatModelLiterals(){return Object.keys(this.chatModelFactories)}chatModelSchemas(){return Object.keys(this.chatModelFactories).reduce((e,t)=>(e[t]=this.chatModelFactories[t].modelSchema,e),{})}chatModel(e){let t=e.modelName;if(!(t in this.chatModelFactories))throw new qe({info:`OpenAI chat model: ${t} not found`,cause:new Error(`OpenAI chat model: ${t} not found, available chat models: 
          [${this.chatModelLiterals().join(", ")}]`)});let o=this.chatModelFactories[t].model,s=this.chatModelFactories[t].modelOptions.parse(e);return new o(s)}embeddingModelLiterals(){return Object.keys(this.embeddingModelFactories)}embeddingModelSchemas(){return Object.keys(this.embeddingModelFactories).reduce((e,t)=>(e[t]=this.embeddingModelFactories[t].modelSchema,e),{})}embeddingModel(e){let t=e.modelName;if(!(t in this.embeddingModelFactories))throw new qe({info:`OpenAI embedding model: ${t} not found`,cause:new Error(`OpenAI embedding model: ${t} not found, available embedding models: 
          [${this.embeddingModelLiterals().join(", ")}]`)});let o=this.embeddingModelFactories[t].model,s=this.embeddingModelFactories[t].modelOptions.parse(e);return new o(s)}};ot.baseUrl="https://api.openai.com/v1";var O=z$1.object({modelName:z$1.string(),apiKey:z$1.string(),baseUrl:z$1.string().url().optional(),completeChatUrl:z$1.string().url().optional(),streamChatUrl:z$1.string().url().optional(),organization:z$1.string().optional()}),S=class{constructor(e,t){this.version="v1";let o=O.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=Z(o.baseUrl||ot.baseUrl),this.streamChatUrl=Z(o.streamChatUrl||`${this.baseUrl}/chat/completions`),this.completeChatUrl=Z(o.completeChatUrl||`${this.baseUrl}/chat/completions`),this.organization=o.organization;}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return M({Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"},this.organization?{"OpenAI-Organization":this.organization}:{})}getDefaultParams(){return {model:this.modelName}}getRetryDelay(e){let t=r=>{let d=/(\d+)(h|m|s|ms)/g,c={h:36e5,m:6e4,s:1e3,ms:1},p,h=0;for(;(p=d.exec(r))!==null;){let g=parseInt(p[1]),E=p[2];h+=g*c[E];}return h},o=0,s=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(s=t(e["x-ratelimit-reset-tokens"]));let m=Math.max(o,s);return {shouldRetry:i,delayMs:m}}getTokenCount(e){return e.reduce((t,o)=>t+o.content.map(s=>s.modality==="text"?s.value:"").join(" ").length,0)}transformModelRequest(e){let t=Po.safeParse(e);if(!t.success)throw new Y({info:"Invalid model request",cause:t.error});let o=t.data,s=o.model;if(o.tool_choice&&(!o.tools||o.tools.length===0))throw new Y({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'tool_choice' is specified")});let i={};o.response_format&&(i.responseFormat=o.response_format.type,o.response_format.type==="json_schema"&&(i.responseSchema={name:o.response_format.json_schema.name,description:o.response_format.json_schema.description||"",strict:o.response_format.json_schema.strict,schema:o.response_format.json_schema.schema})),o.tool_choice&&(typeof o.tool_choice=="string"?i.toolChoice=o.tool_choice:i.toolChoice=o.tool_choice.function.name),i.seed=o.seed,i.maxTokens=o.max_tokens,i.temperature=o.temperature,i.topP=o.top_p,i.presencePenalty=o.presence_penalty,i.frequencyPenalty=o.frequency_penalty,i.stop=o.stop,i.logProbs=o.logprobs,i.topLogProbs=o.top_logprobs;let m=Ne().parse(Je(i)),r=[],d={};o.messages.forEach(p=>{let h=p.role;switch(h){case"system":{let g=p.content;if(typeof g=="string")r.push({role:h,content:[{modality:v,value:g}]});else {let E=g.map(y=>({modality:v,value:y.text}));r.push({role:h,content:E});}}break;case"user":{let g=p.content;if(typeof g=="string")r.push({role:h,content:[{modality:v,value:g}]});else {let E=g.map(y=>y.type==="text"?{modality:v,value:y.text}:y.image_url.url.startsWith("data:")?{modality:F,detail:y.image_url.detail||"auto",value:{type:Ie,base64:y.image_url.url,media_type:Yt(y.image_url.url)}}:{modality:F,detail:y.image_url.detail||"auto",value:{type:ke,url:y.image_url.url}});r.push({role:h,content:E});}}break;case"assistant":{let g=[];if(!p.content&&!p.tool_calls)throw new Y({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("one of'content' or 'tool_calls' must be provided")});if(p.content){let E=p.content;typeof E=="string"?g.push({modality:v,value:E}):E.forEach(y=>{g.push({modality:v,value:y.text});});}p.tool_calls&&p.tool_calls.forEach((E,y)=>{let Ee={modality:w,id:E.id,index:y,name:E.function.name,arguments:E.function.arguments};g.push(Ee),d[Ee.id]=Ee;}),r.push({role:h,content:g});}break;case"tool":{let g=p;r.push({role:h,content:[{modality:R,id:g.tool_call_id,index:d[g.tool_call_id].index,name:d[g.tool_call_id].name,data:g.content}]});}break}});let c=[];return o.tools&&o.tools.forEach(p=>{c.push({type:"function",definition:{schema:{name:p.function.name,description:p.function.description||"",strict:p.function.strict,parameters:p.function.parameters}}});}),{modelName:s,config:m,messages:r,tools:c.length>0?c:void 0}}transformConfig(e,t,o){let s=e.toolChoice;delete e.toolChoice;let i=this.modelSchema.config.schema.safeParse(e);if(!i.success)throw new U({info:`Invalid config for model : '${this.modelName}'`,cause:i.error});let m=i.data;s!==void 0&&(m.toolChoice=s),Object.keys(m).forEach(d=>{if(!(d in this.modelSchema.config.def))throw new U({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`Invalid config key : '${d}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})});let r=Object.keys(m).reduce((d,c)=>{let p=this.modelSchema.config.def[c],h=p.param,g=m[c];return h==="max_tokens"&&p.type==="range"&&g===0?d[h]=p.max:d[h]=g,d},{});if(r.top_logprobs&&!r.logprobs)throw new U({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'logprobs' must be 'true' when 'top_logprobs' is specified")});if("tool_choice"in r&&r.tool_choice!==void 0){let d=r.tool_choice;if(!o||o&&o.length===0)throw new U({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'toolChoice' is specified")});if(o&&o.length>0){let c=this.modelSchema.config.def.toolChoice;if(!c.choices.includes(d))if(o.map(p=>p.definition.schema.name).includes(d))r.tool_choice={type:"function",function:{name:d}};else throw new U({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`toolChoice : '${d}' is not part of provided 'tools' names or 
                one of [${c.choices.join(", ")}]`)})}}if("response_format"in r&&r.response_format!==void 0){let d=r.response_format;if(d==="json_schema")if("response_schema"in r)r.response_format={type:"json_schema",json_schema:r.response_schema},delete r.response_schema;else throw new U({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'responseSchema' is required in config when 'responseFormat' is 'json_schema'")});else r.response_format={type:d};}return r}transformMessages(e){if(!e||e&&e.length===0)return {messages:[]};let t=e.map(o=>{let s=Ae().safeParse(o);if(!s.success)throw new I({info:"Invalid messages",cause:s.error});return s.data});return t.forEach(o=>{o.content.forEach(s=>{if(!this.modelSchema.modalities.includes(s.modality))throw new I({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support modality : '${s.modality}', 
              available modalities : [${this.modelSchema.modalities.join(", ")}]`)})});}),t.forEach(o=>{if(!Object.keys(this.modelSchema.roles).includes(o.role))throw new I({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support role : '${o.role}', 
            available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}),{messages:t.map(o=>{switch(o.role){case ee:{let s=[];return o.content.forEach(i=>{if(i.modality===v)s.push({type:"text",text:i.value});else throw new I({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' cannot have content with modality : '${i.modality}'`)})}),{role:this.modelSchema.roles[o.role],content:s}}case C:{let s=[],i=[];return o.content.forEach(m=>{if(m.modality===v)s.push({type:"text",text:m.value});else if(m.modality===w)i.push({id:m.id,type:"function",function:{name:m.name,arguments:m.arguments}});else throw new I({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' cannot have content with modality : '${m.modality}'`)})}),M({role:this.modelSchema.roles[o.role],content:s},i.length>0?{tool_calls:i}:{})}case H:{let s=[],i=[];o.content.forEach(r=>{if(r.modality===v)s.push({type:"text",text:r.value});else if(r.modality===F)i.push({type:"image_url",image_url:{url:r.value.type==="url"?r.value.url:r.value.base64,detail:r.detail}});else throw new I({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' cannot have content with modality : '${r.modality}'`)})});let m=[...s,...i];return {role:this.modelSchema.roles[o.role],content:m}}case te:{if(o.content.length!==1)throw new I({info:`Invalid message for role : '${o.role}'`,cause:new Error(`role : '${o.role}' must have exactly one content item`)});if(o.content[0].modality!==R)throw new I({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' must have content with modality : '${R}'`)});let s=o.content[0];return {role:this.modelSchema.roles[o.role],tool_call_id:s.id,content:s.data}}default:throw new I({info:`Invalid message 'role' for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' is not supported, 
              available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}})}}transformTools(e){if(!this.modelSchema.modalities.includes(w))throw new Fe({info:`Invalid tool 'modality' for model : ${this.modelName}`,cause:new Error(`model : '${this.modelName}' does not support tool modality : '${w}'`)});return !e||e&&e.length===0?{tools:[]}:{tools:e.map(t=>{let o=_t().safeParse(t);if(!o.success)throw new Fe({info:"Invalid tools",cause:o.error});return o.data}).map(t=>({type:"function",function:t.definition.schema}))}}getCompleteChatUrl(e,t,o){return k(this,null,function*(){return new Promise(s=>{s(this.completeChatUrl);})})}getCompleteChatHeaders(e,t,o){return k(this,null,function*(){return new Promise(s=>{s(this.getDefaultHeaders());})})}getCompleteChatData(e,t,o){return k(this,null,function*(){let s=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new I({info:"Messages are required",cause:new Error("Messages are required")});let m=o?this.transformTools(o):{};return new Promise(r=>{r(M(M(M(M({},this.getDefaultParams()),s),i),m));})})}transformCompleteChatResponse(e){let t=Ln.safeParse(e);if(t.success){if(t.data.choices.length===0)throw new W({info:"Invalid response from model",cause:new Error(`No choices in response : ${JSON.stringify(t.data)}`)});let o=t.data,s=[{role:C,content:[]}],i=o.choices[0].message;i.content&&s[0].content.push(Le(i.content)),i.refusal&&s[0].content.push(Le(i.refusal)),i.tool_calls&&i.tool_calls.forEach((c,p)=>{s[0].content.push(ht(p,c.id,c.function.name,c.function.arguments));});let m={promptTokens:o.usage.prompt_tokens,completionTokens:o.usage.completion_tokens,totalTokens:o.usage.total_tokens},r=[],d=o.choices[0].logprobs;return d&&(d.content&&r.push(...d.content.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes,topLogProbs:c.top_logprobs.map(p=>({token:p.token,logProb:p.logprob,bytes:p.bytes}))}))),d.refusal&&r.push(...d.refusal.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes,topLogProbs:c.top_logprobs.map(p=>({token:p.token,logProb:p.logprob,bytes:p.bytes}))})))),{messages:s,usage:m,logProbs:r}}throw new W({info:"Invalid response from model",cause:t.error})}getStreamChatUrl(e,t,o){return k(this,null,function*(){return new Promise(s=>{s(this.streamChatUrl);})})}getStreamChatHeaders(e,t,o){return k(this,null,function*(){return new Promise(s=>{s(this.getDefaultHeaders());})})}getStreamChatData(e,t,o){return k(this,null,function*(){let s=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new I({info:"Messages are required",cause:new Error("Messages are required")});let m=o?this.transformTools(o):{};return new Promise(r=>{r(M(M(M(M({stream:!0,stream_options:{include_usage:!0}},this.getDefaultParams()),s),i),m));})})}transformStreamChatResponseChunk(e,t){return Xt(this,null,function*(){var o,s;let i=(t+e).split(`
`).filter(m=>m.trim()!=="");for(let m of i){if(m==="data: [DONE]")return;if(m.startsWith("data: {")&&m.endsWith("}")){let r;try{r=JSON.parse(m.substring(6));}catch(c){throw new W({info:`Malformed JSON received in stream : ${r}`,cause:c})}let d=Nn.safeParse(r);if(d.success){let c={partialMessages:[]},p=d.data;if(p.choices.length>0){let h=p.choices[0].delta;if(h!==void 0&&Object.keys(h).length!==0){if("content"in h&&h.content!==null)c.partialMessages.push(Be(C,h.content));else if("refusal"in h&&h.refusal!==null)c.partialMessages.push(Be(C,h.refusal));else if("tool_calls"in h&&h.tool_calls!==void 0){let g=h.tool_calls.at(0);c.partialMessages.push(gt(C,g.index,g.id,(o=g.function)==null?void 0:o.name,(s=g.function)==null?void 0:s.arguments));}}}p.usage&&(c.usage={promptTokens:p.usage.prompt_tokens,completionTokens:p.usage.completion_tokens,totalTokens:p.usage.total_tokens}),yield {partialResponse:c,buffer:t};}else throw new W({info:"Invalid response from model",cause:d.error})}}})}},de=class extends S{constructor(e,t){super(e,t);}transformModelRequest(e){let t=Yn.safeParse(e);if(!t.success)throw new Y({info:"Invalid model request",cause:t.error});let o=t.data,s=ne(M({},o),{max_tokens:o.max_completion_tokens});return delete s.max_completion_tokens,super.transformModelRequest(s)}transformTools(e){throw new L({info:`Model: '${this.modelSchema.name}' does not support 'tools'.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support 'tools'.`)})}getStreamChatUrl(e,t,o){return k(this,null,function*(){throw new L({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}getStreamChatHeaders(e,t,o){return k(this,null,function*(){throw new L({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}getStreamChatData(e,t,o){return k(this,null,function*(){throw new L({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}transformStreamChatResponseChunk(e,t){return Xt(this,null,function*(){throw new L({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}},xo="gpt-3.5-turbo-0125",Zn="The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a   text encoding issue for non-English language function calls. Training data up to Sept 2021.",pe=T(P,K).parse({name:xo,description:Zn,maxInputTokens:4092,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema}}),Xn=O,es=class extends S{constructor(e){super(pe,e);}},So="gpt-3.5-turbo-1106",ts="The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.",ce=T(P,K).parse({name:So,description:ts,maxInputTokens:4092,maxOutputTokens:16385,roles:x,modalities:D,config:{def:u.responseFormat(16385,4).def,schema:u.responseFormat(16385,4).schema}}),os=O,as=class extends S{constructor(e){super(ce,e);}},Mo="gpt-3.5-turbo",ns="Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.",ue=T(P,K).parse({name:Mo,description:ns,maxInputTokens:4092,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema}}),ss=O,is=class extends S{constructor(e){super(ue,e);}},Eo="gpt-4-0125-preview",rs="The latest GPT-4 model intended to reduce cases of \u201Claziness\u201D where the model doesn\u2019t complete a task. Training data up to Apr 2023.",Co=T(P,K).parse({name:Eo,description:rs,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema}}),ls=O,ms=class extends S{constructor(e){super(Co,e);}},wo="gpt-4-0613",ds="Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.",he=T(P,K).parse({name:wo,description:ds,maxInputTokens:8192,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema}}),ps=O,cs=class extends S{constructor(e){super(he,e);}},Io="gpt-4-1106-preview",us="GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.",ge=T(P,K).parse({name:Io,description:us,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema}}),hs=O,gs=class extends S{constructor(e){super(ge,e);}},ko="gpt-4-turbo-2024-04-09",fs="GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.   Training data up to Dec 2023.",fe=T(P,A).parse({name:ko,description:fs,maxInputTokens:128e3,maxOutputTokens:4096,roles:x,modalities:j,config:{def:u.responseFormat(4096,4).def,schema:u.responseFormat(4096,4).schema}}),_s=O,bs=class extends S{constructor(e){super(fe,e);}},Go="gpt-4-turbo-preview",ys="Currently points to gpt-4-0125-preview. Training data up to Apr 2023.",jo=T(P,K).parse({name:Go,description:ys,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema}}),Ts=O,Os=class extends S{constructor(e){super(jo,e);}},Ao="gpt-4-turbo",vs="The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.   Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.",Ro=T(P,A).parse({name:Ao,description:vs,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:j,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema}}),Ps=O,xs=class extends S{constructor(e){super(Ro,e);}},Lo="gpt-4",Ss="Currently points to gpt-4-0613. Training data up to Sept 2021.",_e=T(P,K).parse({name:Lo,description:Ss,maxInputTokens:8192,maxOutputTokens:4092,roles:x,modalities:D,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema}}),Ms=O,Es=class extends S{constructor(e){super(_e,e);}},Bo="gpt-4o-2024-05-13",Cs="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",be=T(P,A).parse({name:Bo,description:Cs,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:j,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema}}),ws=O,Is=class extends S{constructor(e){super(be,e);}},No="gpt-4o-2024-08-06",ks="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",ye=T(P,A).parse({name:No,description:ks,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:j,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema}}),Gs=O,js=class extends S{constructor(e){super(ye,e);}},$o="gpt-4o-mini-2024-07-18",As="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Te=T(P,A).parse({name:$o,description:As,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:j,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema}}),Rs=O,Ls=class extends S{constructor(e){super(Te,e);}},Uo="gpt-4o-mini",Bs="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Oe=T(P,A).parse({name:Uo,description:Bs,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:j,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema}}),Ns=O,$s=class extends S{constructor(e){super(Oe,e);}},qo="gpt-4o",Us="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",ve=T(P,A).parse({name:qo,description:Us,maxInputTokens:128e3,maxOutputTokens:4092,roles:x,modalities:j,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema}}),qs=O,Fs=class extends S{constructor(e){super(ve,e);}},Fo="o1-2024-12-17",zs="A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.",zo=T(P,A).parse({name:Fo,description:zs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:x,modalities:j,config:{def:u.responseFormat(1e5,4).def,schema:u.responseFormat(1e5,4).schema}}),Ds=O,Ks=class extends S{constructor(e){super(zo,e);}},Do="o1-mini-2024-09-12",Hs="Enhanced version of o1-mini optimized for faster reasoning in coding, math, and science. Training data up to September 2024.",Ko=T(Qe,et).parse({name:Do,description:Hs,maxInputTokens:128e3,maxOutputTokens:65536,roles:Ze,modalities:Xe,config:{def:u.oSeries(65536,4).def,schema:u.oSeries(65536,4).schema}}),Vs=O,Js=class extends de{constructor(e){super(Ko,e);}},Ho="o1-mini",Ws="Faster and cheaper reasoning model particularly good at coding, math, and science. Training data up to Oct 2023.",Vo=T(Qe,et).parse({name:Ho,description:Ws,maxInputTokens:128e3,maxOutputTokens:4092,roles:Ze,modalities:Xe,config:{def:u.oSeries(4092,4).def,schema:u.oSeries(4092,4).schema}}),Ys=O,Qs=class extends de{constructor(e){super(Vo,e);}},Jo="o1-preview",Zs="Reasoning model designed to solve hard problems across domains. Training data up to Oct 2023.",Wo=T(Qe,et).parse({name:Jo,description:Zs,maxInputTokens:128e3,maxOutputTokens:4092,roles:Ze,modalities:Xe,config:{def:u.oSeries(4092,4).def,schema:u.oSeries(4092,4).schema}}),Xs=O,ei=class extends de{constructor(e){super(Wo,e);}},Yo="o1",ti="Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.",Qo=T(P,A).parse({name:Yo,description:ti,maxInputTokens:2e5,maxOutputTokens:1e5,roles:x,modalities:j,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),oi=O,ai=class extends de{constructor(e){super(Qo,e);}},se=[z,J],ie=z$1.enum([z,J]),ni=z$1.object({object:z$1.literal("list"),model:z$1.string(),data:z$1.array(z$1.object({index:z$1.number(),object:z$1.literal("embedding"),embedding:z$1.array(z$1.number()).or(z$1.string().base64())})),usage:z$1.object({prompt_tokens:z$1.number().nonnegative(),total_tokens:z$1.number().nonnegative()})}),si=z$1.string().min(1).or(z$1.array(z$1.string().min(1)).min(1)).or(z$1.array(z$1.number().int().nonnegative()).min(1)).or(z$1.array(z$1.array(z$1.number().int().nonnegative()).min(1)).min(1)),ii=z$1.object({model:z$1.string().min(1).optional(),input:si,encoding_format:z$1.enum(["float","base64"]).optional(),dimensions:z$1.number().int().min(1).optional()}),Pe=z$1.object({modelName:z$1.string(),apiKey:z$1.string(),baseUrl:z$1.string().url().optional(),getEmbeddingsUrl:z$1.string().url().optional()}),re=class{constructor(e,t){this.version="v1";let o=Pe.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=Z(o.baseUrl||ot.baseUrl),this.getEmbeddingsUrl=Z(o.getEmbeddingsUrl||`${this.baseUrl}/embeddings`);}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return {Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"}}getDefaultParams(){return {model:this.modelSchema.name}}getRetryDelay(e){let t=r=>{let d=/(\d+)(h|m|s|ms)/g,c={h:36e5,m:6e4,s:1e3,ms:1},p,h=0;for(;(p=d.exec(r))!==null;){let g=parseInt(p[1]),E=p[2];h+=g*c[E];}return h},o=0,s=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(s=t(e["x-ratelimit-reset-tokens"]));let m=Math.max(o,s);return {shouldRetry:i,delayMs:m}}getTokenCount(e){return e.requests.reduce((t,o)=>t+o.length,0)}transformModelRequest(e){let t=ii.safeParse(e);if(!t.success)throw new Y({info:"Invalid model request",cause:t.error});let o=t.data,s=o.model,i={encodingFormat:o.encoding_format,dimensions:o.dimensions},m=Ne().parse(Je(i)),r,d;return typeof o.input=="string"?d=z:typeof o.input[0]=="string"?d=z:d=J,d===z?typeof o.input=="string"?r={modality:d,requests:[o.input]}:r={modality:d,requests:o.input}:typeof o.input[0]=="number"?r={modality:d,requests:[o.input]}:r={modality:d,requests:o.input},{modelName:s,config:m,embeddingRequests:r}}transformConfig(e,t){let o=this.modelSchema.config.schema.safeParse(e);if(!o.success)throw new U({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:o.error});let s=o.data;return Object.keys(s).forEach(i=>{if(!this.modelSchema.config.def[i])throw new U({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:new Error(`Invalid config key : '${i}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})}),Object.keys(s).reduce((i,m)=>{let r=this.modelSchema.config.def[m].param,d=s[m];return i[r]=d,i},{})}transformEmbeddingRequests(e){let t=yt().safeParse(e);if(!t.success)throw new $t({info:"Invalid embedding requests",cause:t.error});return {input:t.data.requests}}getGetEmbeddingsUrl(e,t){return k(this,null,function*(){return new Promise(o=>{o(this.getEmbeddingsUrl);})})}getGetEmbeddingsHeaders(e,t){return k(this,null,function*(){return new Promise(o=>{o(this.getDefaultHeaders());})})}getGetEmbeddingsData(e,t){return k(this,null,function*(){return new Promise(o=>{o(M(M(M({},this.getDefaultParams()),this.transformConfig(e,t)),this.transformEmbeddingRequests(t)));})})}transformGetEmbeddingsResponse(e){let t,o=ni.safeParse(e);if(o.success){let s=o.data;t=typeof s.data[0].embedding=="string"?Ue:$e;let i=s.data.map(m=>typeof m.embedding=="string"?{index:m.index,embedding:m.embedding}:{index:m.index,embedding:m.embedding});return {encodingFormat:t,embeddings:i,usage:{totalTokens:s.usage.total_tokens}}}throw new W({info:"Invalid response from model",cause:o.error})}},Zo="text-embedding-ada-002",ri="Most capable 2nd generation embedding model, replacing 16 first generation models",xe=Q(ie).parse({name:Zo,description:ri,modalities:se,maxInputTokens:8192,maxOutputTokens:1536,config:{def:q.base().def,schema:q.base().schema}}),li=Pe,mi=class extends re{constructor(e){super(xe,e);}},Xo="text-embedding-3-small",di="Increased performance over 2nd generation ada embedding model",Se=Q(ie).parse({name:Xo,description:di,modalities:se,maxInputTokens:8192,maxOutputTokens:1536,config:{def:q.dimensions(1536).def,schema:q.dimensions(1536).schema}}),pi=Pe,ci=class extends re{constructor(e){super(Se,e);}},ea="text-embedding-3-large",ui="Most capable embedding model for both english and non-english tasks",Me=Q(ie).parse({name:ea,description:ui,modalities:se,maxInputTokens:8192,maxOutputTokens:3072,config:{def:q.dimensions(3072).def,schema:q.dimensions(3072).schema}}),hi=Pe,gi=class extends re{constructor(e){super(Me,e);}};var at=T(P,A).parse({name:"__base__",description:"Base chat model for Azure OpenAI",maxInputTokens:128e3,maxOutputTokens:128e3,roles:x,modalities:j,config:{def:u.base(128e3,4).def,schema:u.base(128e3,4).schema}});var b=class extends S{constructor(o,s){let i=_.parse(s),m;if(i.baseUrl)m=i.baseUrl;else if(i.resourceName)m=V.azureUrl(i.resourceName,"openai");else throw new L({info:"Either 'baseUrl' or 'resourceName' must be provided",cause:new Error("Either 'baseUrl' or 'resourceName' must be provided")});let r="2024-06-01",d=`${m}/openai/deployments/${i.deploymentId}`;super(o,{modelName:i.deploymentId,apiKey:i.apiKey,baseUrl:d,completeChatUrl:`${d}/chat/completions?api-version=${r}`,streamChatUrl:`${d}/chat/completions?api-version=${r}`});this.version="v1";this.modelSchema=o,this.deploymentId=i.deploymentId,this.azureApiKey=i.apiKey,this.azureApiVersion=r;}getDefaultHeaders(){return {"Content-Type":"application/json","api-key":this.azureApiKey,source:"adaline"}}};var Ur="gpt-4o",fi=ve,qr=_,ta=class extends b{constructor(t){super(fi,t);}};var Hr="gpt-4o-mini",_i=Oe,Vr=_,oa=class extends b{constructor(t){super(_i,t);}};var Zr="gpt-4o-mini-2024-07-18",bi=Te,Xr=_,aa=class extends b{constructor(t){super(bi,t);}};var nl="gpt-4o-2024-08-06",yi=ye,sl=_,na=class extends b{constructor(t){super(yi,t);}};var dl="gpt-4o-2024-05-13",Ti=be,pl=_,sa=class extends b{constructor(t){super(Ti,t);}};var fl="gpt-4",Oi=_e,_l=_,ia=class extends b{constructor(t){super(Oi,t);}};var vl="gpt-4-turbo-2024-04-09",vi=fe,Pl=_,ra=class extends b{constructor(t){super(vi,t);}};var Cl="gpt-4-1106-preview",Pi=ge,wl=_,la=class extends b{constructor(t){super(Pi,t);}};var Al="gpt-4-0613",xi=he,Rl=_,ma=class extends b{constructor(t){super(xi,t);}};var Ul="gpt-3-5-turbo",Si=ue,ql=_,da=class extends b{constructor(t){super(Si,t);}};var Hl="gpt-3-5-turbo-1106",Mi=ce,Vl=_,pa=class extends b{constructor(t){super(Mi,t);}};var Zl="gpt-3-5-turbo-0125",Ei=pe,Xl=_,ca=class extends b{constructor(t){super(Ei,t);}};var B=z$1.object({apiKey:z$1.string().min(1),deploymentId:z$1.string().min(1),resourceName:z$1.string().min(1).optional(),baseUrl:z$1.string().optional()});var nt=Q(ie).parse({name:"__base__",description:"Base embedding model for Azure OpenAI",maxInputTokens:8192,maxOutputTokens:3072,modalities:se,config:{def:q.dimensions(3072).def,schema:q.dimensions(3072).schema}});var N=class extends re{constructor(o,s){let i=B.parse(s),m;if(i.baseUrl)m=i.baseUrl;else if(i.resourceName)m=V.azureUrl(i.resourceName,"openai");else throw new L({info:"Either 'baseUrl' or 'resourceName' must be provided",cause:new Error("Either 'baseUrl' or 'resourceName' must be provided")});let r="2024-06-01",d=`${m}/openai/deployments/${i.deploymentId}`;super(o,{modelName:i.deploymentId,apiKey:i.apiKey,baseUrl:d,getEmbeddingsUrl:`${d}/embeddings?api-version=${r}`});this.version="v1";this.modelSchema=o,this.deploymentId=i.deploymentId,this.azureApiKey=i.apiKey,this.azureApiVersion=r;}getDefaultHeaders(){return {"Content-Type":"application/json","api-key":this.azureApiKey,source:"adaline"}}};var _m="text-embedding-3-large",Ci=Me,bm=B,ua=class extends N{constructor(t){super(Ci,t);}};var Pm="text-embedding-ada-002",wi=xe,xm=B,ha=class extends N{constructor(t){super(wi,t);}};var wm="text-embedding-3-small",Ii=Se,Im=B,ga=class extends N{constructor(t){super(Ii,t);}};var ki="azure",V=class{constructor(){this.version="v1";this.name=ki;}chatModelLiterals(){return ["__base__"]}chatModelSchemas(){return {__base__:at}}chatModel(t){let o=b,s=_.parse(t);return new o(at,s)}embeddingModelLiterals(){return ["__base__"]}embeddingModelSchemas(){return {__base__:nt}}embeddingModel(t){let o=N,s=B.parse(t);return new o(nt,s)}};V.azureUrl=(t,o)=>`https://${t}.${o}.azure.com`;

export { V as Azure, b as BaseChatModelOpenAI, _ as BaseChatModelOptions, at as BaseChatModelSchema, N as BaseEmbeddingModelOpenAI, B as BaseEmbeddingModelOptions, nt as BaseEmbeddingModelSchema, da as GPT_3_5_Turbo, Ul as GPT_3_5_TurboLiteral, ql as GPT_3_5_TurboOptions, Si as GPT_3_5_TurboSchema, ca as GPT_3_5_Turbo_0125, Zl as GPT_3_5_Turbo_0125Literal, Xl as GPT_3_5_Turbo_0125Options, Ei as GPT_3_5_Turbo_0125Schema, pa as GPT_3_5_Turbo_1106, Hl as GPT_3_5_Turbo_1106Literal, Vl as GPT_3_5_Turbo_1106Options, Mi as GPT_3_5_Turbo_1106Schema, ia as GPT_4, fl as GPT_4Literal, _l as GPT_4Options, Oi as GPT_4Schema, ma as GPT_4_0613, Al as GPT_4_0613Literal, Rl as GPT_4_0613Options, xi as GPT_4_0613Schema, la as GPT_4_1106_Preview, Cl as GPT_4_1106_PreviewLiteral, wl as GPT_4_1106_PreviewOptions, Pi as GPT_4_1106_PreviewSchema, ra as GPT_4_Turbo_2024_04_09, vl as GPT_4_Turbo_2024_04_09Literal, Pl as GPT_4_Turbo_2024_04_09Options, vi as GPT_4_Turbo_2024_04_09Schema, ta as GPT_4o, Ur as GPT_4oLiteral, qr as GPT_4oOptions, fi as GPT_4oSchema, sa as GPT_4o_2024_05_13, dl as GPT_4o_2024_05_13Literal, pl as GPT_4o_2024_05_13Options, Ti as GPT_4o_2024_05_13Schema, na as GPT_4o_2024_08_06, nl as GPT_4o_2024_08_06Literal, sl as GPT_4o_2024_08_06Options, yi as GPT_4o_2024_08_06Schema, oa as GPT_4o_Mini, Hr as GPT_4o_MiniLiteral, Vr as GPT_4o_MiniOptions, _i as GPT_4o_MiniSchema, aa as GPT_4o_Mini_2024_07_18, Zr as GPT_4o_Mini_2024_07_18Literal, Xr as GPT_4o_Mini_2024_07_18Options, bi as GPT_4o_Mini_2024_07_18Schema, ua as Text_Embedding_3_Large, _m as Text_Embedding_3_LargeLiteral, bm as Text_Embedding_3_LargeOptions, Ci as Text_Embedding_3_LargeSchema, ga as Text_Embedding_3_Small, wm as Text_Embedding_3_SmallLiteral, Im as Text_Embedding_3_SmallOptions, Ii as Text_Embedding_3_SmallSchema, ha as Text_Embedding_Ada_002, Pm as Text_Embedding_Ada_002Literal, xm as Text_Embedding_Ada_002Options, wi as Text_Embedding_Ada_002Schema };
//# sourceMappingURL=index.mjs.map
//# sourceMappingURL=index.mjs.map