{"version":3,"sources":["../src/configs/chat-model/base.config.chat-model.openai.ts","../src/configs/chat-model/common.config.chat-model.openai.ts","../src/configs/chat-model/o-series.config.chat-model.openai.ts","../src/configs/chat-model/response-schema.config.chat-model.openai.ts","../src/configs/chat-model/response-format.config.chat-model.openai.ts","../src/configs/embedding-model/common.config.embedding-model.openai.ts","../src/configs/embedding-model/base.config.embedding-model.openai.ts","../src/configs/embedding-model/dimensions.config.embedding-model.openai.ts","../src/configs/configs.openai.ts","../src/models/chat-models/types/roles.chat-model.openai.ts","../src/models/chat-models/types/modalities.chat-model.openai.ts","../src/models/chat-models/types/response.chat-model.openai.ts","../src/models/chat-models/types/request.chat-model.openai.ts","../src/models/chat-models/types/request.o-series.chat-model.openai.ts","../src/provider/provider.openai.ts","../src/models/chat-models/base-chat-model.openai.ts","../src/models/chat-models/base-o-series-chat-model.openai.ts","../src/models/chat-models/gpt-3-5-turbo-0125.openai.ts","../src/models/chat-models/gpt-3-5-turbo-1106.openai.ts","../src/models/chat-models/gpt-3-5-turbo.openai.ts","../src/models/chat-models/gpt-4-0125-preview.openai.ts","../src/models/chat-models/gpt-4-0613.openai.ts","../src/models/chat-models/gpt-4-1106-preview.openai.ts","../src/models/chat-models/gpt-4-turbo-2024-04-09.openai.ts","../src/models/chat-models/gpt-4-turbo-preview.openai.ts","../src/models/chat-models/gpt-4-turbo.openai.ts","../src/models/chat-models/gpt-4.openai.ts","../src/models/chat-models/gpt-4o-2024-05-13.openai.ts","../src/models/chat-models/gpt-4o-2024-08-06.openai.ts","../src/models/chat-models/gpt-4o-mini-2024-07-18.openai.ts","../src/models/chat-models/gpt-4o-mini.openai.ts","../src/models/chat-models/gpt-4o.openai.ts","../src/models/chat-models/o1-2024-12-17.openai.ts","../src/models/chat-models/o1-mini-2024-09-12.openai.ts","../src/models/chat-models/o1-mini.openai.ts","../src/models/chat-models/o1-preview.openai.ts","../src/models/chat-models/o1.openai.ts","../src/models/embedding-models/types/modalitites.embedding-model.openai.ts","../src/models/embedding-models/types/response.embedding-model.openai.ts","../src/models/embedding-models/types/request.embedding-model.openai.ts","../src/models/embedding-models/base-embedding-model.openai.ts","../src/models/embedding-models/text-embedding-ada-002.openai.ts","../src/models/embedding-models/text-embedding-3-small.openai.ts","../src/models/embedding-models/text-embedding-3-large.openai.ts"],"names":["temperature","RangeConfigItem","CHAT_CONFIG","maxTokens","maxOutputTokens","stop","maxSequences","MultiStringConfigItem","topP","frequencyPenalty","presencePenalty","seed","logProbs","SelectBooleanConfigItem","topLogProbs","toolChoice","SelectStringConfigItem","ChatModelBaseConfigSchema","z","value","ChatModelBaseConfigDef","responseSchema","ObjectSchemaConfigItem","ResponseSchema","responseFormat","ChatModelResponseSchemaConfigDef","__spreadProps","__spreadValues","ChatModelResponseSchemaConfigSchema","ChatModelOSeriesConfigDef","ChatModelOSeriesConfigSchema","ChatModelResponseFormatConfigDef","ChatModelResponseFormatConfigSchema","encodingFormat","dimensions","maxDimensions","EmbeddingModelBaseConfigSchema","EmbeddingModelBaseConfigDef","EmbeddingModelDimensionsConfigSchema","EmbeddingModelDimensionsConfigDef","OpenAIChatModelConfigs","OpenAIEmbeddingModelConfigs","OpenAIChatModelRoles","SystemRoleLiteral","UserRoleLiteral","AssistantRoleLiteral","ToolRoleLiteral","OpenAIChatModelRolesMap","OpenAIChatModelOSSeriesRoles","OpenAIChatModelOSSeriesRolesMap","OpenAIChatModelModalities","TextModalityLiteral","ImageModalityLiteral","ToolCallModalityLiteral","ToolResponseModalityLiteral","OpenAIChatModelModalitiesEnum","OpenAIChatModelTextModalities","OpenAIChatModelTextModalitiesEnum","OpenAIChatModelTextToolModalities","OpenAIChatModelTextToolModalitiesEnum","OpenAIBaseLogProb","OpenAILogProb","OpenAIToolCallsCompleteChatResponse","OpenAICompleteChatResponse","OpenAIToolCallsStreamChatResponse","OpenAIStreamChatResponse","OpenAIChatRequestTool","OpenAIChatRequestToolChoiceEnum","OpenAIChatRequestToolChoiceFunction","OpenAIChatRequestResponseFormat","OpenAIChatRequestTextContent","OpenAIChatRequestImageContent","OpenAIChatRequestToolCallContent","OpenAIChatRequestSystemMessage","OpenAIChatRequestUserMessage","OpenAIChatRequestAssistantMessage","OpenAIChatRequestToolMessage","OpenAIChatRequestMessage","OpenAIChatRequest","OpenAIChatOSeriesRequest","ProviderLiteral","OpenAI","GPT_3_5_TurboLiteral","GPT_3_5_Turbo","GPT_3_5_TurboOptions","GPT_3_5_TurboSchema","GPT_3_5_Turbo_0125Literal","GPT_3_5_Turbo_0125","GPT_3_5_Turbo_0125Options","GPT_3_5_Turbo_0125Schema","GPT_3_5_Turbo_1106Literal","GPT_3_5_Turbo_1106","GPT_3_5_Turbo_1106Options","GPT_3_5_Turbo_1106Schema","GPT_4_0125_PreviewLiteral","GPT_4_0125_Preview","GPT_4_0125_PreviewOptions","GPT_4_0125_PreviewSchema","GPT_4_0613Literal","GPT_4_0613","GPT_4_0613Options","GPT_4_0613Schema","GPT_4_1106_PreviewLiteral","GPT_4_1106_Preview","GPT_4_1106_PreviewOptions","GPT_4_1106_PreviewSchema","GPT_4_Turbo_2024_04_09Literal","GPT_4_Turbo_2024_04_09","GPT_4_Turbo_2024_04_09Options","GPT_4_Turbo_2024_04_09Schema","GPT_4_Turbo_PreviewLiteral","GPT_4_Turbo_Preview","GPT_4_Turbo_PreviewOptions","GPT_4_Turbo_PreviewSchema","GPT_4_TurboLiteral","GPT_4_Turbo","GPT_4_TurboOptions","GPT_4_TurboSchema","GPT_4Literal","GPT_4","GPT_4Options","GPT_4Schema","GPT_4o_2024_08_06Literal","GPT_4o_2024_08_06","GPT_4o_2024_08_06Options","GPT_4o_2024_08_06Schema","GPT_4o_MiniLiteral","GPT_4o_Mini","GPT_4o_MiniOptions","GPT_4o_MiniSchema","GPT_4oLiteral","GPT_4o","GPT_4oOptions","GPT_4oSchema","GPT_4o_Mini_2024_07_18Literal","GPT_4o_Mini_2024_07_18","GPT_4o_Mini_2024_07_18Options","GPT_4o_Mini_2024_07_18Schema","GPT_4o_2024_05_13Literal","GPT_4o_2024_05_13","GPT_4o_2024_05_13Options","GPT_4o_2024_05_13Schema","O1_MiniLiteral","O1_Mini","O1_MiniOptions","O1_MiniSchema","O1_PreviewLiteral","O1_Preview","O1_PreviewOptions","O1_PreviewSchema","O1Literal","O1","O1Options","O1Schema","O1_2024_12_17Literal","O1_2024_12_17","O1_2024_12_17Options","O1_2024_12_17Schema","O1_Mini_2024_09_12Literal","O1_Mini_2024_09_12","O1_Mini_2024_09_12Options","O1_Mini_2024_09_12Schema","Text_Embedding_Ada002Literal","Text_Embedding_Ada002","Text_Embedding_Ada002_Options","Text_Embedding_Ada002Schema","Text_Embedding_3_SmallLiteral","Text_Embedding_3_Small","Text_Embedding_3_Small_Options","Text_Embedding_3_SmallSchema","Text_Embedding_3_LargeLiteral","Text_Embedding_3_Large","Text_Embedding_3_Large_Options","Text_Embedding_3_LargeSchema","acc","key","options","modelName","ProviderError","model","parsedOptions","BaseChatModelOptions","BaseChatModel","modelSchema","urlWithoutTrailingSlash","responseHeaders","parseDuration","duration","regex","timeUnits","match","totalMs","unit","resetRequestsDelayMs","resetTokensDelayMs","shouldRetry","delayMs","messages","message","content","request","safeRequest","InvalidModelRequestError","parsedRequest","_config","config","Config","removeUndefinedEntries","toolCallMap","role","_content","c","Base64ImageContentTypeLiteral","getMimeTypeFromBase64","UrlImageContentTypeLiteral","assistantContent","toolCall","index","toolCallContent","toolResponse","tools","tool","_toolChoice","_parsedConfig","InvalidConfigError","parsedConfig","transformedConfig","def","paramKey","paramValue","configToolChoice","parsedMessages","parsedMessage","Message","InvalidMessagesError","textContent","toolCalls","imageContent","combinedContent","InvalidToolsError","parsedTool","Tool","__async","resolve","transformedMessages","transformedTools","response","safe","ModelResponseError","parsedResponse","createTextContent","createToolCallContent","usage","_logProbs","logProb","topLogProb","chunk","buffer","__asyncGenerator","_a","_b","lines","line","structuredLine","error","partialResponse","createPartialTextMessage","createPartialToolCallMessage","BaseOSeriesChatModel","baseRequest","ModelError","GPT_3_5_Turbo_0125Description","ChatModelSchema","GPT_3_5_Turbo_1106Description","GPT_3_5_TurboDescription","GPT_4_0125_PreviewDescription","GPT_4_0613Description","GPT_4_1106_PreviewDescription","GPT_4_Turbo_2024_04_09Description","GPT_4_Turbo_PreviewDescription","GPT_4_TurboDescription","GPT_4Description","GPT_4o_2024_05_13Description","GPT_4o_2024_08_06Description","GPT_4o_MiniDescription","GPT_4oDescription","O1_2024_12_17Description","O1_Mini_2024_09_12Description","O1_MiniDescription","O1_PreviewDescription","O1Description","OpenAIEmbeddingModelModalities","EmbeddingTextModalityLiteral","EmbeddingTokenModalityLiteral","OpenAIEmbeddingModelModalitiesEnum","OpenAIGetEmbeddingsResponse","OpenAIEmbeddingRequestInput","OpenAIEmbeddingRequest","BaseEmbeddingModelOptions","BaseEmbeddingModel","requests","embeddingRequests","embeddingFormat","_parsedRequests","EmbeddingRequests","InvalidEmbeddingRequestsError","Base64EmbeddingLiteral","FloatEmbeddingLiteral","embeddings","item","Text_Embedding_Ada002Description","EmbeddingModelSchema","Text_Embedding_3_SmallDescription","Text_Embedding_3_LargeDescription"],"mappings":";;;;AAAA,IAAA,EAAA,CAAA,MAAA,CAAA,cAAA,CAAA,EAAA,CAAA,MAAA,CAAA,gBAAA,CAAA,IAAA,EAAA,CAAA,MAAA,CAAA,yBAAA,CAAA,IAAA,EAAA,CAAA,MAAA,CAAA,qBAAA,CAAA,IAAA,EAAA,CAAA,MAAA,CAAA,SAAA,CAAA,cAAA,CAAA,EAAA,CAAA,MAAA,CAAA,SAAA,CAAA,oBAAA,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,CAAA,CAAA,MAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,MAAA,CAAA,GAAA,CAAA,SAAA,CAAA,CAAA,CAAA,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,IAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,UAAA,CAAA,CAAA,CAAA,CAAA,YAAA,CAAA,CAAA,CAAA,CAAA,QAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,IAAA,IAAA,CAAA,IAAA,CAAA,GAAA,CAAA,CAAA,EAAA,CAAA,CAAA,EAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,CAAA,IAAA,IAAA,CAAA,IAAA,EAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,EAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,IAAA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,IAAA,CAAA,CAAA,CAAA,EAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,EAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,EAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,OAAA,CAAA,OAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,IAAA,EAAA,EAAA,CAAA,CAAA,CAAA,EAAA,CAAA,SAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,GAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,YAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,OAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,QAAA,CAAA,CAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,IAAA,CAAA,KAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,EAAA,CAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,IAAA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EAAA,CAAA,eAAA,CAAA,CAAA,CAAA,IAAA,CAAA,CAAA,CAAA,CAAA,MAAA,CAAA,CAAA,CAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA,QAAA,CAAA,CAAA,CAAA,CAAA,CCEMA,IAAAA,EAAAA,CAAcC,eAAgB,CAAA,CAClC,KAAO,CAAA,aAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,WAAY,CAAA,KAAA,CAC/B,WAAaA,CAAAA,WAAAA,CAAY,WAAY,CAAA,WAAA,CACrC,IAAK,CACL,CAAA,GAAA,CAAK,CACL,CAAA,IAAA,CAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKC,CAAAA,EAAAA,CAAaC,CACjBH,EAAAA,eAAAA,CAAgB,CACd,KAAA,CAAO,YACP,CAAA,KAAA,CAAOC,YAAY,UAAW,CAAA,KAAA,CAC9B,WAAaA,CAAAA,WAAAA,CAAY,UAAW,CAAA,WAAA,CACpC,GAAK,CAAA,CAAA,CACL,GAAKE,CAAAA,CAAAA,CACL,IAAM,CAAA,CAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEGC,GAAQC,CACZC,EAAAA,qBAAAA,CAAsB,CACpB,KAAA,CAAO,MACP,CAAA,KAAA,CAAOL,WAAY,CAAA,IAAA,CAAKI,CAAY,CAAA,CAAE,KACtC,CAAA,WAAA,CAAaJ,WAAY,CAAA,IAAA,CAAKI,CAAY,CAAA,CAAE,YAC5C,GAAKA,CAAAA,CACP,CAAC,CAAA,CAEGE,EAAOP,CAAAA,eAAAA,CAAgB,CAC3B,KAAA,CAAO,OACP,CAAA,KAAA,CAAOC,WAAY,CAAA,KAAA,CAAM,KACzB,CAAA,WAAA,CAAaA,WAAY,CAAA,KAAA,CAAM,YAC/B,GAAK,CAAA,CAAA,CACL,GAAK,CAAA,CAAA,CACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKO,EAAmBR,CAAAA,eAAAA,CAAgB,CACvC,KAAA,CAAO,mBACP,CAAA,KAAA,CAAOC,YAAY,iBAAkB,CAAA,KAAA,CACrC,WAAaA,CAAAA,WAAAA,CAAY,iBAAkB,CAAA,WAAA,CAC3C,GAAK,CAAA,CAAA,CAAA,CACL,GAAK,CAAA,CAAA,CACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKQ,GAAkBT,eAAgB,CAAA,CACtC,KAAO,CAAA,kBAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,gBAAiB,CAAA,KAAA,CACpC,WAAaA,CAAAA,WAAAA,CAAY,gBAAiB,CAAA,WAAA,CAC1C,GAAK,CAAA,CAAA,CAAA,CACL,GAAK,CAAA,CAAA,CACL,KAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKS,CAAAA,EAAAA,CAAOV,eAAgB,CAAA,CAC3B,KAAO,CAAA,MAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,IAAK,CAAA,KAAA,CACxB,WAAaA,CAAAA,WAAAA,CAAY,KAAK,WAC9B,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,GACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKU,CAAAA,EAAAA,CAAWC,uBAAwB,CAAA,CACvC,KAAO,CAAA,UAAA,CACP,MAAOX,WAAY,CAAA,SAAA,CAAU,KAC7B,CAAA,WAAA,CAAaA,WAAY,CAAA,SAAA,CAAU,WACnC,CAAA,OAAA,CAAS,CACX,CAAA,CAAC,CAEKY,CAAAA,EAAAA,CAAcb,eAAgB,CAAA,CAClC,KAAO,CAAA,cAAA,CACP,MAAOC,WAAY,CAAA,aAAA,CAAc,KACjC,CAAA,WAAA,CAAaA,WAAY,CAAA,aAAA,CAAc,WACvC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,EACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,EAEKa,EAAaC,CAAAA,sBAAAA,CAAuB,CACxC,KAAA,CAAO,aACP,CAAA,KAAA,CAAO,aACP,CAAA,WAAA,CACE,uLACF,CAAA,OAAA,CAAS,MACT,CAAA,OAAA,CAAS,CAAC,MAAA,CAAQ,UAAY,CAAA,MAAM,CACtC,CAAC,EDhFKC,IAAAA,CAAAA,CAA4B,CAACb,CAAAA,CAAyBE,CAC1DY,GAAAA,CAAAA,CAAE,MAAO,CAAA,CACP,WAAalB,CAAAA,EAAAA,CAAY,MACzB,CAAA,SAAA,CAAWG,EAAUC,CAAAA,CAAe,EAAE,MACtC,CAAA,IAAA,CAAMC,EAAKC,CAAAA,CAAY,CAAE,CAAA,MAAA,CACzB,IAAME,CAAAA,EAAAA,CAAK,OACX,gBAAkBC,CAAAA,EAAAA,CAAiB,MACnC,CAAA,eAAA,CAAiBC,EAAgB,CAAA,MAAA,CACjC,IAAMC,CAAAA,EAAAA,CAAK,OAAO,SAAWQ,CAAAA,CAAAA,EAAWA,CAAU,GAAA,CAAA,CAAI,KAAYA,CAAAA,CAAAA,CAAM,CACxE,CAAA,QAAA,CAAUP,EAAS,CAAA,MAAA,CACnB,WAAaE,CAAAA,EAAAA,CAAY,MACzB,CAAA,UAAA,CAAYC,EAAW,CAAA,MACzB,CAAC,CAEGK,CAAAA,CAAAA,CAAyB,CAAChB,CAAAA,CAAyBE,CACtD,IAAA,CACC,WAAaN,CAAAA,EAAAA,CAAY,GACzB,CAAA,SAAA,CAAWG,EAAUC,CAAAA,CAAe,CAAE,CAAA,GAAA,CACtC,IAAMC,CAAAA,EAAAA,CAAKC,CAAY,CAAE,CAAA,GAAA,CACzB,IAAME,CAAAA,EAAAA,CAAK,GACX,CAAA,gBAAA,CAAkBC,EAAiB,CAAA,GAAA,CACnC,eAAiBC,CAAAA,EAAAA,CAAgB,GACjC,CAAA,IAAA,CAAMC,EAAK,CAAA,GAAA,CACX,QAAUC,CAAAA,EAAAA,CAAS,IACnB,WAAaE,CAAAA,EAAAA,CAAY,GACzB,CAAA,UAAA,CAAYC,EAAW,CAAA,GACzB,CEzCF,ECKMM,IAAAA,EAAAA,CAAiBC,sBAAuB,CAAA,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAOpB,CAAAA,WAAAA,CAAY,gBAAgB,KACnC,CAAA,WAAA,CAAaA,WAAY,CAAA,eAAA,CAAgB,WACzC,CAAA,YAAA,CAAcqB,cAChB,CAAC,CAEKC,CAAAA,EAAAA,CAAiBR,sBAAuB,CAAA,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAOd,CAAAA,WAAAA,CAAY,4BAA4B,KAC/C,CAAA,WAAA,CAAaA,WAAY,CAAA,2BAAA,CAA4B,WACrD,CAAA,OAAA,CAAS,MACT,CAAA,OAAA,CAAS,CAAC,MAAA,CAAQ,aAAe,CAAA,aAAa,CAChD,CAAC,CAEKuB,CAAAA,EAAAA,CAAmC,CAACrB,CAAyBE,CAAAA,CAAAA,GAA0BoB,CAAAC,CAAAA,CAAAA,CAAA,EACxFP,CAAAA,CAAAA,CAAuBhB,CAAiBE,CAAAA,CAAY,CADoC,CAAA,CAAA,CAE3F,cAAgBkB,CAAAA,EAAAA,CAAe,GAC/B,CAAA,cAAA,CAAgBH,EAAe,CAAA,GACjC,GAEMO,EAAsC,CAAA,CAACxB,CAAyBE,CAAAA,CAAAA,GACpEW,CAA0Bb,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CAC9D,cAAgBkB,CAAAA,EAAAA,CAAe,MAC/B,CAAA,cAAA,CAAgBH,EAAe,CAAA,MACjC,CAAC,EDzBH,IAAMrB,EAAcC,CAAAA,eAAAA,CAAgB,CAClC,KAAA,CAAO,aACP,CAAA,KAAA,CAAOC,WAAY,CAAA,WAAA,CAAY,KAC/B,CAAA,WAAA,CAAaA,WAAY,CAAA,WAAA,CAAY,WACrC,CAAA,GAAA,CAAK,EACL,GAAK,CAAA,CAAA,CACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKC,EAAaC,CAAAA,CAAAA,EACjBH,eAAgB,CAAA,CACd,KAAO,CAAA,uBAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,WAAW,KAC9B,CAAA,WAAA,CAAaA,WAAY,CAAA,UAAA,CAAW,WACpC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAKE,CACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEGyB,CAAAA,EAAAA,CAA4B,CAACzB,CAAyBE,CAAAA,CAAAA,GAA0BoB,CAAAC,CAAAA,CAAAA,CAAA,EACjFF,CAAAA,EAAAA,CAAiCrB,CAAiBE,CAAAA,CAAY,CADmB,CAAA,CAAA,CAEpF,WAAaN,CAAAA,EAAAA,CAAY,GACzB,CAAA,SAAA,CAAWG,EAAUC,CAAAA,CAAe,EAAE,GACxC,CAAA,CAAA,CAEM0B,EAA+B,CAAA,CAAC1B,CAAyBE,CAAAA,CAAAA,GAC7DsB,EAAoCxB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CACxE,WAAaN,CAAAA,EAAAA,CAAY,MACzB,CAAA,SAAA,CAAWG,GAAUC,CAAe,CAAA,CAAE,MACxC,CAAC,EEhCH,IAAMoB,EAAiBR,CAAAA,sBAAAA,CAAuB,CAC5C,KAAA,CAAO,kBACP,KAAOd,CAAAA,WAAAA,CAAY,eAAgB,CAAA,KAAA,CACnC,WAAaA,CAAAA,WAAAA,CAAY,eAAgB,CAAA,WAAA,CACzC,QAAS,MACT,CAAA,OAAA,CAAS,CAAC,MAAA,CAAQ,aAAa,CACjC,CAAC,CAAA,CAEK6B,GAAmC,CAAC3B,CAAAA,CAAyBE,CAA0BoB,GAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACxFP,CAAuBhB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAA,CADoC,CAE3F,cAAA,CAAgBkB,EAAe,CAAA,GACjC,CAEMQ,CAAAA,CAAAA,EAAAA,CAAsC,CAAC5B,CAAyBE,CAAAA,CAAAA,GACpEW,CAA0Bb,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CAC9D,cAAgBkB,CAAAA,EAAAA,CAAe,MACjC,CAAC,EClBGS,IAAAA,EAAAA,CAAiBjB,sBAAuB,CAAA,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAO,CAAA,iBAAA,CACP,WAAa,CAAA,oDAAA,CACb,QAAS,OACT,CAAA,OAAA,CAAS,CAAC,OAAA,CAAS,QAAQ,CAC7B,CAAC,CAAA,CAEKkB,EAAcC,CAAAA,CAAAA,EAClBlC,eAAgB,CAAA,CACd,KAAO,CAAA,YAAA,CACP,KAAO,CAAA,YAAA,CACP,YAAa,yDACb,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAKkC,CACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAASA,CACX,CAAC,ECfH,IAAMC,EAAiC,CAAA,IACrClB,CAAE,CAAA,MAAA,CAAO,CACP,cAAgBe,CAAAA,EAAAA,CAAe,MACjC,CAAC,CAEGI,CAAAA,EAAAA,CAA8B,KACjC,CACC,cAAgBJ,CAAAA,EAAAA,CAAe,GACjC,CAAA,ECTIK,IAAAA,EAAAA,CAAwCH,CAC5CC,EAAAA,EAAAA,GAAiC,MAAO,CAAA,CACtC,UAAYF,CAAAA,EAAAA,CAAWC,CAAa,CAAA,CAAE,MACxC,CAAC,CAEGI,CAAAA,EAAAA,CAAqCJ,CACxCT,EAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACIU,EAA4B,EAAA,CAAA,CADhC,CAEC,UAAYH,CAAAA,EAAAA,CAAWC,CAAa,CAAA,CAAE,GACxC,CAAA,ECKIK,IAAAA,CAAAA,CAAyB,CAC7B,IAAA,CAAM,CAACpC,CAAAA,CAAyBE,CAA0B,IAAA,CACxD,GAAKc,CAAAA,CAAAA,CAAuBhB,EAAiBE,CAAY,CAAA,CACzD,MAAQW,CAAAA,CAAAA,CAA0Bb,CAAiBE,CAAAA,CAAY,CACjE,CAAA,CAAA,CACA,cAAgB,CAAA,CAACF,CAAyBE,CAAAA,CAAAA,IAA0B,CAClE,GAAA,CAAKyB,EAAiC3B,CAAAA,CAAAA,CAAiBE,CAAY,CACnE,CAAA,MAAA,CAAQ0B,EAAoC5B,CAAAA,CAAAA,CAAiBE,CAAY,CAC3E,CACA,CAAA,CAAA,cAAA,CAAgB,CAACF,CAAAA,CAAyBE,CAA0B,IAAA,CAClE,GAAKmB,CAAAA,EAAAA,CAAiCrB,CAAiBE,CAAAA,CAAY,EACnE,MAAQsB,CAAAA,EAAAA,CAAoCxB,CAAiBE,CAAAA,CAAY,CAC3E,CAAA,CAAA,CACA,OAAS,CAAA,CAACF,CAAyBE,CAAAA,CAAAA,IAA0B,CAC3D,GAAA,CAAKuB,EAA0BzB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAC5D,OAAQwB,EAA6B1B,CAAAA,CAAAA,CAAiBE,CAAY,CACpE,CACF,CAAA,CAAA,CAEMmC,CAA8B,CAAA,CAClC,IAAM,CAAA,KAAO,CACX,GAAA,CAAKJ,EAA4B,EAAA,CACjC,MAAQD,CAAAA,EAAAA,EACV,CACA,CAAA,CAAA,UAAA,CAAaD,CAA2B,GAAA,CACtC,GAAKI,CAAAA,EAAAA,CAAkCJ,CAAa,CAAA,CACpD,MAAQG,CAAAA,EAAAA,CAAqCH,CAAa,CAC5D,CACF,CAAA,ECzCMO,IAAAA,CAAAA,CAAuBxB,CAAE,CAAA,IAAA,CAAK,CAACyB,iBAAAA,CAAmBC,eAAiBC,CAAAA,oBAAAA,CAAsBC,eAAe,CAAC,CAEzGC,CAAAA,CAAAA,CAA0B,CAC9B,MAAA,CAAQJ,iBACR,CAAA,IAAA,CAAMC,gBACN,SAAWC,CAAAA,oBAAAA,CACX,IAAMC,CAAAA,eACR,CAEME,CAAAA,CAAAA,CAA+B9B,CAAE,CAAA,IAAA,CAAK,CAAC0B,eAAAA,CAAiBC,oBAAoB,CAAC,CAE7EI,CAAAA,CAAAA,CAAkC,CACtC,IAAA,CAAML,gBACN,SAAWC,CAAAA,oBACb,ECbMK,IAAAA,CAAAA,CAA+D,CACnEC,mBAAAA,CACAC,oBACAC,CAAAA,uBAAAA,CACAC,2BACF,CAAA,CAEMC,CAAgCrC,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAC3CiC,mBACAC,CAAAA,oBAAAA,CACAC,uBACAC,CAAAA,2BACF,CAAC,CAEKE,CAAAA,CAAAA,CAAmE,CAACL,mBAAmB,CAEvFM,CAAAA,CAAAA,CAAoCvC,CAAE,CAAA,IAAA,CAAK,CAACiC,mBAAmB,CAAC,CAAA,CAEhEO,CAAuE,CAAA,CAC3EP,mBACAE,CAAAA,uBAAAA,CACAC,2BACF,CAEMK,CAAAA,CAAAA,CAAwCzC,CAAE,CAAA,IAAA,CAAK,CAACiC,mBAAAA,CAAqBE,uBAAyBC,CAAAA,2BAA2B,CAAC,EC3B1HM,IAAAA,EAAAA,CAAoB1C,EAAE,MAAO,CAAA,CACjC,KAAOA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAChB,OAASA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAClB,KAAOA,CAAAA,CAAAA,CAAE,KAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAC,EAAE,QAAS,EACtC,CAAC,CAAA,CAEK2C,EAAgB3C,CAAAA,CAAAA,CACnB,MAAO,CAAA,CACN,OAASA,CAAAA,CAAAA,CACN,KACC0C,CAAAA,EAAAA,CAAkB,MAAO,CAAA,CACvB,YAAc1C,CAAAA,CAAAA,CAAE,MAAM0C,EAAiB,CACzC,CAAC,CACH,CACC,CAAA,QAAA,EACA,CAAA,QAAA,EACH,CAAA,OAAA,CAAS1C,CACN,CAAA,KAAA,CACC0C,EAAkB,CAAA,MAAA,CAAO,CACvB,YAAA,CAAc1C,EAAE,KAAM0C,CAAAA,EAAiB,CACzC,CAAC,CACH,CAAA,CACC,QAAS,EAAA,CACT,QAAS,EACd,CAAC,CAAA,CACA,QAAS,EAAA,CAENE,EAAsC5C,CAAAA,CAAAA,CAAE,MAC5CA,CAAE,CAAA,MAAA,CAAO,CACP,EAAA,CAAIA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACpB,IAAMA,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAAC,UAAU,CAAC,EACzB,QAAUA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACjB,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACf,SAAWA,CAAAA,CAAAA,CAAE,MAAO,EACtB,CAAC,CACH,CAAC,CACH,EAEM6C,EAA6B7C,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC1C,EAAIA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACb,MAAQA,CAAAA,CAAAA,CAAE,OAAQ,CAAA,iBAAiB,CACnC,CAAA,OAAA,CAASA,CAAE,CAAA,MAAA,GACX,KAAOA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAChB,kBAAoBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CACxC,OAASA,CAAAA,CAAAA,CAAE,KACTA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACP,MAAOA,CAAE,CAAA,MAAA,EACT,CAAA,OAAA,CAASA,CAAE,CAAA,MAAA,CAAO,CAChB,IAAA,CAAMA,EAAE,MAAO,EAAA,CACf,OAASA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,UAC/B,CAAA,UAAA,CAAY4C,EAAoC,CAAA,QAAA,EAChD,CAAA,OAAA,CAAS5C,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAAW,CAAA,QAAA,EACjC,CAAC,CACD,CAAA,QAAA,CAAU2C,GAAc,QAAS,EAAA,CACjC,aAAe3C,CAAAA,CAAAA,CAAE,MAAO,EAC1B,CAAC,CACH,CACA,CAAA,KAAA,CAAOA,CAAE,CAAA,MAAA,CAAO,CACd,aAAA,CAAeA,CAAE,CAAA,MAAA,GACjB,iBAAmBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAC5B,YAAcA,CAAAA,CAAAA,CAAE,MAAO,EACzB,CAAC,CACH,CAAC,CAAA,CAGK8C,EAAoC9C,CAAAA,CAAAA,CAAE,KAC1CA,CAAAA,CAAAA,CAAE,OAAO,CACP,KAAA,CAAOA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAClB,CAAA,EAAA,CAAIA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAC/B,KAAMA,CAAE,CAAA,IAAA,CAAK,CAAC,UAAU,CAAC,CAAA,CAAE,QAAS,EAAA,CACpC,QAAUA,CAAAA,CAAAA,CACP,MAAO,CAAA,CACN,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CACjC,SAAWA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EACjC,CAAC,CAAA,CACA,QAAS,EACd,CAAC,CACH,EAEM+C,EAA2B/C,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACxC,EAAIA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACb,MAAQA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACjB,OAASA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAClB,MAAOA,CAAE,CAAA,MAAA,EACT,CAAA,kBAAA,CAAoBA,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAC/B,CAAA,OAAA,CAASA,CAAE,CAAA,KAAA,CACTA,CAAE,CAAA,MAAA,CAAO,CACP,KAAA,CAAOA,EAAE,MAAO,EAAA,CAChB,KAAOA,CAAAA,CAAAA,CACJ,MAAO,CAAA,CACN,OAASA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CACxC,UAAY8C,CAAAA,EAAAA,CAAkC,UAC9C,CAAA,OAAA,CAAS9C,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAAW,CAAA,QAAA,EACjC,CAAC,CACA,CAAA,EAAA,CAAGA,CAAE,CAAA,MAAA,CAAO,EAAE,CAAC,CAClB,CAAA,QAAA,CAAU2C,EACV,CAAA,aAAA,CAAe3C,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAC5B,CAAC,CACH,CAAA,CACA,KAAOA,CAAAA,CAAAA,CACJ,MAAO,CAAA,CACN,cAAeA,CAAE,CAAA,MAAA,EACjB,CAAA,iBAAA,CAAmBA,CAAE,CAAA,MAAA,EACrB,CAAA,YAAA,CAAcA,CAAE,CAAA,MAAA,EAClB,CAAC,CACA,CAAA,QAAA,EACA,CAAA,QAAA,EACL,CAAC,EC3GKgD,IAAAA,EAAAA,CAAwBhD,CAAE,CAAA,MAAA,CAAO,CACrC,IAAA,CAAMA,CAAE,CAAA,OAAA,CAAQ,UAAU,CAAA,CAC1B,SAAUA,CAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,WAAaA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,EAAE,QAAS,EAAA,CACxC,MAAQA,CAAAA,CAAAA,CAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAC7B,UAAYA,CAAAA,CAAAA,CAAE,GAAI,EACpB,CAAC,CACH,CAAC,CAAA,CAGKiD,GAAkCjD,CAAE,CAAA,IAAA,CAAK,CAAC,MAAA,CAAQ,MAAQ,CAAA,UAAU,CAAC,CAAA,CAGrEkD,GAAsClD,CAAE,CAAA,MAAA,CAAO,CACnD,IAAA,CAAMA,CAAE,CAAA,OAAA,CAAQ,UAAU,CAAA,CAC1B,SAAUA,CAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CACxB,CAAC,CACH,CAAC,CAAA,CAGKmD,EAAkCnD,CAAAA,CAAAA,CACrC,OAAO,CACN,IAAA,CAAMA,CAAE,CAAA,IAAA,CAAK,CAAC,MAAA,CAAQ,aAAa,CAAC,CACtC,CAAC,CACA,CAAA,EAAA,CACCA,CAAE,CAAA,MAAA,CAAO,CACP,IAAA,CAAMA,EAAE,OAAQ,CAAA,aAAa,CAC7B,CAAA,WAAA,CAAaA,CAAE,CAAA,MAAA,CAAO,CACpB,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,WAAaA,CAAAA,CAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CACxC,MAAQA,CAAAA,CAAAA,CAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAC7B,MAAQA,CAAAA,CAAAA,CAAE,GAAI,EAChB,CAAC,CACH,CAAC,CACH,CAAA,CAGIoD,EAA+BpD,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC5C,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACtB,CAAA,IAAA,CAAMA,EAAE,OAAQ,CAAA,MAAM,CACxB,CAAC,CAGKqD,CAAAA,EAAAA,CAAgCrD,CAAE,CAAA,MAAA,CAAO,CAC7C,IAAA,CAAMA,CAAE,CAAA,OAAA,CAAQ,WAAW,CAAA,CAC3B,SAAWA,CAAAA,CAAAA,CAAE,OAAO,CAClB,GAAA,CAAKA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,GAAA,CAAI,CAAC,CAAA,CAC3B,MAAQA,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAAC,KAAO,CAAA,MAAA,CAAQ,MAAM,CAAC,CAAA,CAAE,QAAS,EACnD,CAAC,CACH,CAAC,CAAA,CAGKsD,EAAmCtD,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAChD,EAAIA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CACpB,IAAMA,CAAAA,CAAAA,CAAE,OAAQ,CAAA,UAAU,CAC1B,CAAA,QAAA,CAAUA,CAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CACtB,CAAA,SAAA,CAAWA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAC7B,CAAC,CACH,CAAC,CAAA,CAGKuD,EAAiCvD,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC9C,KAAMA,CAAE,CAAA,OAAA,CAAQ,QAAQ,CAAA,CACxB,OAASA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,EAAA,CAAGA,CAAE,CAAA,KAAA,CAAMoD,EAA4B,CAAA,CAAE,IAAI,CAAC,CAAC,CAC5E,CAAC,CAGKI,CAAAA,EAAAA,CAA+BxD,CAAE,CAAA,MAAA,CAAO,CAC5C,IAAA,CAAMA,CAAE,CAAA,OAAA,CAAQ,MAAM,CAAA,CACtB,OAASA,CAAAA,CAAAA,CACN,QACA,CAAA,GAAA,CAAI,CAAC,CAAA,CACL,EAAGA,CAAAA,CAAAA,CAAE,KAAMA,CAAAA,CAAAA,CAAE,KAAM,CAAA,CAACoD,EAA8BC,CAAAA,EAA6B,CAAC,CAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAC9F,CAAC,CAAA,CAGKI,EAAoCzD,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACjD,IAAMA,CAAAA,CAAAA,CAAE,OAAQ,CAAA,WAAW,CAC3B,CAAA,OAAA,CAASA,CAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAC,CAAE,CAAA,EAAA,CAAGA,CAAE,CAAA,KAAA,CAAMoD,EAA4B,CAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAAA,CAAE,QAAS,EAAA,CACrF,UAAYpD,CAAAA,CAAAA,CAAE,MAAMsD,EAAgC,CAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAC/D,CAAC,EAGKI,EAA+B1D,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC5C,IAAMA,CAAAA,CAAAA,CAAE,OAAQ,CAAA,MAAM,EACtB,YAAcA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAC9B,CAAA,OAAA,CAASA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAC3B,CAAC,CAAA,CAGK2D,GAA2B3D,CAAE,CAAA,KAAA,CAAM,CACvCuD,EAAAA,CACAC,EACAC,CAAAA,EAAAA,CACAC,EACF,CAAC,CAGKE,CAAAA,EAAAA,CAAoB5D,CAAE,CAAA,MAAA,CAAO,CACjC,KAAA,CAAOA,CAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EACzB,CAAA,QAAA,CAAUA,CAAE,CAAA,KAAA,CAAM2D,EAAwB,CAAA,CAAE,GAAI,CAAA,CAAC,CACjD,CAAA,iBAAA,CAAmB3D,CAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAA,CAAE,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CACjE,QAAUA,CAAAA,CAAAA,CAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAAE,UACjC,CAAA,YAAA,CAAcA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,GAAI,CAAA,EAAE,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACnD,CAAA,UAAA,CAAYA,EAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACzC,CAAA,gBAAA,CAAkBA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAE,CAAA,CAAA,CAAE,IAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAChE,eAAiBmD,CAAAA,EAAAA,CAAgC,QAAS,EAAA,CAC1D,IAAMnD,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,UAC5B,CAAA,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,EAAA,CAAGA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,MAAA,EAAQ,CAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAAA,CAAE,UAAW,CAAA,QAAA,EAC3D,CAAA,WAAA,CAAaA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,GACjD,KAAOA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CACpD,KAAOA,CAAAA,CAAAA,CAAE,MAAMgD,EAAqB,CAAA,CAAE,QAAS,EAAA,CAC/C,WAAaC,CAAAA,EAAAA,CAAgC,EAAGC,CAAAA,EAAmC,CAAE,CAAA,QAAA,EACvF,CAAC,EClHKW,IAAAA,EAAAA,CAA2BD,EAAkB,CAAA,IAAA,CAAK,CAAE,UAAA,CAAY,CAAK,CAAA,CAAC,CAAE,CAAA,MAAA,CAAO,CACnF,qBAAA,CAAuB5D,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACtD,CAAC,ECAD,IAAM8D,EAAkB,CAAA,QAAA,CAClBC,CAAN,CAAA,KAAoI,CAApI,WACE,EAAA,CAAA,IAAA,CAAS,OAAU,CAAA,IAAA,CACnB,IAAS,CAAA,IAAA,CAAOD,EAGhB,CAAA,IAAA,CAAiB,kBAOb,CAAA,CACF,CAAQE,EAAoB,EAAG,CAC7B,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAiB,EAAG,CAC1B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAA0B,EAAG,CACnC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAkB,EAAG,CAC3B,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAY,EAAG,CACrB,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAkB,EAAG,CAC3B,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAa,EAAG,CACtB,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAc,EAAG,CACvB,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAiB,EAAG,CAC1B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAS,EAAG,CAClB,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAoB,EAAG,CAC7B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACF,CAAA,CAEA,IAAiB,CAAA,uBAAA,CAOb,CACF,CAAQC,EAA4B,EAAG,CACrC,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACF,EAEA,CAAA,iBAAA,EAA8B,CAC5B,OAAO,MAAO,CAAA,IAAA,CAAK,KAAK,kBAAkB,CAC5C,CAEA,gBAAA,EAAwD,CACtD,OAAO,MAAO,CAAA,IAAA,CAAK,IAAK,CAAA,kBAAkB,CAAE,CAAA,MAAA,CAC1C,CAACC,CAAAA,CAAKC,CACJD,IAAAA,CAAAA,CAAIC,CAAG,CAAI,CAAA,IAAA,CAAK,kBAAmBA,CAAAA,CAAG,CAAE,CAAA,WAAA,CACjCD,CAET,CAAA,CAAA,EACF,CACF,CAEA,SAAA,CAAUE,CAAyB,CAAA,CACjC,IAAMC,CAAAA,CAAYD,EAAQ,SAC1B,CAAA,GAAI,EAAEC,CAAAA,IAAa,IAAK,CAAA,kBAAA,CAAA,CACtB,MAAM,IAAIC,cAAc,CACtB,IAAA,CAAM,CAAsBD,mBAAAA,EAAAA,CAAS,CACrC,UAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,sBAAsBA,CAAS,CAAA;AAAA,WAAA,EAC3C,KAAK,iBAAkB,EAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC7C,CAAC,EAGH,IAAME,CAAAA,CAAQ,KAAK,kBAAmBF,CAAAA,CAAS,EAAE,KAC3CG,CAAAA,CAAAA,CAAgB,KAAK,kBAAmBH,CAAAA,CAAS,EAAE,YAAa,CAAA,KAAA,CAAMD,CAAO,CACnF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CAEA,sBAAA,EAAmC,CACjC,OAAO,MAAA,CAAO,KAAK,IAAK,CAAA,uBAAuB,CACjD,CAEA,qBAAA,EAAkE,CAChE,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,uBAAuB,CAAE,CAAA,MAAA,CAC/C,CAACN,CAAKC,CAAAA,CAAAA,IACJD,EAAIC,CAAG,CAAA,CAAI,KAAK,uBAAwBA,CAAAA,CAAG,EAAE,WACtCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,cAAeE,CAAAA,CAAAA,CAA8B,CAC3C,IAAMC,CAAAA,CAAYD,EAAQ,SAC1B,CAAA,GAAI,EAAEC,CAAa,IAAA,IAAA,CAAK,yBACtB,MAAM,IAAIC,cAAc,CACtB,IAAA,CAAM,2BAA2BD,CAAS,CAAA,UAAA,CAAA,CAC1C,MAAO,IAAI,KAAA,CAAM,2BAA2BA,CAAS,CAAA;AAAA,WAChD,EAAA,IAAA,CAAK,sBAAuB,EAAA,CAAE,IAAK,CAAA,IAAI,CAAC,CAAG,CAAA,CAAA,CAClD,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAQ,KAAK,uBAAwBF,CAAAA,CAAS,CAAE,CAAA,KAAA,CAChDG,CAAgB,CAAA,IAAA,CAAK,uBAAwBH,CAAAA,CAAS,CAAE,CAAA,YAAA,CAAa,KAAMD,CAAAA,CAAO,CACxF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CACF,EArMMnG,CAAAA,CAGY,QAAU,2BCsD5B,CAAA,IAAMoG,CAAuBnK,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACpC,UAAWA,CAAE,CAAA,MAAA,EACb,CAAA,MAAA,CAAQA,CAAE,CAAA,MAAA,EACV,CAAA,OAAA,CAASA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,QAAA,GAC1B,eAAiBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,UAClC,CAAA,aAAA,CAAeA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,GAAM,QAAS,EAAA,CACzC,YAAcA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EACpC,CAAC,CAAA,CAGKoK,CAAN,CAAA,KAAgE,CAW9D,WAAA,CAAYC,EAAkCP,CAAmC,CAAA,CAVjF,IAAS,CAAA,OAAA,CAAU,IAWjB,CAAA,IAAMI,EAAgBC,CAAqB,CAAA,KAAA,CAAML,CAAO,CAAA,CACxD,IAAK,CAAA,WAAA,CAAcO,EACnB,IAAK,CAAA,SAAA,CAAYH,CAAc,CAAA,SAAA,CAC/B,IAAK,CAAA,MAAA,CAASA,CAAc,CAAA,MAAA,CAC5B,IAAK,CAAA,OAAA,CAAUI,uBAAwBJ,CAAAA,CAAAA,CAAc,OAAWnG,EAAAA,CAAAA,CAAO,OAAO,CAC9E,CAAA,IAAA,CAAK,aAAgBuG,CAAAA,uBAAAA,CAAwBJ,CAAc,CAAA,aAAA,EAAiB,GAAG,IAAK,CAAA,OAAO,CAAmB,iBAAA,CAAA,CAAA,CAC9G,IAAK,CAAA,eAAA,CAAkBI,wBAAwBJ,CAAc,CAAA,eAAA,EAAmB,CAAG,EAAA,IAAA,CAAK,OAAO,CAAA,iBAAA,CAAmB,CAClH,CAAA,IAAA,CAAK,YAAeA,CAAAA,CAAAA,CAAc,aACpC,CAEA,iBAA6B,EAAA,CAC3B,OAAO,IAAK,CAAA,OACd,CAEA,iBAAA,EAAiC,CAC/B,OAAOzJ,EAAA,CACL,aAAA,CAAe,CAAU,OAAA,EAAA,IAAA,CAAK,MAAM,CAAA,CAAA,CACpC,eAAgB,kBACZ,CAAA,CAAA,IAAA,CAAK,YAAe,CAAA,CAAE,qBAAuB,CAAA,IAAA,CAAK,YAAa,CAAA,CAAI,EAAC,CAE5E,CAEA,gBAAA,EAA+B,CAC7B,OAAO,CACL,KAAO,CAAA,IAAA,CAAK,SACd,CACF,CAQA,aAAA,CAAc8J,EAAyE,CAErF,IAAMC,CAAiBC,CAAAA,CAAAA,EAA6B,CAClD,IAAMC,EAAQ,kBACRC,CAAAA,CAAAA,CAAwC,CAC5C,CAAA,CAAG,IACH,CAAA,CAAA,CAAG,GACH,CAAA,CAAA,CAAG,GACH,CAAA,EAAA,CAAI,CACN,CAAA,CAEIC,CACAC,CAAAA,CAAAA,CAAU,EACd,KAAQD,CAAAA,CAAAA,CAAQF,CAAM,CAAA,IAAA,CAAKD,CAAQ,CAAA,IAAO,MAAM,CAC9C,IAAMxK,CAAQ,CAAA,QAAA,CAAS2K,CAAM,CAAA,CAAC,CAAC,CACzBE,CAAAA,CAAAA,CAAOF,CAAM,CAAA,CAAC,CACpBC,CAAAA,CAAAA,EAAW5K,CAAQ0K,CAAAA,CAAAA,CAAUG,CAAI,EACnC,CAEA,OAAOD,CACT,CAAA,CAEIE,EAAuB,CACvBC,CAAAA,CAAAA,CAAqB,CACnBC,CAAAA,CAAAA,CAAc,CAChBV,CAAAA,CAAAA,CAAAA,CAAgB,4BAA4B,CAC9CQ,GAAAA,CAAAA,CAAuBP,CAAcD,CAAAA,CAAAA,CAAgB,4BAA4B,CAAC,GAEhFA,CAAgB,CAAA,0BAA0B,CAC5CS,GAAAA,CAAAA,CAAqBR,CAAcD,CAAAA,CAAAA,CAAgB,0BAA0B,CAAC,CAIhF,CAAA,CAAA,IAAMW,CAAU,CAAA,IAAA,CAAK,GAAIH,CAAAA,CAAAA,CAAsBC,CAAkB,CACjE,CAAA,OAAO,CAAE,WAAA,CAAAC,CAAa,CAAA,OAAA,CAAAC,CAAQ,CAChC,CAEA,aAAcC,CAAAA,CAAAA,CAAiC,CAC7C,OAAOA,EAAS,MAAO,CAAA,CAACvB,CAAKwB,CAAAA,CAAAA,GACpBxB,CAAMwB,CAAAA,CAAAA,CAAQ,OAAQ,CAAA,GAAA,CAAKC,CAAaA,EAAAA,CAAAA,CAAQ,QAAa,GAAA,MAAA,CAASA,CAAQ,CAAA,KAAA,CAAQ,EAAG,CAAE,CAAA,IAAA,CAAK,GAAG,CAAA,CAAE,MAC3G,CAAA,CAAC,CACN,CAEA,qBAAA,CAAsBC,CAKpB,CAAA,CACA,IAAMC,CAAAA,CAAc3H,GAAkB,SAAU0H,CAAAA,CAAO,CACvD,CAAA,GAAI,CAACC,CAAAA,CAAY,OACf,CAAA,MAAM,IAAIC,wBAAAA,CAAyB,CAAE,IAAA,CAAM,uBAAyB,CAAA,KAAA,CAAOD,EAAY,KAAM,CAAC,CAGhG,CAAA,IAAME,CAAgBF,CAAAA,CAAAA,CAAY,KAE5BxB,CAAY0B,CAAAA,CAAAA,CAAc,KAEhC,CAAA,GAAIA,CAAc,CAAA,WAAA,GAAgB,CAACA,CAAc,CAAA,KAAA,EAASA,CAAc,CAAA,KAAA,CAAM,MAAW,GAAA,CAAA,CAAA,CACvF,MAAM,IAAID,wBAAyB,CAAA,CACjC,IAAM,CAAA,CAAA,mCAAA,EAAsC,IAAK,CAAA,SAAS,IAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,sDAAsD,CACzE,CAAC,EAGH,IAAME,CAAAA,CAAsB,EAAC,CACzBD,CAAc,CAAA,eAAA,GAChBC,EAAQ,cAAiBD,CAAAA,CAAAA,CAAc,eAAgB,CAAA,IAAA,CACnDA,CAAc,CAAA,eAAA,CAAgB,IAAS,GAAA,aAAA,GACzCC,CAAQ,CAAA,cAAA,CAAiB,CACvB,IAAA,CAAMD,CAAc,CAAA,eAAA,CAAgB,YAAY,IAChD,CAAA,WAAA,CAAaA,CAAc,CAAA,eAAA,CAAgB,WAAY,CAAA,WAAA,EAAe,GACtE,MAAQA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,MAClD,CAAA,MAAA,CAAQA,EAAc,eAAgB,CAAA,WAAA,CAAY,MACpD,CAAA,CAAA,CAAA,CAIAA,CAAc,CAAA,WAAA,GACZ,OAAOA,CAAAA,CAAc,WAAgB,EAAA,QAAA,CACvCC,CAAQ,CAAA,UAAA,CAAaD,CAAc,CAAA,WAAA,CAEnCC,EAAQ,UAAaD,CAAAA,CAAAA,CAAc,WAAY,CAAA,QAAA,CAAS,IAI5DC,CAAAA,CAAAA,CAAAA,CAAQ,KAAOD,CAAc,CAAA,IAAA,CAC7BC,CAAQ,CAAA,SAAA,CAAYD,CAAc,CAAA,UAAA,CAClCC,EAAQ,WAAcD,CAAAA,CAAAA,CAAc,WACpCC,CAAAA,CAAAA,CAAQ,IAAOD,CAAAA,CAAAA,CAAc,KAC7BC,CAAAA,CAAAA,CAAQ,eAAkBD,CAAAA,CAAAA,CAAc,gBACxCC,CAAAA,CAAAA,CAAQ,gBAAmBD,CAAAA,CAAAA,CAAc,kBACzCC,CAAQ,CAAA,IAAA,CAAOD,CAAc,CAAA,IAAA,CAC7BC,CAAQ,CAAA,QAAA,CAAWD,EAAc,QACjCC,CAAAA,CAAAA,CAAQ,WAAcD,CAAAA,CAAAA,CAAc,YAEpC,CAAA,IAAME,EAASC,MAAO,EAAA,CAAE,KAAMC,CAAAA,sBAAAA,CAAuBH,CAAO,CAAC,CAEvDP,CAAAA,CAAAA,CAA0B,EAAC,CAC3BW,CAAqD,CAAA,EAC3DL,CAAAA,CAAAA,CAAc,SAAS,OAASL,CAAAA,CAAAA,EAAY,CAC1C,IAAMW,CAAOX,CAAAA,CAAAA,CAAQ,KACrB,OAAQW,CAAAA,EACN,IAAK,QACH,CAAA,CACE,IAAMV,CAAUD,CAAAA,CAAAA,CAAQ,OACxB,CAAA,GAAI,OAAOC,CAAAA,EAAY,QACrBF,CAAAA,CAAAA,CAAS,IAAK,CAAA,CACZ,IAAMY,CAAAA,CAAAA,CACN,OAAS,CAAA,CAAC,CAAE,QAAU9J,CAAAA,mBAAAA,CAAqB,KAAOoJ,CAAAA,CAAQ,CAAC,CAC7D,CAAC,CACI,CAAA,KAAA,CACL,IAAMW,CAAAA,CAAWX,CAAQ,CAAA,GAAA,CAAKY,IACrB,CAAE,QAAA,CAAUhK,mBAAqB,CAAA,KAAA,CAAOgK,CAAE,CAAA,IAAK,CACvD,CAAA,CAAA,CACDd,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMY,CAAM,CAAA,OAAA,CAASC,CAAS,CAAC,EACjD,CACF,CACA,MAEF,IAAK,OACH,CACE,IAAMX,CAAUD,CAAAA,CAAAA,CAAQ,OACxB,CAAA,GAAI,OAAOC,CAAY,EAAA,QAAA,CACrBF,CAAS,CAAA,IAAA,CAAK,CACZ,IAAA,CAAMY,CACN,CAAA,OAAA,CAAS,CAAC,CAAE,QAAU9J,CAAAA,mBAAAA,CAAqB,KAAOoJ,CAAAA,CAAQ,CAAC,CAC7D,CAAC,CACI,CAAA,KAAA,CACL,IAAMW,CAAAA,CAAWX,EAAQ,GAAKY,CAAAA,CAAAA,EACxBA,CAAE,CAAA,IAAA,GAAS,MACN,CAAA,CAAE,SAAUhK,mBAAqB,CAAA,KAAA,CAAOgK,CAAE,CAAA,IAAK,CAElDA,CAAAA,CAAAA,CAAE,SAAU,CAAA,GAAA,CAAI,UAAW,CAAA,OAAO,CAC7B,CAAA,CACL,QAAU/J,CAAAA,oBAAAA,CACV,OAAQ+J,CAAE,CAAA,SAAA,CAAU,MAAU,EAAA,MAAA,CAC9B,KAAO,CAAA,CACL,KAAMC,6BACN,CAAA,MAAA,CAAQD,CAAE,CAAA,SAAA,CAAU,GACpB,CAAA,UAAA,CAAYE,sBAAsBF,CAAE,CAAA,SAAA,CAAU,GAAG,CACnD,CACF,CAAA,CAEO,CACL,QAAA,CAAU/J,oBACV,CAAA,MAAA,CAAQ+J,CAAE,CAAA,SAAA,CAAU,MAAU,EAAA,MAAA,CAC9B,MAAO,CAAE,IAAA,CAAMG,0BAA4B,CAAA,GAAA,CAAKH,CAAE,CAAA,SAAA,CAAU,GAAI,CAClE,CAGL,CACDd,CAAAA,CAAAA,CAAS,IAAK,CAAA,CAAE,KAAMY,CAAM,CAAA,OAAA,CAASC,CAAS,CAAC,EACjD,CACF,CACA,MAEF,IAAK,WAAA,CACH,CACE,IAAMK,CAAkC,CAAA,GAExC,GAAI,CAACjB,CAAQ,CAAA,OAAA,EAAW,CAACA,CAAAA,CAAQ,WAC/B,MAAM,IAAII,wBAAyB,CAAA,CACjC,IAAM,CAAA,CAAA,mCAAA,EAAsC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,kDAAkD,CACrE,CAAC,CAGH,CAAA,GAAIJ,CAAQ,CAAA,OAAA,CAAS,CACnB,IAAMC,EAAUD,CAAQ,CAAA,OAAA,CACpB,OAAOC,CAAAA,EAAY,QACrBgB,CAAAA,CAAAA,CAAiB,KAAK,CAAE,QAAA,CAAUpK,mBAAqB,CAAA,KAAA,CAAOoJ,CAAQ,CAAC,EAEvEA,CAAQ,CAAA,OAAA,CAASY,CAAM,EAAA,CACrBI,CAAiB,CAAA,IAAA,CAAK,CAAE,QAAA,CAAUpK,mBAAqB,CAAA,KAAA,CAAOgK,CAAE,CAAA,IAAK,CAAC,EACxE,CAAC,EAEL,CAEIb,CAAQ,CAAA,UAAA,EACQA,CAAQ,CAAA,UAAA,CAChB,QAAQ,CAACkB,CAAAA,CAAUC,EAAU,GAAA,CACrC,IAAMC,EAAAA,CAAuC,CAC3C,QAAUrK,CAAAA,uBAAAA,CACV,EAAImK,CAAAA,CAAAA,CAAS,EACb,CAAA,KAAA,CAAOC,EACP,CAAA,IAAA,CAAMD,CAAS,CAAA,QAAA,CAAS,IACxB,CAAA,SAAA,CAAWA,CAAS,CAAA,QAAA,CAAS,SAC/B,CACAD,CAAAA,CAAAA,CAAiB,IAAKG,CAAAA,EAAe,CACrCV,CAAAA,CAAAA,CAAYU,GAAgB,EAAE,CAAA,CAAIA,GACpC,CAAC,CAEHrB,CAAAA,CAAAA,CAAS,KAAK,CAAE,IAAA,CAAMY,CAAM,CAAA,OAAA,CAASM,CAAiB,CAAC,EACzD,CACA,MAEF,IAAK,MACH,CAAA,CACE,IAAMI,CAAAA,CAAerB,EACrBD,CAAS,CAAA,IAAA,CAAK,CACZ,IAAA,CAAMY,CACN,CAAA,OAAA,CAAS,CACP,CACE,QAAA,CAAU3J,2BACV,CAAA,EAAA,CAAIqK,CAAa,CAAA,YAAA,CACjB,MAAOX,CAAYW,CAAAA,CAAAA,CAAa,YAAY,CAAA,CAAE,KAC9C,CAAA,IAAA,CAAMX,CAAYW,CAAAA,CAAAA,CAAa,YAAY,CAAA,CAAE,IAC7C,CAAA,IAAA,CAAMA,CAAa,CAAA,OACrB,CACF,CACF,CAAC,EACH,CACA,KACJ,CACF,CAAC,CAED,CAAA,IAAMC,CAAoB,CAAA,EAC1B,CAAA,OAAIjB,EAAc,KAChBA,EAAAA,CAAAA,CAAc,KAAM,CAAA,OAAA,CAASkB,CAAoC,EAAA,CAC/DD,CAAM,CAAA,IAAA,CAAK,CACT,IAAA,CAAM,UACN,CAAA,UAAA,CAAY,CACV,MAAA,CAAQ,CACN,IAAMC,CAAAA,CAAAA,CAAK,QAAS,CAAA,IAAA,CACpB,WAAaA,CAAAA,CAAAA,CAAK,SAAS,WAAe,EAAA,EAAA,CAC1C,MAAQA,CAAAA,CAAAA,CAAK,QAAS,CAAA,MAAA,CACtB,WAAYA,CAAK,CAAA,QAAA,CAAS,UAC5B,CACF,CACF,CAAC,EACH,CAAC,CAGI,CAAA,CACL,SAAA5C,CAAAA,CAAAA,CACA,MAAA4B,CAAAA,CAAAA,CACA,SAAAR,CACA,CAAA,KAAA,CAAOuB,CAAM,CAAA,MAAA,CAAS,CAAIA,CAAAA,CAAAA,CAAQ,MACpC,CACF,CAGA,eAAgBf,CAAAA,CAAAA,CAAoBR,CAA0BuB,CAAAA,CAAAA,CAAgC,CAC5F,IAAME,CAAAA,CAAcjB,CAAO,CAAA,UAAA,CAC3B,OAAOA,CAAAA,CAAO,UAEd,CAAA,IAAMkB,CAAgB,CAAA,IAAA,CAAK,WAAY,CAAA,MAAA,CAAO,MAAO,CAAA,SAAA,CAAUlB,CAAM,CACrE,CAAA,GAAI,CAACkB,CAAAA,CAAc,OACjB,CAAA,MAAM,IAAIC,kBAAmB,CAAA,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,SAAS,IACnD,KAAOD,CAAAA,CAAAA,CAAc,KACvB,CAAC,CAGH,CAAA,IAAME,CAAeF,CAAAA,CAAAA,CAAc,IAC/BD,CAAAA,CAAAA,GAAgB,KAClBG,CAAAA,GAAAA,CAAAA,CAAa,UAAaH,CAAAA,CAAAA,CAAAA,CAG5B,OAAO,IAAKG,CAAAA,CAAY,CAAE,CAAA,OAAA,CAASlD,CAAQ,EAAA,CACzC,GAAI,EAAEA,CAAAA,IAAO,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,GAAA,CAAA,CACnC,MAAM,IAAIiD,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CACnD,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,sBAAA,EAAyBjD,CAAG,CAAA;AAAA,8BAAA,EACvB,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,MAAO,CAAA,GAAG,EAAE,IAAK,CAAA,IAAI,CAAC,CAAA,CAAA,CAAG,CAC9E,CAAC,CAEL,CAAC,CAED,CAAA,IAAMmD,EAAoB,MAAO,CAAA,IAAA,CAAKD,CAAY,CAAA,CAAE,OAAO,CAACnD,CAAAA,CAAKC,IAAQ,CACvE,IAAMoD,EAAM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIpD,CAAAA,CAAG,EACrCqD,CAAWD,CAAAA,CAAAA,CAAI,MACfE,CAAcJ,CAAAA,CAAAA,CAA4BlD,CAAG,CAEnD,CAAA,OAAIqD,CAAa,GAAA,YAAA,EAAgBD,EAAI,IAAS,GAAA,OAAA,EAAWE,IAAe,CACtEvD,CAAAA,CAAAA,CAAIsD,CAAQ,CAAID,CAAAA,CAAAA,CAAI,GAEpBrD,CAAAA,CAAAA,CAAIsD,CAAQ,CAAIC,CAAAA,CAAAA,CAGXvD,CACT,CAAG,CAAA,EAAgB,CAEnB,CAAA,GAAIoD,CAAkB,CAAA,YAAA,EAAgB,CAACA,CAAkB,CAAA,QAAA,CACvD,MAAM,IAAIF,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAO,IAAI,KAAA,CAAM,4DAA4D,CAC/E,CAAC,EAGH,GAAI,aAAA,GAAiBE,CAAqBA,EAAAA,CAAAA,CAAkB,cAAgB,KAAW,CAAA,CAAA,CACrF,IAAMnN,CAAamN,CAAAA,CAAAA,CAAkB,YACrC,GAAI,CAACN,CAAUA,EAAAA,CAAAA,EAASA,EAAM,MAAW,GAAA,CAAA,CACvC,MAAM,IAAII,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,SAAS,IACnD,KAAO,CAAA,IAAI,MAAM,qDAAqD,CACxE,CAAC,CACI,CAAA,GAAIJ,GAASA,CAAM,CAAA,MAAA,CAAS,EAAG,CACpC,IAAMU,EAAmB,IAAK,CAAA,WAAA,CAAY,OAAO,GAAI,CAAA,UAAA,CACrD,GAAI,CAACA,EAAiB,OAAQ,CAAA,QAAA,CAASvN,CAAU,CAC/C,CAAA,GAAI6M,EAAM,GAAKC,CAAAA,CAAAA,EAASA,CAAK,CAAA,UAAA,CAAW,OAAO,IAAI,CAAA,CAAE,SAAS9M,CAAU,CAAA,CACtEmN,EAAkB,WAAc,CAAA,CAAE,IAAM,CAAA,UAAA,CAAY,SAAU,CAAE,IAAA,CAAMnN,CAAW,CAAE,CAAA,CAAA,WAE7E,IAAIiN,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAO,IAAI,KAAA,CAAM,iBAAiBjN,CAAU,CAAA;AAAA,wBAAA,EAChCuN,CAAiB,CAAA,OAAA,CAAQ,IAAK,CAAA,IAAI,CAAC,CAAG,CAAA,CAAA,CACpD,CAAC,CAGP,CACF,CAEA,GAAI,iBAAqBJ,GAAAA,CAAAA,EAAqBA,EAAkB,eAAoB,GAAA,KAAA,CAAA,CAAW,CAC7F,IAAM1M,CAAiB0M,CAAAA,CAAAA,CAAkB,eACzC,CAAA,GAAI1M,IAAmB,aACrB,CAAA,GAAM,iBAAqB0M,GAAAA,CAAAA,CAMzBA,EAAkB,eAAkB,CAAA,CAClC,IAAM,CAAA,aAAA,CACN,YAAaA,CAAkB,CAAA,eACjC,CACA,CAAA,OAAOA,CAAkB,CAAA,eAAA,CAAA,KATnB,MAAA,IAAIF,mBAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,+EAA+E,CAClG,CAAC,CASHE,CAAAA,KAAAA,CAAAA,CAAkB,gBAAkB,CAAE,IAAA,CAAM1M,CAAe,EAE/D,CAEA,OAAO0M,CACT,CAEA,iBAAA,CAAkB7B,EAAqC,CACrD,GAAI,CAACA,CAAAA,EAAaA,GAAYA,CAAS,CAAA,MAAA,GAAW,CAChD,CAAA,OAAO,CAAE,QAAA,CAAU,EAAG,EAGxB,IAAMkC,CAAAA,CAAiBlC,CAAS,CAAA,GAAA,CAAKC,GAAY,CAC/C,IAAMkC,CAAgBC,CAAAA,OAAAA,GAAU,SAAUnC,CAAAA,CAAO,CACjD,CAAA,GAAI,CAACkC,CAAc,CAAA,OAAA,CACjB,MAAM,IAAIE,qBAAqB,CAAE,IAAA,CAAM,kBAAoB,CAAA,KAAA,CAAOF,EAAc,KAAM,CAAC,CAEzF,CAAA,OAAOA,EAAc,IACvB,CAAC,CAED,CAAA,OAAAD,CAAe,CAAA,OAAA,CAASjC,CAAY,EAAA,CAClCA,EAAQ,OAAQ,CAAA,OAAA,CAASC,CAAY,EAAA,CACnC,GAAI,CAAC,IAAA,CAAK,WAAY,CAAA,UAAA,CAAW,SAASA,CAAQ,CAAA,QAAQ,CACxD,CAAA,MAAM,IAAImC,oBAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,KAAO,CAAA,IAAI,MAAM,CAAY,SAAA,EAAA,IAAA,CAAK,SAAS,CAAA,+BAAA,EAAkCnC,EAAQ,QAAQ,CAAA;AAAA,sCACjE,EAAA,IAAA,CAAK,YAAY,UAAW,CAAA,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACvE,CAAC,CAEL,CAAC,EACH,CAAC,EAEDgC,CAAe,CAAA,OAAA,CAASjC,GAAY,CAClC,GAAI,CAAC,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,SAASA,CAAQ,CAAA,IAAI,EAC5D,MAAM,IAAIoC,oBAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,MAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAA8BpC,2BAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAAA;AAAA,+BAAA,EAC9D,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC1E,CAAC,CAEL,CAAC,CAAA,CAiHM,CAAE,QA/GmBiC,CAAAA,CAAAA,CAAe,IAAKjC,CAAY,EAAA,CAC1D,OAAQA,CAAQ,CAAA,IAAA,EACd,KAAK3J,iBAAAA,CAAmB,CACtB,IAAMgM,CAAAA,CAAgD,EACtD,CAAA,OAAArC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAapJ,GAAAA,mBAAAA,CACvBwL,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,OAEhD,MAAA,IAAImC,qBAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWpC,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EAEM,CACL,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMD,EAAQ,IAAI,CAAA,CACzC,QAASqC,CACX,CACF,CAEA,KAAK9L,oBAAAA,CAAsB,CACzB,IAAM8L,CAAAA,CAAgD,EAChDC,CAAAA,CAAAA,CAA+F,EACrG,CAAA,OAAAtC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAapJ,GAAAA,mBAAAA,CACvBwL,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,UAC7CA,CAAQ,CAAA,QAAA,GAAalJ,wBAC9BuL,CAAU,CAAA,IAAA,CAAK,CACb,EAAIrC,CAAAA,CAAAA,CAAQ,GACZ,IAAM,CAAA,UAAA,CACN,SAAU,CAAE,IAAA,CAAMA,EAAQ,IAAM,CAAA,SAAA,CAAWA,EAAQ,SAAU,CAC/D,CAAC,CAED,CAAA,KAAA,MAAM,IAAImC,oBAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA,uCAAA,EAA0CC,EAAQ,QAAQ,CAAA,CAAA,CAAG,CACvG,CAAC,CAEL,CAAC,CAEM5K,CAAAA,CAAAA,CAAA,CACL,IAAM,CAAA,IAAA,CAAK,YAAY,KAAM2K,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,OAAA,CAASqC,GACLC,CAAU,CAAA,MAAA,CAAS,EAAI,CAAE,UAAA,CAAYA,CAAU,CAAI,CAAA,GAE3D,CAEA,KAAKhM,gBAAiB,CACpB,IAAM+L,EAAgD,EAAC,CACjDE,EAAoF,EAAC,CAC3FvC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAapJ,GAAAA,mBAAAA,CACvBwL,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,UAC7CA,CAAQ,CAAA,QAAA,GAAanJ,qBAC9ByL,CAAa,CAAA,IAAA,CAAK,CAChB,IAAM,CAAA,WAAA,CACN,UAAW,CACT,GAAA,CAAKtC,EAAQ,KAAM,CAAA,IAAA,GAAS,MAAQA,CAAQ,CAAA,KAAA,CAAM,IAAMA,CAAQ,CAAA,KAAA,CAAM,OACtE,MAAQA,CAAAA,CAAAA,CAAQ,MAClB,CACF,CAAC,OAEK,MAAA,IAAImC,qBAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWpC,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EAED,IAAMuC,CAAAA,CAAkB,CAAC,GAAGH,CAAAA,CAAa,GAAGE,CAAY,CAAA,CAExD,OAAO,CACL,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMvC,EAAQ,IAAI,CAAA,CACzC,QAASwC,CACX,CACF,CAEA,KAAKhM,eAAAA,CAAiB,CACpB,GAAIwJ,CAAAA,CAAQ,QAAQ,MAAW,GAAA,CAAA,CAC7B,MAAM,IAAIoC,oBAAAA,CAAqB,CAC7B,IAAM,CAAA,CAAA,4BAAA,EAA+BpC,EAAQ,IAAI,CAAA,CAAA,CAAA,CACjD,MAAO,IAAI,KAAA,CAAM,WAAWA,CAAQ,CAAA,IAAI,sCAAsC,CAChF,CAAC,EAGH,GAAIA,CAAAA,CAAQ,QAAQ,CAAC,CAAA,CAAE,WAAahJ,2BAClC,CAAA,MAAM,IAAIoL,oBAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA,qCAAA,EAAwChJ,2BAA2B,CAAG,CAAA,CAAA,CAChH,CAAC,CAGH,CAAA,IAAMqK,EAAerB,CAAQ,CAAA,OAAA,CAAQ,CAAC,CACtC,CAAA,OAAO,CACL,IAAM,CAAA,IAAA,CAAK,YAAY,KAAMA,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,YAAA,CAAcqB,EAAa,EAC3B,CAAA,OAAA,CAASA,EAAa,IACxB,CACF,CAEA,QACE,MAAM,IAAIe,oBAAqB,CAAA,CAC7B,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAC1D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA;AAAA,iCAAA,EACjB,MAAO,CAAA,IAAA,CAAK,IAAK,CAAA,WAAA,CAAY,KAAK,CAAE,CAAA,IAAA,CAAK,IAAI,CAAC,CAAG,CAAA,CAAA,CAC1E,CAAC,CAEL,CACF,CAAC,CAEsC,CACzC,CAEA,cAAesB,CAAAA,CAAAA,CAA+B,CAC5C,GAAI,CAAC,IAAK,CAAA,WAAA,CAAY,UAAW,CAAA,QAAA,CAASvK,uBAAuB,CAAA,CAC/D,MAAM,IAAI0L,kBAAkB,CAC1B,IAAA,CAAM,CAAuC,oCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAC3D,KAAO,CAAA,IAAI,MAAM,CAAY,SAAA,EAAA,IAAA,CAAK,SAAS,CAAA,oCAAA,EAAuC1L,uBAAuB,CAAA,CAAA,CAAG,CAC9G,CAAC,EAGH,OAAI,CAACuK,CAAUA,EAAAA,CAAAA,EAASA,CAAM,CAAA,MAAA,GAAW,CAChC,CAAA,CAAE,MAAO,EAAiB,CAgB5B,CAAA,CAAE,KAbWA,CAAAA,CAAAA,CAAM,GAAKC,CAAAA,CAAAA,EAAS,CACtC,IAAMmB,CAAAA,CAAaC,IAAK,EAAA,CAAE,SAAUpB,CAAAA,CAAI,CACxC,CAAA,GAAI,CAACmB,CAAW,CAAA,OAAA,CACd,MAAM,IAAID,iBAAkB,CAAA,CAAE,IAAM,CAAA,eAAA,CAAiB,MAAOC,CAAW,CAAA,KAAM,CAAC,CAAA,CAEhF,OAAOA,CAAAA,CAAW,IACpB,CAAC,EAEoC,GAAKnB,CAAAA,CAAAA,GAAU,CAClD,IAAA,CAAM,UACN,CAAA,QAAA,CAAUA,CAAK,CAAA,UAAA,CAAW,MAC5B,CAAE,CAAA,CAE+B,CACnC,CAGM,kBAAmBhB,CAAAA,CAAAA,CAAqBR,CAA0BuB,CAAAA,CAAAA,CAAsC,QAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAAA,CAAQ,KAAK,eAAe,EAC9B,CAAC,CACH,CAGM,CAAA,CAAA,sBAAA,CAAuBtC,CAAqBR,CAAAA,CAAAA,CAA0BuB,EAA0C,CAAAsB,OAAAA,CAAAA,CAAA,IACpH,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAAA,CAAQ,KAAK,iBAAkB,EAAC,EAClC,CAAC,CACH,CAAA,CAAA,CAEM,mBAAoBtC,CAAAA,CAAAA,CAAoBR,EAAyBuB,CAAyC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC9G,IAAMhB,CAAAA,CAAoB,IAAK,CAAA,eAAA,CAAgBrB,EAAQR,CAAUuB,CAAAA,CAAK,CAChEwB,CAAAA,CAAAA,CAAsB,IAAK,CAAA,iBAAA,CAAkB/C,CAAQ,CAAA,CAC3D,GAAI+C,CAAoB,CAAA,QAAA,EAAaA,CAAoB,CAAA,QAAA,CAA2B,MAAW,GAAA,CAAA,CAC7F,MAAM,IAAIV,qBAAqB,CAC7B,IAAA,CAAM,uBACN,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,uBAAuB,CAC1C,CAAC,CAGH,CAAA,IAAMW,CAAmBzB,CAAAA,CAAAA,CAAQ,IAAK,CAAA,cAAA,CAAeA,CAAK,CAAA,CAAI,EAE9D,CAAA,OAAO,IAAI,OAAA,CAASuB,CAAY,EAAA,CAC9BA,CAAQxN,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,GACH,IAAK,CAAA,gBAAA,EACLuM,CAAAA,CAAAA,CAAAA,CAAAA,CACAkB,CACAC,CAAAA,CAAAA,CAAAA,CACJ,EACH,CAAC,CACH,CAEA,CAAA,CAAA,6BAAA,CAA8BC,CAAiC,CAAA,CAC7D,IAAMC,CAAAA,CAAOxL,EAA2B,CAAA,SAAA,CAAUuL,CAAQ,CAC1D,CAAA,GAAIC,CAAK,CAAA,OAAA,CAAS,CAChB,GAAIA,CAAK,CAAA,IAAA,CAAK,QAAQ,MAAW,GAAA,CAAA,CAC/B,MAAM,IAAIC,kBAAmB,CAAA,CAC3B,IAAM,CAAA,6BAAA,CACN,MAAO,IAAI,KAAA,CAAM,CAA4B,yBAAA,EAAA,IAAA,CAAK,SAAUD,CAAAA,CAAAA,CAAK,IAAI,CAAC,EAAE,CAC1E,CAAC,CAGH,CAAA,IAAME,CAAiDF,CAAAA,CAAAA,CAAK,IACtDlD,CAAAA,CAAAA,CAA0B,CAC9B,CACE,IAAA,CAAMxJ,oBACN,CAAA,OAAA,CAAS,EACX,CACF,CAAA,CACMyJ,EAAUmD,CAAe,CAAA,OAAA,CAAQ,CAAC,CAAA,CAAE,OACtCnD,CAAAA,CAAAA,CAAQ,OACVD,EAAAA,CAAAA,CAAS,CAAC,CAAE,CAAA,OAAA,CAAQ,IAAKqD,CAAAA,iBAAAA,CAAkBpD,EAAQ,OAAO,CAAC,CAGzDA,CAAAA,CAAAA,CAAQ,SACVD,CAAS,CAAA,CAAC,CAAE,CAAA,OAAA,CAAQ,IAAKqD,CAAAA,iBAAAA,CAAkBpD,CAAQ,CAAA,OAAO,CAAC,CAGzDA,CAAAA,CAAAA,CAAQ,UACVA,EAAAA,CAAAA,CAAQ,UAAW,CAAA,OAAA,CAAQ,CAACkB,CAAAA,CAAUC,IAAU,CAC9CpB,CAAAA,CAAS,CAAC,CAAA,CAAE,OAAQ,CAAA,IAAA,CAClBsD,qBACElC,CAAAA,CAAAA,CACAD,EAAS,EACTA,CAAAA,CAAAA,CAAS,QAAS,CAAA,IAAA,CAClBA,CAAS,CAAA,QAAA,CAAS,SACpB,CACF,EACF,CAAC,CAAA,CAGH,IAAMoC,CAAAA,CAAuB,CAC3B,YAAA,CAAcH,CAAe,CAAA,KAAA,CAAM,cACnC,gBAAkBA,CAAAA,CAAAA,CAAe,KAAM,CAAA,iBAAA,CACvC,WAAaA,CAAAA,CAAAA,CAAe,KAAM,CAAA,YACpC,EAEM7O,CAA6B,CAAA,EAC7BiP,CAAAA,CAAAA,CAAYJ,CAAe,CAAA,OAAA,CAAQ,CAAC,CAAA,CAAE,SAC5C,OAAII,CAAAA,GACEA,CAAU,CAAA,OAAA,EACZjP,CAAS,CAAA,IAAA,CACP,GAAGiP,CAAAA,CAAU,QAAQ,GAAKC,CAAAA,CAAAA,GAAa,CACrC,KAAA,CAAOA,CAAQ,CAAA,KAAA,CACf,OAASA,CAAAA,CAAAA,CAAQ,QACjB,KAAOA,CAAAA,CAAAA,CAAQ,KACf,CAAA,WAAA,CAAaA,CAAQ,CAAA,YAAA,CAAa,GAAKC,CAAAA,CAAAA,GAAgB,CACrD,KAAOA,CAAAA,CAAAA,CAAW,KAClB,CAAA,OAAA,CAASA,CAAW,CAAA,OAAA,CACpB,KAAOA,CAAAA,CAAAA,CAAW,KACpB,CAAE,CAAA,CACJ,CAAE,CAAA,CACJ,CAEEF,CAAAA,CAAAA,CAAU,OACZjP,EAAAA,CAAAA,CAAS,KACP,GAAGiP,CAAAA,CAAU,OAAQ,CAAA,GAAA,CAAKC,CAAa,GAAA,CACrC,KAAOA,CAAAA,CAAAA,CAAQ,MACf,OAASA,CAAAA,CAAAA,CAAQ,OACjB,CAAA,KAAA,CAAOA,CAAQ,CAAA,KAAA,CACf,WAAaA,CAAAA,CAAAA,CAAQ,aAAa,GAAKC,CAAAA,CAAAA,GAAgB,CACrD,KAAA,CAAOA,CAAW,CAAA,KAAA,CAClB,OAASA,CAAAA,CAAAA,CAAW,QACpB,KAAOA,CAAAA,CAAAA,CAAW,KACpB,CAAA,CAAE,CACJ,CAAE,CAAA,CACJ,CAIG,CAAA,CAAA,CACL,SAAU1D,CACV,CAAA,KAAA,CAAOuD,CACP,CAAA,QAAA,CAAUhP,CACZ,CACF,CAEA,MAAM,IAAI4O,kBAAmB,CAAA,CAAE,IAAM,CAAA,6BAAA,CAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CACzF,CAGM,gBAAA,CAAiB1C,CAAqBR,CAAAA,CAAAA,CAA0BuB,CAAsC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1G,OAAO,IAAI,OAAA,CAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,aAAa,EAC5B,CAAC,CACH,CAAA,CAAA,CAGM,oBAAqBtC,CAAAA,CAAAA,CAAqBR,CAA0BuB,CAAAA,CAAAA,CAA0C,CAAAsB,OAAAA,CAAAA,CAAA,sBAClH,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,iBAAA,EAAmB,EAClC,CAAC,CACH,CAAA,CAAA,CAEM,iBAAkBtC,CAAAA,CAAAA,CAAoBR,CAAyBuB,CAAAA,CAAAA,CAAyC,QAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,IAAMhB,CAAAA,CAAoB,IAAK,CAAA,eAAA,CAAgBrB,CAAQR,CAAAA,CAAAA,CAAUuB,CAAK,CAChEwB,CAAAA,CAAAA,CAAsB,IAAK,CAAA,iBAAA,CAAkB/C,CAAQ,CAAA,CAC3D,GAAI+C,CAAAA,CAAoB,UAAaA,CAAoB,CAAA,QAAA,CAA2B,MAAW,GAAA,CAAA,CAC7F,MAAM,IAAIV,oBAAqB,CAAA,CAC7B,KAAM,uBACN,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,uBAAuB,CAC1C,CAAC,CAAA,CAGH,IAAMW,CAAmBzB,CAAAA,CAAAA,CAAQ,IAAK,CAAA,cAAA,CAAeA,CAAK,CAAA,CAAI,EAAC,CAE/D,OAAO,IAAI,OAAA,CAASuB,CAAY,EAAA,CAC9BA,CAAQxN,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,CACN,MAAA,CAAQ,GACR,cAAgB,CAAA,CAAE,aAAe,CAAA,CAAA,CAAK,CACnC,CAAA,CAAA,IAAA,CAAK,gBAAiB,EAAA,CAAA,CACtBuM,GACAkB,CACAC,CAAAA,CAAAA,CAAAA,CACJ,EACH,CAAC,CACH,CAAA,CAAA,CAEO,gCACLW,CAAAA,CAAAA,CACAC,EAC8E,CAAAC,OAAAA,EAAAA,CAAA,IA/xBlF,CAAA,IAAA,CAAA,WAAA,CAAA,IAAAC,EAAAC,CAiyBI,CAAA,IAAMC,CAASJ,CAAAA,CAAAA,CAAAA,CAASD,GAAO,KAAM,CAAA,CAAA;AAAA,CAAI,CAAE,CAAA,MAAA,CAAQM,CAASA,EAAAA,CAAAA,CAAK,IAAK,EAAA,GAAM,EAAE,CAAA,CAC9E,IAAWA,IAAAA,CAAAA,IAAQD,CAAO,CAAA,CACxB,GAAIC,CAAS,GAAA,cAAA,CAEX,OACK,GAAIA,CAAK,CAAA,UAAA,CAAW,SAAS,CAAA,EAAKA,EAAK,QAAS,CAAA,GAAG,CAAG,CAAA,CAE3D,IAAIC,CAAAA,CACJ,GAAI,CAEFA,EAAiB,IAAK,CAAA,KAAA,CAAMD,CAAK,CAAA,SAAA,CAAU,CAAe,CAAC,EAC7D,CAAA,MAASE,EAAO,CAEd,MAAM,IAAIhB,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,CAAuCe,oCAAAA,EAAAA,CAAc,GAC3D,KAAOC,CAAAA,CACT,CAAC,CACH,CAEA,IAAMjB,CAAOtL,CAAAA,EAAAA,CAAyB,UAAUsM,CAAc,CAAA,CAC9D,GAAIhB,CAAAA,CAAK,OAAS,CAAA,CAChB,IAAMkB,CAAAA,CAA2C,CAAE,eAAiB,CAAA,EAAG,CAAA,CACjEhB,CAA+CF,CAAAA,CAAAA,CAAK,IAC1D,CAAA,GAAIE,CAAe,CAAA,OAAA,CAAQ,MAAS,CAAA,CAAA,CAAG,CACrC,IAAMnD,CAAUmD,CAAAA,CAAAA,CAAe,QAAQ,CAAC,CAAA,CAAE,KAC1C,CAAA,GAAInD,CAAY,GAAA,KAAA,CAAA,EAAa,MAAO,CAAA,IAAA,CAAKA,CAAO,CAAE,CAAA,MAAA,GAAW,CAC3D,CAAA,CAAA,GAAI,SAAaA,GAAAA,CAAAA,EAAWA,CAAQ,CAAA,OAAA,GAAY,KAC9CmE,CAAgB,CAAA,eAAA,CAAgB,IAAKC,CAAAA,wBAAAA,CAAyB7N,oBAAsByJ,CAAAA,CAAAA,CAAQ,OAAiB,CAAC,UACrG,SAAaA,GAAAA,CAAAA,EAAWA,CAAQ,CAAA,OAAA,GAAY,IACrDmE,CAAAA,CAAAA,CAAgB,eAAgB,CAAA,IAAA,CAAKC,yBAAyB7N,oBAAsByJ,CAAAA,CAAAA,CAAQ,OAAiB,CAAC,CACrG,CAAA,KAAA,GAAA,YAAA,GAAgBA,CAAWA,EAAAA,CAAAA,CAAQ,aAAe,KAAW,CAAA,CAAA,CACtE,IAAMkB,CAAAA,CAAWlB,CAAQ,CAAA,UAAA,CAAW,EAAG,CAAA,CAAC,EACxCmE,CAAgB,CAAA,eAAA,CAAgB,IAC9BE,CAAAA,4BAAAA,CACE9N,oBACA2K,CAAAA,CAAAA,CAAS,KACTA,CAAAA,CAAAA,CAAS,EACT2C,CAAAA,CAAAA,CAAAA,CAAA3C,CAAS,CAAA,QAAA,GAAT,IAAA2C,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA,CAAmB,IACnBC,CAAAA,CAAAA,CAAAA,CAAA5C,EAAS,QAAT,GAAA,IAAA,CAAA,KAAA,CAAA,CAAA4C,CAAmB,CAAA,SACrB,CACF,EACF,CAEJ,CAAA,CAEIX,EAAe,KACjBgB,GAAAA,CAAAA,CAAgB,KAAQ,CAAA,CACtB,YAAchB,CAAAA,CAAAA,CAAe,KAAM,CAAA,aAAA,CACnC,iBAAkBA,CAAe,CAAA,KAAA,CAAM,iBACvC,CAAA,WAAA,CAAaA,CAAe,CAAA,KAAA,CAAM,YACpC,CAAA,CAAA,CAGF,MAAM,CAAE,eAAA,CAAiBgB,CAAiB,CAAA,MAAA,CAAQR,CAAO,EAC3D,CACE,KAAA,MAAM,IAAIT,kBAAmB,CAAA,CAAE,IAAM,CAAA,6BAAA,CAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CAE3F,CAGF,CACF,CACF,CAAA,CAAA,ECz1BA,IAAMqB,CAAN,CAAA,cAAmCtF,CAAc,CAC/C,WAAYC,CAAAA,CAAAA,CAAkCP,EAAmC,CAC/E,KAAA,CAAMO,CAAaP,CAAAA,CAAO,EAC5B,CAEA,qBAAsBwB,CAAAA,CAAAA,CAKpB,CACA,IAAMC,CAAAA,CAAc1H,EAAyB,CAAA,SAAA,CAAUyH,CAAO,CAAA,CAC9D,GAAI,CAACC,EAAY,OACf,CAAA,MAAM,IAAIC,wBAAAA,CAAyB,CAAE,IAAA,CAAM,uBAAyB,CAAA,KAAA,CAAOD,EAAY,KAAM,CAAC,CAGhG,CAAA,IAAME,CAAgBF,CAAAA,CAAAA,CAAY,IAC5BoE,CAAAA,CAAAA,CAAcnP,EAAAC,CAAA,CAAA,EAAA,CACfgL,CADe,CAAA,CAAA,CAElB,UAAYA,CAAAA,CAAAA,CAAc,qBAC5B,CAAA,CAAA,CACA,cAAOkE,CAAY,CAAA,qBAAA,CAEZ,KAAM,CAAA,qBAAA,CAAsBA,CAAW,CAChD,CAGA,cAAA,CAAejD,EAA+B,CAC5C,MAAM,IAAIkD,UAAAA,CAAW,CACnB,IAAA,CAAM,CAAW,QAAA,EAAA,IAAA,CAAK,YAAY,IAAI,CAAA,2BAAA,CAAA,CACtC,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,QAAA,EAAW,IAAK,CAAA,WAAA,CAAY,IAAI,CAAA,2BAAA,CAA6B,CAChF,CAAC,CACH,CAGM,gBAAiBjE,CAAAA,CAAAA,CAAqBR,EAA0BuB,CAAsC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1G,MAAM,IAAI4B,UAAW,CAAA,CACnB,KAAM,CAAW,QAAA,EAAA,IAAA,CAAK,WAAY,CAAA,IAAI,CACtC,6BAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,WAAW,IAAK,CAAA,WAAA,CAAY,IAAI,CAAA,6BAAA,CAA+B,CAClF,CAAC,CACH,CAAA,CAAA,CAGM,qBAAqBjE,CAAqBR,CAAAA,CAAAA,CAA0BuB,CAA0C,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAClH,MAAM,IAAI4B,WAAW,CACnB,IAAA,CAAM,CAAW,QAAA,EAAA,IAAA,CAAK,WAAY,CAAA,IAAI,CACtC,6BAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAW,IAAK,CAAA,WAAA,CAAY,IAAI,CAAA,6BAAA,CAA+B,CAClF,CAAC,CACH,CAGM,CAAA,CAAA,iBAAA,CAAkBjE,CAAoBR,CAAAA,CAAAA,CAAyBuB,CAAyC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,MAAM,IAAI4B,UAAW,CAAA,CACnB,IAAM,CAAA,CAAA,QAAA,EAAW,IAAK,CAAA,WAAA,CAAY,IAAI,CACtC,6BAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,CAAW,QAAA,EAAA,IAAA,CAAK,WAAY,CAAA,IAAI,+BAA+B,CAClF,CAAC,CACH,CAAA,CAAA,CAEO,gCAELd,CAAAA,CAAAA,CAEAC,CAC8E,CAAA,CAAA,OAAAC,GAAA,IAC9E,CAAA,IAAA,CAAA,WAAA,CAAA,MAAM,IAAIY,UAAAA,CAAW,CACnB,IAAA,CAAM,CAAW,QAAA,EAAA,IAAA,CAAK,YAAY,IAAI,CAAA,6BAAA,CAAA,CACtC,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,QAAA,EAAW,IAAK,CAAA,WAAA,CAAY,IAAI,CAA+B,6BAAA,CAAA,CAClF,CAAC,CAGH,CACF,CAAA,CAAA,EChEA,IAAMxL,EAA4B,CAAA,oBAAA,CAC5ByL,EACJ,CAAA,yNAAA,CAGItL,EAA2BuL,CAAAA,eAAAA,CAAgBtO,EAAsBiB,CAAqC,CAAA,CAAE,KAAM,CAAA,CAClH,IAAM2B,CAAAA,EAAAA,CACN,WAAayL,CAAAA,EAAAA,CACb,cAAgB,CAAA,IAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,KAAOhO,CAAAA,CAAAA,CACP,UAAYW,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKlB,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CACpD,OAAQA,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,CAAE,CAAA,MACzD,CACF,CAAC,EAEKgD,EAA4B6F,CAAAA,CAAAA,CAG5B9F,EAAN,CAAA,cAAiC+F,CAAc,CAC7C,WAAYN,CAAAA,CAAAA,CAAwC,CAClD,KAAMvF,CAAAA,EAAAA,CAA0BuF,CAAO,EACzC,CACF,ECzBA,IAAMtF,EAA4B,CAAA,oBAAA,CAC5BuL,EACJ,CAAA,sNAAA,CAGIpL,EAA2BmL,CAAAA,eAAAA,CAAgBtO,EAAsBiB,CAAqC,CAAA,CAAE,KAAM,CAAA,CAClH,IAAM+B,CAAAA,EAAAA,CACN,WAAauL,CAAAA,EAAAA,CACb,eAAgB,IAChB,CAAA,eAAA,CAAiB,KACjB,CAAA,KAAA,CAAOlO,CACP,CAAA,UAAA,CAAYW,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKlB,CAAAA,CAAAA,CAAuB,cAAe,CAAA,KAAA,CAAO,CAAC,CAAA,CAAE,GACrD,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,KAAA,CAAO,CAAC,CAAA,CAAE,MAC1D,CACF,CAAC,CAAA,CAEKoD,GAA4ByF,CAG5B1F,CAAAA,EAAAA,CAAN,cAAiC2F,CAAc,CAC7C,WAAA,CAAYN,CAAwC,CAAA,CAClD,MAAMnF,EAA0BmF,CAAAA,CAAO,EACzC,CACF,ECzBM9F,IAAAA,EAAAA,CAAuB,eACvBgM,CAAAA,EAAAA,CAA2B,wEAE3B7L,CAAAA,EAAAA,CAAsB2L,eAAgBtO,CAAAA,CAAAA,CAAsBiB,CAAqC,CAAE,CAAA,KAAA,CAAM,CAC7G,IAAA,CAAMuB,EACN,CAAA,WAAA,CAAagM,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,KAAOnO,CAAAA,CAAAA,CACP,UAAYW,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAKlB,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAAA,CAEK4C,GAAuBiG,CAGvBlG,CAAAA,EAAAA,CAAN,cAA4BmG,CAAc,CACxC,WAAA,CAAYN,CAAmC,CAAA,CAC7C,MAAM3F,EAAqB2F,CAAAA,CAAO,EACpC,CACF,ECvBMlF,IAAAA,EAAAA,CAA4B,oBAC5BqL,CAAAA,EAAAA,CACJ,qJAEIlL,CAAAA,EAAAA,CAA2B+K,eAAgBtO,CAAAA,CAAAA,CAAsBiB,CAAqC,CAAE,CAAA,KAAA,CAAM,CAClH,IAAA,CAAMmC,EACN,CAAA,WAAA,CAAaqL,EACb,CAAA,cAAA,CAAgB,MAChB,eAAiB,CAAA,IAAA,CACjB,KAAOpO,CAAAA,CAAAA,CACP,UAAYW,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAKlB,CAAuB,CAAA,IAAA,CAAK,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CAC1C,MAAQA,CAAAA,CAAAA,CAAuB,KAAK,IAAM,CAAA,CAAC,CAAE,CAAA,MAC/C,CACF,CAAC,CAEKwD,CAAAA,EAAAA,CAA4BqF,CAG5BtF,CAAAA,EAAAA,CAAN,cAAiCuF,CAAc,CAC7C,WAAA,CAAYN,CAAwC,CAAA,CAClD,MAAM/E,EAA0B+E,CAAAA,CAAO,EACzC,CACF,ECxBM9E,IAAAA,EAAAA,CAAoB,YACpBkL,CAAAA,EAAAA,CACJ,8GAEI/K,CAAAA,EAAAA,CAAmB2K,eAAgBtO,CAAAA,CAAAA,CAAsBiB,CAAqC,CAAE,CAAA,KAAA,CAAM,CAC1G,IAAA,CAAMuC,EACN,CAAA,WAAA,CAAakL,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,KAAOrO,CAAAA,CAAAA,CACP,UAAYW,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAKlB,CAAuB,CAAA,IAAA,CAAK,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CAC1C,MAAQA,CAAAA,CAAAA,CAAuB,KAAK,IAAM,CAAA,CAAC,CAAE,CAAA,MAC/C,CACF,CAAC,CAEK4D,CAAAA,EAAAA,CAAoBiF,EAGpBlF,EAAN,CAAA,cAAyBmF,CAAc,CACrC,WAAYN,CAAAA,CAAAA,CAAgC,CAC1C,KAAA,CAAM3E,EAAkB2E,CAAAA,CAAO,EACjC,CACF,ECxBM1E,IAAAA,EAAAA,CAA4B,oBAC5B+K,CAAAA,EAAAA,CACJ,0QAGI5K,CAAAA,EAAAA,CAA2BuK,eAAgBtO,CAAAA,CAAAA,CAAsBiB,CAAqC,CAAE,CAAA,KAAA,CAAM,CAClH,IAAA,CAAM2C,EACN,CAAA,WAAA,CAAa+K,EACb,CAAA,cAAA,CAAgB,MAChB,eAAiB,CAAA,IAAA,CACjB,KAAOtO,CAAAA,CAAAA,CACP,UAAYW,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAKlB,CAAuB,CAAA,IAAA,CAAK,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CAC1C,MAAQA,CAAAA,CAAAA,CAAuB,KAAK,IAAM,CAAA,CAAC,CAAE,CAAA,MAC/C,CACF,CAAC,CAEKgE,CAAAA,EAAAA,CAA4B6E,EAG5B9E,EAAN,CAAA,cAAiC+E,CAAc,CAC7C,WAAYN,CAAAA,CAAAA,CAAwC,CAClD,KAAA,CAAMvE,GAA0BuE,CAAO,EACzC,CACF,MC9BMtE,EAAgC,CAAA,wBAAA,CAChC4K,EACJ,CAAA,0KAAA,CAGIzK,EAA+BmK,CAAAA,eAAAA,CAAgBtO,CAAsBa,CAAAA,CAA6B,EAAE,KAAM,CAAA,CAC9G,IAAMmD,CAAAA,EAAAA,CACN,WAAa4K,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAOvO,CACP,CAAA,UAAA,CAAYG,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKV,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAAA,CAEKoE,EAAgCyE,CAAAA,CAAAA,CAGhC1E,GAAN,cAAqC2E,CAAc,CACjD,WAAA,CAAYN,CAA4C,CAAA,CACtD,KAAMnE,CAAAA,EAAAA,CAA8BmE,CAAO,EAC7C,CACF,ECpBA,IAAMlE,GAA6B,qBAC7ByK,CAAAA,EAAAA,CAAiC,uEAEjCtK,CAAAA,EAAAA,CAA4B+J,eAAgBtO,CAAAA,CAAAA,CAAsBiB,CAAqC,CAAA,CAAE,KAAM,CAAA,CACnH,IAAMmD,CAAAA,EAAAA,CACN,WAAayK,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAOxO,CACP,CAAA,UAAA,CAAYW,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlB,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAAA,CAEKwE,EAA6BqE,CAAAA,CAAAA,CAG7BtE,GAAN,cAAkCuE,CAAc,CAC9C,WAAA,CAAYN,CAAyC,CAAA,CACnD,KAAM/D,CAAAA,EAAAA,CAA2B+D,CAAO,EAC1C,CACF,EC5BA,IAAM9D,GAAqB,aACrBsK,CAAAA,EAAAA,CACJ,gMAGInK,CAAAA,EAAAA,CAAoB2J,eAAgBtO,CAAAA,CAAAA,CAAsBa,CAA6B,CAAA,CAAE,MAAM,CACnG,IAAA,CAAM2D,EACN,CAAA,WAAA,CAAasK,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,KACjB,KAAOzO,CAAAA,CAAAA,CACP,UAAYG,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,GAAKV,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MACzD,CACF,CAAC,CAEK4E,CAAAA,EAAAA,CAAqBiE,CAGrBlE,CAAAA,EAAAA,CAAN,cAA0BmE,CAAc,CACtC,WAAYN,CAAAA,CAAAA,CAAiC,CAC3C,KAAA,CAAM3D,EAAmB2D,CAAAA,CAAO,EAClC,CACF,ECpBM1D,IAAAA,EAAAA,CAAe,QACfmK,EAAmB,CAAA,gEAAA,CAEnBhK,EAAcuJ,CAAAA,eAAAA,CAAgBtO,CAAsBiB,CAAAA,CAAqC,CAAE,CAAA,KAAA,CAAM,CACrG,IAAM2D,CAAAA,EAAAA,CACN,WAAamK,CAAAA,EAAAA,CACb,cAAgB,CAAA,IAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,MAAO1O,CACP,CAAA,UAAA,CAAYW,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlB,CAAuB,CAAA,IAAA,CAAK,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CAC1C,MAAQA,CAAAA,CAAAA,CAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MAC/C,CACF,CAAC,CAEKgF,CAAAA,EAAAA,CAAe6D,CAGf9D,CAAAA,EAAAA,CAAN,cAAoB+D,CAAc,CAChC,WAAYN,CAAAA,CAAAA,CAA2B,CACrC,KAAA,CAAMvD,EAAauD,CAAAA,CAAO,EAC5B,CACF,EC5BMtC,IAAAA,EAAAA,CAA2B,oBAC3BgJ,EAA+B,CAAA,2FAAA,CAE/B7I,EAA0BmI,CAAAA,eAAAA,CAAgBtO,CAAsBa,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CACzG,IAAMmF,CAAAA,EAAAA,CACN,WAAagJ,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,MAAO3O,CACP,CAAA,UAAA,CAAYG,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKV,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,EAAE,MACzD,CACF,CAAC,CAAA,CAEKoG,EAA2ByC,CAAAA,CAAAA,CAG3B1C,EAAN,CAAA,cAAgC2C,CAAc,CAC5C,WAAA,CAAYN,CAAuC,CAAA,CACjD,KAAMnC,CAAAA,EAAAA,CAAyBmC,CAAO,EACxC,CACF,ECvBA,IAAMtD,EAA2B,CAAA,mBAAA,CAC3BiK,GAA+B,2FAE/B9J,CAAAA,EAAAA,CAA0BmJ,eAAgBtO,CAAAA,CAAAA,CAAsBa,CAA6B,CAAA,CAAE,KAAM,CAAA,CACzG,KAAMmE,EACN,CAAA,WAAA,CAAaiK,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO5O,EACP,UAAYG,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,GAAKV,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAEKoF,CAAAA,EAAAA,CAA2ByD,CAG3B1D,CAAAA,EAAAA,CAAN,cAAgC2D,CAAc,CAC5C,WAAA,CAAYN,CAAuC,CAAA,CACjD,KAAMnD,CAAAA,EAAAA,CAAyBmD,CAAO,EACxC,CACF,ECvBA,IAAM1C,EAAgC,CAAA,wBAAA,CAChCsJ,GACJ,8JAGInJ,CAAAA,EAAAA,CAA+BuI,eAAgBtO,CAAAA,CAAAA,CAAsBa,CAA6B,CAAA,CAAE,KAAM,CAAA,CAC9G,KAAM+E,EACN,CAAA,WAAA,CAAasJ,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO7O,EACP,UAAYG,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,GAAKV,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAEKgG,CAAAA,EAAAA,CAAgC6C,CAGhC9C,CAAAA,EAAAA,CAAN,cAAqC+C,CAAc,CACjD,WAAYN,CAAAA,CAAAA,CAA4C,CACtD,KAAA,CAAMvC,EAA8BuC,CAAAA,CAAO,EAC7C,CACF,ECzBA,IAAMlD,EAAqB,CAAA,aAAA,CACrB8J,GACJ,8JAGI3J,CAAAA,EAAAA,CAAoB+I,eAAgBtO,CAAAA,CAAAA,CAAsBa,CAA6B,CAAA,CAAE,KAAM,CAAA,CACnG,KAAMuE,EACN,CAAA,WAAA,CAAa8J,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO7O,EACP,UAAYG,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,GAAKV,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAEKwF,CAAAA,EAAAA,CAAqBqD,CAGrBtD,CAAAA,EAAAA,CAAN,cAA0BuD,CAAc,CACtC,WAAYN,CAAAA,CAAAA,CAAiC,CAC3C,KAAA,CAAM/C,EAAmB+C,CAAAA,CAAO,EAClC,CACF,ECzBM9C,IAAAA,EAAAA,CAAgB,QAChB2J,CAAAA,EAAAA,CACJ,8JAGIxJ,CAAAA,EAAAA,CAAe2I,eAAgBtO,CAAAA,CAAAA,CAAsBa,CAA6B,CAAA,CAAE,KAAM,CAAA,CAC9F,KAAM2E,EACN,CAAA,WAAA,CAAa2J,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO9O,EACP,UAAYG,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,GAAKV,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACF,CAAC,CAEK4F,CAAAA,EAAAA,CAAgBiD,CAGhBlD,CAAAA,EAAAA,CAAN,cAAqBmD,CAAc,CACjC,WAAYN,CAAAA,CAAAA,CAA4B,CACtC,KAAA,CAAM3C,EAAc2C,CAAAA,CAAO,EAC7B,CACF,ECzBMtB,IAAAA,EAAAA,CAAuB,eACvBoI,CAAAA,EAAAA,CACJ,mIAEIjI,EAAsBmH,CAAAA,eAAAA,CAAgBtO,CAAsBa,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CACrG,IAAA,CAAMmG,GACN,WAAaoI,CAAAA,EAAAA,CACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,KAAO/O,CAAAA,CAAAA,CACP,WAAYG,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKV,CAAuB,CAAA,cAAA,CAAe,GAAQ,CAAA,CAAC,EAAE,GACtD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,GAAQ,CAAA,CAAC,CAAE,CAAA,MAC3D,CACF,CAAC,CAAA,CAEKoH,EAAuByB,CAAAA,CAAAA,CAGvB1B,EAAN,CAAA,cAA4B2B,CAAc,CACxC,YAAYN,CAAmC,CAAA,CAC7C,KAAMnB,CAAAA,EAAAA,CAAqBmB,CAAO,EACpC,CACF,EClBA,IAAMlB,EAA4B,CAAA,oBAAA,CAC5BiI,EACJ,CAAA,8HAAA,CAEI9H,GAA2B+G,eAAgBhO,CAAAA,CAAAA,CAA8BS,CAAiC,CAAA,CAAE,KAAM,CAAA,CACtH,IAAMqG,CAAAA,EAAAA,CACN,YAAaiI,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,KACjB,CAAA,KAAA,CAAO9O,CACP,CAAA,UAAA,CAAYO,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKhB,CAAuB,CAAA,OAAA,CAAQ,KAAO,CAAA,CAAC,EAAE,GAC9C,CAAA,MAAA,CAAQA,CAAuB,CAAA,OAAA,CAAQ,KAAO,CAAA,CAAC,CAAE,CAAA,MACnD,CACF,CAAC,CAAA,CAEKwH,EAA4BqB,CAAAA,CAAAA,CAG5BtB,EAAN,CAAA,cAAiC6G,CAAqB,CACpD,YAAY5F,CAAwC,CAAA,CAClD,KAAMf,CAAAA,EAAAA,CAA0Be,CAAO,EACzC,CACF,ECxBA,IAAMlC,EAAiB,CAAA,SAAA,CACjBkJ,EACJ,CAAA,kHAAA,CAEI/I,GAAgB+H,eAAgBhO,CAAAA,CAAAA,CAA8BS,CAAiC,CAAA,CAAE,KAAM,CAAA,CAC3G,IAAMqF,CAAAA,EAAAA,CACN,YAAakJ,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO/O,CACP,CAAA,UAAA,CAAYO,EACZ,MAAQ,CAAA,CACN,GAAKhB,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IAC7C,MAAQA,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MAClD,CACF,CAAC,CAEKwG,CAAAA,EAAAA,CAAiBqC,CAGjBtC,CAAAA,EAAAA,CAAN,cAAsB6H,CAAqB,CACzC,WAAA,CAAY5F,EAA6B,CACvC,KAAA,CAAM/B,EAAe+B,CAAAA,CAAO,EAC9B,CACF,ECxBM9B,IAAAA,EAAAA,CAAoB,YACpB+I,CAAAA,EAAAA,CAAwB,+FAExB5I,CAAAA,EAAAA,CAAmB2H,gBAAgBhO,CAA8BS,CAAAA,CAAiC,CAAE,CAAA,KAAA,CAAM,CAC9G,IAAA,CAAMyF,EACN,CAAA,WAAA,CAAa+I,GACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,KAAOhP,CAAAA,CAAAA,CACP,UAAYO,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKhB,CAAuB,CAAA,OAAA,CAAQ,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CAC7C,OAAQA,CAAuB,CAAA,OAAA,CAAQ,IAAM,CAAA,CAAC,CAAE,CAAA,MAClD,CACF,CAAC,CAEK4G,CAAAA,EAAAA,CAAoBiC,CAGpBlC,CAAAA,EAAAA,CAAN,cAAyByH,CAAqB,CAC5C,WAAA,CAAY5F,EAAgC,CAC1C,KAAA,CAAM3B,EAAkB2B,CAAAA,CAAO,EACjC,CACF,EC5BM1B,IAAAA,EAAAA,CAAY,IACZ4I,CAAAA,EAAAA,CACJ,6IAEIzI,CAAAA,EAAAA,CAAWuH,gBAAgBtO,CAAsBa,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC1F,IAAA,CAAM+F,EACN,CAAA,WAAA,CAAa4I,GACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,KAAOnP,CAAAA,CAAAA,CACP,UAAYG,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKV,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,GAAA,CAC/C,OAAQA,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,MACpD,CACF,CAAC,EAEKgH,EAAY6B,CAAAA,CAAAA,CAGZ9B,EAAN,CAAA,cAAiBqH,CAAqB,CACpC,WAAY5F,CAAAA,CAAAA,CAAwB,CAClC,KAAMvB,CAAAA,EAAAA,CAAUuB,CAAO,EACzB,CACF,EC5BA,IAAMmH,EAAyE,CAC7EC,4BAAAA,CACAC,6BACF,CAAA,CAEMC,CAAqCpR,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAACkR,6BAA8BC,6BAA6B,CAAC,ECR/G,IAAME,GAA8BrR,CAAE,CAAA,MAAA,CAAO,CAC3C,MAAA,CAAQA,CAAE,CAAA,OAAA,CAAQ,MAAM,CAAA,CACxB,MAAOA,CAAE,CAAA,MAAA,EACT,CAAA,IAAA,CAAMA,CAAE,CAAA,KAAA,CACNA,CAAE,CAAA,MAAA,CAAO,CACP,KAAOA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAChB,MAAQA,CAAAA,CAAAA,CAAE,OAAQ,CAAA,WAAW,EAC7B,SAAWA,CAAAA,CAAAA,CAAE,KAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAC,CAAE,CAAA,EAAA,CAAGA,CAAE,CAAA,MAAA,EAAS,CAAA,MAAA,EAAQ,CACvD,CAAC,CACH,EACA,KAAOA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACd,aAAeA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,aAC1B,CAAA,YAAA,CAAcA,CAAE,CAAA,MAAA,EAAS,CAAA,WAAA,EAC3B,CAAC,CACH,CAAC,ECdKsR,IAAAA,EAAAA,CAA8BtR,EACjC,MAAO,EAAA,CACP,GAAI,CAAA,CAAC,CACL,CAAA,EAAA,CAAGA,CAAE,CAAA,KAAA,CAAMA,EAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CACpC,CAAA,EAAA,CAAGA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,GAAM,WAAY,EAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CACjD,CAAA,EAAA,CAAGA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,GAAM,WAAY,EAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAA,CAG9DuR,EAAyBvR,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACtC,KAAOA,CAAAA,CAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAClC,KAAOsR,CAAAA,EAAAA,CACP,gBAAiBtR,CAAE,CAAA,IAAA,CAAK,CAAC,OAAA,CAAS,QAAQ,CAAC,CAAE,CAAA,QAAA,GAC7C,UAAYA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,GAAI,CAAA,CAAC,EAAE,QAAS,EAC/C,CAAC,ECmBD,IAAMwR,CAA4BxR,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACzC,SAAWA,CAAAA,CAAAA,CAAE,QACb,CAAA,MAAA,CAAQA,CAAE,CAAA,MAAA,EACV,CAAA,OAAA,CAASA,CAAE,CAAA,MAAA,GAAS,GAAI,EAAA,CAAE,QAAS,EAAA,CACnC,gBAAkBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,KAAM,CAAA,QAAA,EACrC,CAAC,CAGKyR,CAAAA,CAAAA,CAAN,KAA+E,CAS7E,YAAYpH,CAAuCP,CAAAA,CAAAA,CAAwC,CAR3F,IAAA,CAAS,OAAU,CAAA,IAAA,CASjB,IAAMI,CAAAA,CAAgBsH,EAA0B,KAAM1H,CAAAA,CAAO,CAC7D,CAAA,IAAA,CAAK,WAAcO,CAAAA,CAAAA,CACnB,IAAK,CAAA,SAAA,CAAYH,EAAc,SAC/B,CAAA,IAAA,CAAK,MAASA,CAAAA,CAAAA,CAAc,MAC5B,CAAA,IAAA,CAAK,OAAUI,CAAAA,uBAAAA,CAAwBJ,EAAc,OAAWnG,EAAAA,CAAAA,CAAO,OAAO,CAAA,CAC9E,IAAK,CAAA,gBAAA,CAAmBuG,uBAAwBJ,CAAAA,CAAAA,CAAc,kBAAoB,CAAG,EAAA,IAAA,CAAK,OAAO,CAAA,WAAA,CAAa,EAChH,CAEA,iBAA6B,EAAA,CAC3B,OAAO,IAAK,CAAA,OACd,CAEA,iBAAA,EAAiC,CAC/B,OAAO,CACL,aAAA,CAAe,UAAU,IAAK,CAAA,MAAM,CACpC,CAAA,CAAA,cAAA,CAAgB,kBAClB,CACF,CAEA,gBAAA,EAA+B,CAC7B,OAAO,CACL,KAAO,CAAA,IAAA,CAAK,WAAY,CAAA,IAC1B,CACF,CAQA,cAAcK,CAAyE,CAAA,CAErF,IAAMC,CAAAA,CAAiBC,CAA6B,EAAA,CAClD,IAAMC,CAAAA,CAAQ,mBACRC,CAAwC,CAAA,CAC5C,CAAG,CAAA,IAAA,CACH,CAAG,CAAA,GAAA,CACH,CAAG,CAAA,GAAA,CACH,EAAI,CAAA,CACN,CAEIC,CAAAA,CAAAA,CACAC,CAAU,CAAA,CAAA,CACd,KAAQD,CAAAA,CAAAA,CAAQF,EAAM,IAAKD,CAAAA,CAAQ,CAAO,IAAA,IAAA,EAAM,CAC9C,IAAMxK,CAAQ,CAAA,QAAA,CAAS2K,EAAM,CAAC,CAAC,CACzBE,CAAAA,CAAAA,CAAOF,CAAM,CAAA,CAAC,CACpBC,CAAAA,CAAAA,EAAW5K,EAAQ0K,CAAUG,CAAAA,CAAI,EACnC,CAEA,OAAOD,CACT,CAEIE,CAAAA,CAAAA,CAAuB,EACvBC,CAAqB,CAAA,CAAA,CACnBC,CAAc,CAAA,CAAA,CAAA,CAChBV,CAAgB,CAAA,4BAA4B,CAC9CQ,GAAAA,CAAAA,CAAuBP,EAAcD,CAAgB,CAAA,4BAA4B,CAAC,CAAA,CAAA,CAEhFA,CAAgB,CAAA,0BAA0B,CAC5CS,GAAAA,CAAAA,CAAqBR,EAAcD,CAAgB,CAAA,0BAA0B,CAAC,CAAA,CAAA,CAIhF,IAAMW,CAAAA,CAAU,IAAK,CAAA,GAAA,CAAIH,EAAsBC,CAAkB,CAAA,CACjE,OAAO,CAAE,WAAAC,CAAAA,CAAAA,CAAa,OAAAC,CAAAA,CAAQ,CAChC,CAEA,aAAA,CAAcwG,CAAyC,CAAA,CACrD,OAAOA,CAAAA,CAAS,QAAS,CAAA,MAAA,CAAO,CAAC9H,CAAK0B,CAAAA,CAAAA,GAAY1B,CAAM0B,CAAAA,CAAAA,CAAQ,MAAQ,CAAA,CAAC,CAC3E,CAEA,sBAAsBA,CAIpB,CAAA,CACA,IAAMC,CAAAA,CAAcgG,EAAuB,CAAA,SAAA,CAAUjG,CAAO,CAAA,CAC5D,GAAI,CAACC,CAAAA,CAAY,OACf,CAAA,MAAM,IAAIC,wBAAAA,CAAyB,CAAE,IAAA,CAAM,wBAAyB,KAAOD,CAAAA,CAAAA,CAAY,KAAM,CAAC,CAGhG,CAAA,IAAME,CAAgBF,CAAAA,CAAAA,CAAY,KAE5BxB,CAAY0B,CAAAA,CAAAA,CAAc,KAE1BC,CAAAA,CAAAA,CAAU,CACd,cAAA,CAAgBD,CAAc,CAAA,eAAA,CAC9B,WAAYA,CAAc,CAAA,UAC5B,CACME,CAAAA,CAAAA,CAASC,MAAO,EAAA,CAAE,KAAMC,CAAAA,sBAAAA,CAAuBH,CAAO,CAAC,CAAA,CAEzDiG,CACAC,CAAAA,CAAAA,CACJ,OAAI,OAAOnG,CAAc,CAAA,KAAA,EAAU,QACjCmG,CAAAA,CAAAA,CAAkBV,4BAEd,CAAA,OAAOzF,CAAc,CAAA,KAAA,CAAM,CAAC,CAAA,EAAM,SACpCmG,CAAkBV,CAAAA,4BAAAA,CAElBU,CAAkBT,CAAAA,6BAAAA,CAIlBS,CAAoBV,GAAAA,4BAAAA,CAClB,OAAOzF,CAAAA,CAAc,OAAU,QACjCkG,CAAAA,CAAAA,CAAoB,CAClB,QAAA,CAAUC,CACV,CAAA,QAAA,CAAU,CAACnG,CAAAA,CAAc,KAAK,CAChC,CAAA,CAEAkG,CAAoB,CAAA,CAClB,QAAUC,CAAAA,CAAAA,CACV,QAAUnG,CAAAA,CAAAA,CAAc,KAC1B,CAGE,CAAA,OAAOA,CAAc,CAAA,KAAA,CAAM,CAAC,CAAA,EAAM,QACpCkG,CAAAA,CAAAA,CAAoB,CAClB,QAAUC,CAAAA,CAAAA,CACV,QAAU,CAAA,CAACnG,CAAc,CAAA,KAAiB,CAC5C,CAAA,CAEAkG,EAAoB,CAClB,QAAA,CAAUC,CACV,CAAA,QAAA,CAAUnG,CAAc,CAAA,KAC1B,CAIG,CAAA,CACL,UAAA1B,CACA,CAAA,MAAA,CAAA4B,CACA,CAAA,iBAAA,CAAAgG,CACF,CACF,CAGA,eAAA,CAAgBhG,EAAoB+F,CAA8C,CAAA,CAChF,IAAM7E,CAAAA,CAAgB,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,MAAA,CAAO,UAAUlB,CAAM,CAAA,CACrE,GAAI,CAACkB,CAAc,CAAA,OAAA,CACjB,MAAM,IAAIC,mBAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,WAAY,CAAA,IAAI,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAOD,EAAc,KACvB,CAAC,CAGH,CAAA,IAAME,CAAeF,CAAAA,CAAAA,CAAc,IACnC,CAAA,OAAA,MAAA,CAAO,KAAKE,CAA0B,CAAA,CAAE,OAASlD,CAAAA,CAAAA,EAAQ,CACvD,GAAI,CAAC,IAAA,CAAK,YAAY,MAAO,CAAA,GAAA,CAAIA,CAAG,CAAA,CAClC,MAAM,IAAIiD,kBAAmB,CAAA,CAC3B,KAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,WAAY,CAAA,IAAI,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,yBAAyBjD,CAAG,CAAA;AAAA,8BACvB,EAAA,MAAA,CAAO,KAAK,IAAK,CAAA,WAAA,CAAY,OAAO,GAAG,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC9E,CAAC,CAEL,CAAC,CAAA,CAEyB,OAAO,IAAKkD,CAAAA,CAAY,CAAE,CAAA,MAAA,CAAO,CAACnD,CAAAA,CAAKC,IAAQ,CAEvE,IAAMqD,EADM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIrD,CAAAA,CAAG,EACtB,KACfsD,CAAAA,CAAAA,CAAaJ,EAAalD,CAAG,CAAA,CACnC,OAAAD,CAAIsD,CAAAA,CAAQ,EAAIC,CACTvD,CAAAA,CACT,CAAG,CAAA,EAAgB,CAGrB,CAEA,0BAA2B8H,CAAAA,CAAAA,CAA6C,CACtE,IAAMG,CAAAA,CAAkBC,mBAAoB,CAAA,SAAA,CAAUJ,CAAQ,CAC9D,CAAA,GAAI,CAACG,CAAgB,CAAA,OAAA,CACnB,MAAM,IAAIE,6BAAAA,CAA8B,CAAE,IAAM,CAAA,4BAAA,CAA8B,KAAOF,CAAAA,CAAAA,CAAgB,KAAM,CAAC,EAS9G,OAAO,CACL,MAFqBA,CAAgB,CAAA,IAAA,CAEf,QACxB,CACF,CAGM,oBAAoBlG,CAAqB+F,CAAAA,CAAAA,CAAoD,QAAA1D,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CACjG,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,gBAAgB,EAC/B,CAAC,CACH,CAGM,CAAA,CAAA,uBAAA,CAAwBtC,EAAqB+F,CAAwD,CAAA,CAAA,OAAA1D,EAAA,IACzG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ,CAAA,IAAA,CAAK,mBAAmB,EAClC,CAAC,CACH,CAAA,CAAA,CAEM,oBAAqBtC,CAAAA,CAAAA,CAAoB+F,CAAsD,CAAA,CAAA,OAAA1D,EAAA,IACnG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQxN,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,GACH,IAAK,CAAA,gBAAA,IACL,IAAK,CAAA,eAAA,CAAgBkL,EAAQ+F,CAAQ,CAAA,CAAA,CACrC,KAAK,0BAA2BA,CAAAA,CAAQ,CAC5C,CAAA,EACH,CAAC,CACH,GAEA,8BAA+BtD,CAAAA,CAAAA,CAAsC,CACnE,IAAIrN,CAAAA,CACEsN,EAAOgD,EAA4B,CAAA,SAAA,CAAUjD,CAAQ,CAC3D,CAAA,GAAIC,EAAK,OAAS,CAAA,CAChB,IAAME,CAAiBF,CAAAA,CAAAA,CAAK,KAC5BtN,CAAiB,CAAA,OAAOwN,CAAe,CAAA,IAAA,CAAK,CAAC,CAAA,CAAE,WAAc,QAAWyD,CAAAA,sBAAAA,CAAyBC,sBACjG,IAAMC,CAAAA,CAAa3D,EAAe,IAAK,CAAA,GAAA,CAAK4D,CACtC,EAAA,OAAOA,CAAK,CAAA,SAAA,EAAc,SACrB,CACL,KAAA,CAAOA,EAAK,KACZ,CAAA,SAAA,CAAWA,EAAK,SAClB,CAAA,CAEO,CACL,KAAA,CAAOA,CAAK,CAAA,KAAA,CACZ,UAAWA,CAAK,CAAA,SAClB,CAEH,CAED,CAAA,OAAO,CACL,cAAgBpR,CAAAA,CAAAA,CAChB,WAAYmR,CACZ,CAAA,KAAA,CAAO,CACL,WAAa3D,CAAAA,CAAAA,CAAe,MAAM,YACpC,CACF,CACF,CAEA,MAAM,IAAID,kBAAAA,CAAmB,CAAE,IAAA,CAAM,8BAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CACzF,CACF,MC7RMrF,EAA+B,CAAA,wBAAA,CAC/BoJ,GAAmC,mFAEnCjJ,CAAAA,EAAAA,CAA8BkJ,qBAAqBjB,CAAkC,CAAA,CAAE,KAAM,CAAA,CACjG,IAAMpI,CAAAA,EAAAA,CACN,YAAaoJ,EACb,CAAA,UAAA,CAAYnB,EACZ,cAAgB,CAAA,IAAA,CAChB,gBAAiB,IACjB,CAAA,MAAA,CAAQ,CACN,GAAK1P,CAAAA,CAAAA,CAA4B,MAAO,CAAA,GAAA,CACxC,OAAQA,CAA4B,CAAA,IAAA,GAAO,MAC7C,CACF,CAAC,CAAA,CAEK2H,EAAgCsI,CAAAA,CAAAA,CAGhCvI,GAAN,cAAoCwI,CAAmB,CACrD,WAAY3H,CAAAA,CAAAA,CAA4C,CACtD,KAAMX,CAAAA,EAAAA,CAA6BW,CAAO,EAC5C,CACF,ECtBMV,IAAAA,EAAAA,CAAgC,yBAChCkJ,EAAoC,CAAA,+DAAA,CAEpC/I,EAA+B8I,CAAAA,oBAAAA,CAAqBjB,CAAkC,CAAA,CAAE,MAAM,CAClG,IAAA,CAAMhI,GACN,WAAakJ,CAAAA,EAAAA,CACb,WAAYrB,CACZ,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,OAAQ,CACN,GAAA,CAAK1P,EAA4B,UAAW,CAAA,IAAI,EAAE,GAClD,CAAA,MAAA,CAAQA,CAA4B,CAAA,UAAA,CAAW,IAAI,CAAA,CAAE,MACvD,CACF,CAAC,EAEK+H,EAAiCkI,CAAAA,CAAAA,CAGjCnI,GAAN,cAAqCoI,CAAmB,CACtD,WAAY3H,CAAAA,CAAAA,CAA6C,CACvD,KAAMP,CAAAA,EAAAA,CAA8BO,CAAO,EAC7C,CACF,ECtBMN,IAAAA,EAAAA,CAAgC,yBAChC+I,EAAoC,CAAA,qEAAA,CAEpC5I,GAA+B0I,oBAAqBjB,CAAAA,CAAkC,EAAE,KAAM,CAAA,CAClG,KAAM5H,EACN,CAAA,WAAA,CAAa+I,GACb,UAAYtB,CAAAA,CAAAA,CACZ,eAAgB,IAChB,CAAA,eAAA,CAAiB,KACjB,MAAQ,CAAA,CACN,GAAK1P,CAAAA,CAAAA,CAA4B,UAAW,CAAA,IAAI,EAAE,GAClD,CAAA,MAAA,CAAQA,EAA4B,UAAW,CAAA,IAAI,EAAE,MACvD,CACF,CAAC,CAAA,CAEKmI,EAAiC8H,CAAAA,CAAAA,CAGjC/H,GAAN,cAAqCgI,CAAmB,CACtD,WAAY3H,CAAAA,CAAAA,CAA6C,CACvD,KAAMH,CAAAA,EAAAA,CAA8BG,CAAO,EAC7C,CACF","file":"index.mjs","sourcesContent":["import { z } from \"zod\";\n\nimport {\n  frequencyPenalty,\n  logProbs,\n  maxTokens,\n  presencePenalty,\n  seed,\n  stop,\n  temperature,\n  toolChoice,\n  topLogProbs,\n  topP,\n} from \"./common.config.chat-model.openai\";\n\nconst ChatModelBaseConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  z.object({\n    temperature: temperature.schema,\n    maxTokens: maxTokens(maxOutputTokens).schema,\n    stop: stop(maxSequences).schema,\n    topP: topP.schema,\n    frequencyPenalty: frequencyPenalty.schema,\n    presencePenalty: presencePenalty.schema,\n    seed: seed.schema.transform((value) => (value === 0 ? undefined : value)),\n    logProbs: logProbs.schema,\n    topLogProbs: topLogProbs.schema,\n    toolChoice: toolChoice.schema,\n  });\n\nconst ChatModelBaseConfigDef = (maxOutputTokens: number, maxSequences: number) =>\n  ({\n    temperature: temperature.def,\n    maxTokens: maxTokens(maxOutputTokens).def,\n    stop: stop(maxSequences).def,\n    topP: topP.def,\n    frequencyPenalty: frequencyPenalty.def,\n    presencePenalty: presencePenalty.def,\n    seed: seed.def,\n    logProbs: logProbs.def,\n    topLogProbs: topLogProbs.def,\n    toolChoice: toolChoice.def,\n  }) as const;\n\nexport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema };\n","import { CHAT_CONFIG, MultiStringConfigItem, RangeConfigItem, SelectBooleanConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nconst temperature = RangeConfigItem({\n  param: \"temperature\",\n  title: CHAT_CONFIG.TEMPERATURE.title,\n  description: CHAT_CONFIG.TEMPERATURE.description,\n  min: 0,\n  max: 2,\n  step: 0.01,\n  default: 1,\n});\n\nconst maxTokens = (maxOutputTokens: number) =>\n  RangeConfigItem({\n    param: \"max_tokens\",\n    title: CHAT_CONFIG.MAX_TOKENS.title,\n    description: CHAT_CONFIG.MAX_TOKENS.description,\n    min: 0,\n    max: maxOutputTokens,\n    step: 1,\n    default: 0,\n  });\n\nconst stop = (maxSequences: number) =>\n  MultiStringConfigItem({\n    param: \"stop\",\n    title: CHAT_CONFIG.STOP(maxSequences).title,\n    description: CHAT_CONFIG.STOP(maxSequences).description,\n    max: maxSequences,\n  });\n\nconst topP = RangeConfigItem({\n  param: \"top_p\",\n  title: CHAT_CONFIG.TOP_P.title,\n  description: CHAT_CONFIG.TOP_P.description,\n  min: 0,\n  max: 1,\n  step: 0.01,\n  default: 1,\n});\n\nconst frequencyPenalty = RangeConfigItem({\n  param: \"frequency_penalty\",\n  title: CHAT_CONFIG.FREQUENCY_PENALTY.title,\n  description: CHAT_CONFIG.FREQUENCY_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst presencePenalty = RangeConfigItem({\n  param: \"presence_penalty\",\n  title: CHAT_CONFIG.PRESENCE_PENALTY.title,\n  description: CHAT_CONFIG.PRESENCE_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst seed = RangeConfigItem({\n  param: \"seed\",\n  title: CHAT_CONFIG.SEED.title,\n  description: CHAT_CONFIG.SEED.description,\n  min: 0,\n  max: 1000000,\n  step: 1,\n  default: 0,\n});\n\nconst logProbs = SelectBooleanConfigItem({\n  param: \"logprobs\",\n  title: CHAT_CONFIG.LOG_PROBS.title,\n  description: CHAT_CONFIG.LOG_PROBS.description,\n  default: false,\n});\n\nconst topLogProbs = RangeConfigItem({\n  param: \"top_logprobs\",\n  title: CHAT_CONFIG.TOP_LOG_PROBS.title,\n  description: CHAT_CONFIG.TOP_LOG_PROBS.description,\n  min: 0,\n  max: 20,\n  step: 1,\n  default: 0,\n});\n\nconst toolChoice = SelectStringConfigItem({\n  param: \"tool_choice\",\n  title: \"Tool choice\",\n  description:\n    \"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.\",\n  default: \"auto\",\n  choices: [\"auto\", \"required\", \"none\"],\n});\n\nexport { frequencyPenalty, logProbs, maxTokens, presencePenalty, seed, stop, temperature, toolChoice, topLogProbs, topP };\n","import { CHAT_CONFIG, RangeConfigItem } from \"@adaline/provider\";\n\nimport { ChatModelResponseSchemaConfigDef, ChatModelResponseSchemaConfigSchema } from \"./response-schema.config.chat-model.openai\";\n\n// o1 models only support temperature = 1.0\nconst temperature = RangeConfigItem({\n  param: \"temperature\",\n  title: CHAT_CONFIG.TEMPERATURE.title,\n  description: CHAT_CONFIG.TEMPERATURE.description,\n  min: 1,\n  max: 1,\n  step: 0.01,\n  default: 1,\n});\n\nconst maxTokens = (maxOutputTokens: number) =>\n  RangeConfigItem({\n    param: \"max_completion_tokens\",\n    title: CHAT_CONFIG.MAX_TOKENS.title,\n    description: CHAT_CONFIG.MAX_TOKENS.description,\n    min: 0,\n    max: maxOutputTokens,\n    step: 1,\n    default: 0,\n  });\n\nconst ChatModelOSeriesConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelResponseSchemaConfigDef(maxOutputTokens, maxSequences),\n  temperature: temperature.def,\n  maxTokens: maxTokens(maxOutputTokens).def,\n});\n\nconst ChatModelOSeriesConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelResponseSchemaConfigSchema(maxOutputTokens, maxSequences).extend({\n    temperature: temperature.schema,\n    maxTokens: maxTokens(maxOutputTokens).schema,\n  });\n\nexport { ChatModelOSeriesConfigDef, ChatModelOSeriesConfigSchema };\n","import { CHAT_CONFIG, ObjectSchemaConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\nimport { ResponseSchema } from \"@adaline/types\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.openai\";\n\nconst responseSchema = ObjectSchemaConfigItem({\n  param: \"response_schema\",\n  title: CHAT_CONFIG.RESPONSE_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_SCHEMA.description,\n  objectSchema: ResponseSchema,\n});\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,\n  default: \"text\",\n  choices: [\"text\", \"json_object\", \"json_schema\"],\n});\n\nconst ChatModelResponseSchemaConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n  responseFormat: responseFormat.def,\n  responseSchema: responseSchema.def,\n});\n\nconst ChatModelResponseSchemaConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelBaseConfigSchema(maxOutputTokens, maxSequences).extend({\n    responseFormat: responseFormat.schema,\n    responseSchema: responseSchema.schema,\n  });\n\nexport { ChatModelResponseSchemaConfigDef, ChatModelResponseSchemaConfigSchema };\n","import { CHAT_CONFIG, SelectStringConfigItem } from \"@adaline/provider\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.openai\";\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT.description,\n  default: \"text\",\n  choices: [\"text\", \"json_object\"],\n});\n\nconst ChatModelResponseFormatConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n  responseFormat: responseFormat.def,\n});\n\nconst ChatModelResponseFormatConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelBaseConfigSchema(maxOutputTokens, maxSequences).extend({\n    responseFormat: responseFormat.schema,\n  });\n\nexport { ChatModelResponseFormatConfigDef, ChatModelResponseFormatConfigSchema };\n","import { RangeConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nconst encodingFormat = SelectStringConfigItem({\n  param: \"encoding_format\",\n  title: \"Encoding format\",\n  description: \"Select the encoding format for the word embedding.\",\n  default: \"float\",\n  choices: [\"float\", \"base64\"],\n});\n\nconst dimensions = (maxDimensions: number) =>\n  RangeConfigItem({\n    param: \"dimensions\",\n    title: \"Dimensions\",\n    description: \"Select the number of dimensions for the word embedding.\",\n    min: 1,\n    max: maxDimensions,\n    step: 1,\n    default: maxDimensions,\n  });\n\nexport { encodingFormat, dimensions };\n","import { z } from \"zod\";\n\nimport { encodingFormat } from \"./common.config.embedding-model.openai\";\n\nconst EmbeddingModelBaseConfigSchema = () =>\n  z.object({\n    encodingFormat: encodingFormat.schema,\n  });\n\nconst EmbeddingModelBaseConfigDef = () =>\n  ({\n    encodingFormat: encodingFormat.def,\n  }) as const;\n\nexport { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema };\n","import { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema } from \"./base.config.embedding-model.openai\";\nimport { dimensions } from \"./common.config.embedding-model.openai\";\n\nconst EmbeddingModelDimensionsConfigSchema = (maxDimensions: number) =>\n  EmbeddingModelBaseConfigSchema().extend({\n    dimensions: dimensions(maxDimensions).schema,\n  });\n\nconst EmbeddingModelDimensionsConfigDef = (maxDimensions: number) =>\n  ({\n    ...EmbeddingModelBaseConfigDef(),\n    dimensions: dimensions(maxDimensions).def,\n  }) as const;\n\nexport { EmbeddingModelDimensionsConfigDef, EmbeddingModelDimensionsConfigSchema };\n","import {\n  ChatModelBaseConfigDef,\n  ChatModelBaseConfigSchema,\n  ChatModelOSeriesConfigDef,\n  ChatModelOSeriesConfigSchema,\n  ChatModelResponseFormatConfigDef,\n  ChatModelResponseFormatConfigSchema,\n  ChatModelResponseSchemaConfigDef,\n  ChatModelResponseSchemaConfigSchema,\n} from \"./chat-model\";\nimport {\n  EmbeddingModelBaseConfigDef,\n  EmbeddingModelBaseConfigSchema,\n  EmbeddingModelDimensionsConfigDef,\n  EmbeddingModelDimensionsConfigSchema,\n} from \"./embedding-model\";\n\nconst OpenAIChatModelConfigs = {\n  base: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelBaseConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  responseFormat: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelResponseFormatConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelResponseFormatConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  responseSchema: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelResponseSchemaConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelResponseSchemaConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  oSeries: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelOSeriesConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelOSeriesConfigSchema(maxOutputTokens, maxSequences),\n  }),\n} as const;\n\nconst OpenAIEmbeddingModelConfigs = {\n  base: () => ({\n    def: EmbeddingModelBaseConfigDef(),\n    schema: EmbeddingModelBaseConfigSchema(),\n  }),\n  dimensions: (maxDimensions: number) => ({\n    def: EmbeddingModelDimensionsConfigDef(maxDimensions),\n    schema: EmbeddingModelDimensionsConfigSchema(maxDimensions),\n  }),\n} as const;\n\nexport { OpenAIChatModelConfigs, OpenAIEmbeddingModelConfigs };\n","import { z } from \"zod\";\n\nimport { AssistantRoleLiteral, SystemRoleLiteral, ToolRoleLiteral, UserRoleLiteral } from \"@adaline/types\";\n\nconst OpenAIChatModelRoles = z.enum([SystemRoleLiteral, UserRoleLiteral, AssistantRoleLiteral, ToolRoleLiteral]);\n\nconst OpenAIChatModelRolesMap = {\n  system: SystemRoleLiteral,\n  user: UserRoleLiteral,\n  assistant: AssistantRoleLiteral,\n  tool: ToolRoleLiteral,\n} as const;\n\nconst OpenAIChatModelOSSeriesRoles = z.enum([UserRoleLiteral, AssistantRoleLiteral]);\n\nconst OpenAIChatModelOSSeriesRolesMap = {\n  user: UserRoleLiteral,\n  assistant: AssistantRoleLiteral,\n} as const;\n\nexport { OpenAIChatModelRoles, OpenAIChatModelRolesMap, OpenAIChatModelOSSeriesRoles, OpenAIChatModelOSSeriesRolesMap };\n","import { z } from \"zod\";\n\nimport { ChatModelSchemaType } from \"@adaline/provider\";\nimport { ImageModalityLiteral, TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral } from \"@adaline/types\";\n\nconst OpenAIChatModelModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst OpenAIChatModelModalitiesEnum = z.enum([\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n]);\n\nconst OpenAIChatModelTextModalities: ChatModelSchemaType[\"modalities\"] = [TextModalityLiteral];\n\nconst OpenAIChatModelTextModalitiesEnum = z.enum([TextModalityLiteral]);\n\nconst OpenAIChatModelTextToolModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst OpenAIChatModelTextToolModalitiesEnum = z.enum([TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral]);\n\nexport {\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelModalities,\n  OpenAIChatModelTextModalitiesEnum,\n  OpenAIChatModelTextModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n  OpenAIChatModelTextToolModalities,\n};\n","import { z } from \"zod\";\n\nconst OpenAIBaseLogProb = z.object({\n  token: z.string(),\n  logprob: z.number(),\n  bytes: z.array(z.number()).nullable(),\n});\n\nconst OpenAILogProb = z\n  .object({\n    content: z\n      .array(\n        OpenAIBaseLogProb.extend({\n          top_logprobs: z.array(OpenAIBaseLogProb),\n        })\n      )\n      .nullable()\n      .optional(),\n    refusal: z\n      .array(\n        OpenAIBaseLogProb.extend({\n          top_logprobs: z.array(OpenAIBaseLogProb),\n        })\n      )\n      .nullable()\n      .optional(),\n  })\n  .nullable();\n\nconst OpenAIToolCallsCompleteChatResponse = z.array(\n  z.object({\n    id: z.string().min(1),\n    type: z.enum([\"function\"]),\n    function: z.object({\n      name: z.string(),\n      arguments: z.string(),\n    }),\n  })\n);\n\nconst OpenAICompleteChatResponse = z.object({\n  id: z.string(),\n  object: z.literal(\"chat.completion\"),\n  created: z.number(),\n  model: z.string(),\n  system_fingerprint: z.string().nullable(),\n  choices: z.array(\n    z.object({\n      index: z.number(),\n      message: z.object({\n        role: z.string(),\n        content: z.string().nullable().optional(),\n        tool_calls: OpenAIToolCallsCompleteChatResponse.optional(),\n        refusal: z.string().nullable().optional(),\n      }),\n      logprobs: OpenAILogProb.optional(),\n      finish_reason: z.string(),\n    })\n  ),\n  usage: z.object({\n    prompt_tokens: z.number(),\n    completion_tokens: z.number(),\n    total_tokens: z.number(),\n  }),\n});\ntype OpenAICompleteChatResponseType = z.infer<typeof OpenAICompleteChatResponse>;\n\nconst OpenAIToolCallsStreamChatResponse = z.array(\n  z.object({\n    index: z.number().int(),\n    id: z.string().min(1).optional(),\n    type: z.enum([\"function\"]).optional(),\n    function: z\n      .object({\n        name: z.string().min(1).optional(),\n        arguments: z.string().optional(),\n      })\n      .optional(),\n  })\n);\n\nconst OpenAIStreamChatResponse = z.object({\n  id: z.string(),\n  object: z.string(),\n  created: z.number(),\n  model: z.string(),\n  system_fingerprint: z.string().nullable(),\n  choices: z.array(\n    z.object({\n      index: z.number(),\n      delta: z\n        .object({\n          content: z.string().nullable().optional(),\n          tool_calls: OpenAIToolCallsStreamChatResponse.optional(),\n          refusal: z.string().nullable().optional(),\n        })\n        .or(z.object({})),\n      logprobs: OpenAILogProb,\n      finish_reason: z.string().nullable(),\n    })\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number(),\n      completion_tokens: z.number(),\n      total_tokens: z.number(),\n    })\n    .nullable()\n    .optional(),\n});\ntype OpenAIStreamChatResponseType = z.infer<typeof OpenAIStreamChatResponse>;\n\nexport {\n  OpenAIStreamChatResponse,\n  OpenAICompleteChatResponse,\n  OpenAIToolCallsStreamChatResponse,\n  OpenAIToolCallsCompleteChatResponse,\n  type OpenAIStreamChatResponseType,\n  type OpenAICompleteChatResponseType,\n};\n","import { z } from \"zod\";\n\nconst OpenAIChatRequestTool = z.object({\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n    description: z.string().min(1).optional(),\n    strict: z.boolean().optional(),\n    parameters: z.any(),\n  }),\n});\ntype OpenAIChatRequestToolType = z.infer<typeof OpenAIChatRequestTool>;\n\nconst OpenAIChatRequestToolChoiceEnum = z.enum([\"none\", \"auto\", \"required\"]);\ntype OpenAIChatRequestToolChoiceEnumType = z.infer<typeof OpenAIChatRequestToolChoiceEnum>;\n\nconst OpenAIChatRequestToolChoiceFunction = z.object({\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n  }),\n});\ntype OpenAIChatRequestToolChoiceFunctionType = z.infer<typeof OpenAIChatRequestToolChoiceFunction>;\n\nconst OpenAIChatRequestResponseFormat = z\n  .object({\n    type: z.enum([\"text\", \"json_object\"]),\n  })\n  .or(\n    z.object({\n      type: z.literal(\"json_schema\"),\n      json_schema: z.object({\n        name: z.string().min(1),\n        description: z.string().min(1).optional(),\n        strict: z.boolean().optional(),\n        schema: z.any(),\n      }),\n    })\n  );\ntype OpenAIChatRequestResponseFormatType = z.infer<typeof OpenAIChatRequestResponseFormat>;\n\nconst OpenAIChatRequestTextContent = z.object({\n  text: z.string().min(1),\n  type: z.literal(\"text\"),\n});\ntype OpenAIChatRequestTextContentType = z.infer<typeof OpenAIChatRequestTextContent>;\n\nconst OpenAIChatRequestImageContent = z.object({\n  type: z.literal(\"image_url\"),\n  image_url: z.object({\n    url: z.string().url().min(1),\n    detail: z.enum([\"low\", \"high\", \"auto\"]).optional(),\n  }),\n});\ntype OpenAIChatRequestImageContentType = z.infer<typeof OpenAIChatRequestImageContent>;\n\nconst OpenAIChatRequestToolCallContent = z.object({\n  id: z.string().min(1),\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n    arguments: z.string().min(1),\n  }),\n});\ntype OpenAIChatRequestToolCallContentType = z.infer<typeof OpenAIChatRequestToolCallContent>;\n\nconst OpenAIChatRequestSystemMessage = z.object({\n  role: z.literal(\"system\"),\n  content: z.string().min(1).or(z.array(OpenAIChatRequestTextContent).min(1)),\n});\ntype OpenAIChatRequestSystemMessageType = z.infer<typeof OpenAIChatRequestSystemMessage>;\n\nconst OpenAIChatRequestUserMessage = z.object({\n  role: z.literal(\"user\"),\n  content: z\n    .string()\n    .min(1)\n    .or(z.array(z.union([OpenAIChatRequestTextContent, OpenAIChatRequestImageContent])).min(1)),\n});\ntype OpenAIChatRequestUserMessageType = z.infer<typeof OpenAIChatRequestUserMessage>;\n\nconst OpenAIChatRequestAssistantMessage = z.object({\n  role: z.literal(\"assistant\"),\n  content: z.string().min(1).or(z.array(OpenAIChatRequestTextContent).min(1)).optional(),\n  tool_calls: z.array(OpenAIChatRequestToolCallContent).min(1).optional(),\n});\ntype OpenAIChatRequestAssistantMessageType = z.infer<typeof OpenAIChatRequestAssistantMessage>;\n\nconst OpenAIChatRequestToolMessage = z.object({\n  role: z.literal(\"tool\"),\n  tool_call_id: z.string().min(1),\n  content: z.string().min(1),\n});\ntype OpenAIChatRequestToolMessageType = z.infer<typeof OpenAIChatRequestToolMessage>;\n\nconst OpenAIChatRequestMessage = z.union([\n  OpenAIChatRequestSystemMessage,\n  OpenAIChatRequestUserMessage,\n  OpenAIChatRequestAssistantMessage,\n  OpenAIChatRequestToolMessage,\n]);\ntype OpenAIChatRequestMessageType = z.infer<typeof OpenAIChatRequestMessage>;\n\nconst OpenAIChatRequest = z.object({\n  model: z.string().min(1).optional(),\n  messages: z.array(OpenAIChatRequestMessage).min(1),\n  frequency_penalty: z.number().min(-2).max(2).nullable().optional(),\n  logprobs: z.boolean().nullable().optional(),\n  top_logprobs: z.number().min(0).max(20).nullable().optional(),\n  max_tokens: z.number().min(0).nullable().optional(),\n  presence_penalty: z.number().min(-2).max(2).nullable().optional(),\n  response_format: OpenAIChatRequestResponseFormat.optional(),\n  seed: z.number().nullable().optional(),\n  stop: z.string().or(z.array(z.string()).max(4)).nullable().optional(),\n  temperature: z.number().min(0).max(2).nullable().optional(),\n  top_p: z.number().min(0).max(1).nullable().optional(),\n  tools: z.array(OpenAIChatRequestTool).optional(),\n  tool_choice: OpenAIChatRequestToolChoiceEnum.or(OpenAIChatRequestToolChoiceFunction).optional(),\n});\ntype OpenAIChatRequestType = z.infer<typeof OpenAIChatRequest>;\n\nexport {\n  OpenAIChatRequest,\n  OpenAIChatRequestMessage,\n  OpenAIChatRequestSystemMessage,\n  OpenAIChatRequestUserMessage,\n  OpenAIChatRequestAssistantMessage,\n  OpenAIChatRequestToolMessage,\n  OpenAIChatRequestTextContent,\n  OpenAIChatRequestImageContent,\n  OpenAIChatRequestToolCallContent,\n  OpenAIChatRequestTool,\n  OpenAIChatRequestToolChoiceEnum,\n  OpenAIChatRequestToolChoiceFunction,\n  OpenAIChatRequestResponseFormat,\n  type OpenAIChatRequestType,\n  type OpenAIChatRequestMessageType,\n  type OpenAIChatRequestSystemMessageType,\n  type OpenAIChatRequestUserMessageType,\n  type OpenAIChatRequestAssistantMessageType,\n  type OpenAIChatRequestToolMessageType,\n  type OpenAIChatRequestTextContentType,\n  type OpenAIChatRequestImageContentType,\n  type OpenAIChatRequestToolCallContentType,\n  type OpenAIChatRequestToolType,\n  type OpenAIChatRequestToolChoiceEnumType,\n  type OpenAIChatRequestToolChoiceFunctionType,\n  type OpenAIChatRequestResponseFormatType,\n};\n","import { z } from \"zod\";\n\nimport { OpenAIChatRequest } from \"./request.chat-model.openai\";\n\nconst OpenAIChatOSeriesRequest = OpenAIChatRequest.omit({ max_tokens: true }).extend({\n  max_completion_tokens: z.number().min(0).nullable().optional(),\n});\ntype OpenAIChatOSeriesRequestType = z.infer<typeof OpenAIChatOSeriesRequest>;\n\nexport { OpenAIChatOSeriesRequest, type OpenAIChatOSeriesRequestType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchemaType, ChatModelV1, EmbeddingModelSchemaType, EmbeddingModelV1, ProviderError, ProviderV1 } from \"@adaline/provider\";\n\nimport * as Models from \"../models\";\n\nconst ProviderLiteral = \"openai\";\nclass OpenAI<C extends Models.BaseChatModelOptionsType, E extends Models.BaseEmbeddingModelOptionsType> implements ProviderV1<C, E> {\n  readonly version = \"v1\" as const;\n  readonly name = ProviderLiteral;\n  static readonly baseUrl = \"https://api.openai.com/v1\";\n\n  private readonly chatModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): ChatModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: ChatModelSchemaType;\n    }\n  > = {\n    [Models.GPT_3_5_TurboLiteral]: {\n      model: Models.GPT_3_5_Turbo,\n      modelOptions: Models.GPT_3_5_TurboOptions,\n      modelSchema: Models.GPT_3_5_TurboSchema,\n    },\n    [Models.GPT_3_5_Turbo_0125Literal]: {\n      model: Models.GPT_3_5_Turbo_0125,\n      modelOptions: Models.GPT_3_5_Turbo_0125Options,\n      modelSchema: Models.GPT_3_5_Turbo_0125Schema,\n    },\n    [Models.GPT_3_5_Turbo_1106Literal]: {\n      model: Models.GPT_3_5_Turbo_1106,\n      modelOptions: Models.GPT_3_5_Turbo_1106Options,\n      modelSchema: Models.GPT_3_5_Turbo_1106Schema,\n    },\n    [Models.GPT_4_0125_PreviewLiteral]: {\n      model: Models.GPT_4_0125_Preview,\n      modelOptions: Models.GPT_4_0125_PreviewOptions,\n      modelSchema: Models.GPT_4_0125_PreviewSchema,\n    },\n    [Models.GPT_4_0613Literal]: {\n      model: Models.GPT_4_0613,\n      modelOptions: Models.GPT_4_0613Options,\n      modelSchema: Models.GPT_4_0613Schema,\n    },\n    [Models.GPT_4_1106_PreviewLiteral]: {\n      model: Models.GPT_4_1106_Preview,\n      modelOptions: Models.GPT_4_1106_PreviewOptions,\n      modelSchema: Models.GPT_4_1106_PreviewSchema,\n    },\n    [Models.GPT_4_Turbo_2024_04_09Literal]: {\n      model: Models.GPT_4_Turbo_2024_04_09,\n      modelOptions: Models.GPT_4_Turbo_2024_04_09Options,\n      modelSchema: Models.GPT_4_Turbo_2024_04_09Schema,\n    },\n    [Models.GPT_4_Turbo_PreviewLiteral]: {\n      model: Models.GPT_4_Turbo_Preview,\n      modelOptions: Models.GPT_4_Turbo_PreviewOptions,\n      modelSchema: Models.GPT_4_Turbo_PreviewSchema,\n    },\n    [Models.GPT_4_TurboLiteral]: {\n      model: Models.GPT_4_Turbo,\n      modelOptions: Models.GPT_4_TurboOptions,\n      modelSchema: Models.GPT_4_TurboSchema,\n    },\n    [Models.GPT_4Literal]: {\n      model: Models.GPT_4,\n      modelOptions: Models.GPT_4Options,\n      modelSchema: Models.GPT_4Schema,\n    },\n    [Models.GPT_4o_2024_08_06Literal]: {\n      model: Models.GPT_4o_2024_08_06,\n      modelOptions: Models.GPT_4o_2024_08_06Options,\n      modelSchema: Models.GPT_4o_2024_08_06Schema,\n    },\n    [Models.GPT_4o_MiniLiteral]: {\n      model: Models.GPT_4o_Mini,\n      modelOptions: Models.GPT_4o_MiniOptions,\n      modelSchema: Models.GPT_4o_MiniSchema,\n    },\n    [Models.GPT_4oLiteral]: {\n      model: Models.GPT_4o,\n      modelOptions: Models.GPT_4oOptions,\n      modelSchema: Models.GPT_4oSchema,\n    },\n    [Models.GPT_4o_Mini_2024_07_18Literal]: {\n      model: Models.GPT_4o_Mini_2024_07_18,\n      modelOptions: Models.GPT_4o_Mini_2024_07_18Options,\n      modelSchema: Models.GPT_4o_Mini_2024_07_18Schema,\n    },\n    [Models.GPT_4o_2024_05_13Literal]: {\n      model: Models.GPT_4o_2024_05_13,\n      modelOptions: Models.GPT_4o_2024_05_13Options,\n      modelSchema: Models.GPT_4o_2024_05_13Schema,\n    },\n    [Models.O1_MiniLiteral]: {\n      model: Models.O1_Mini,\n      modelOptions: Models.O1_MiniOptions,\n      modelSchema: Models.O1_MiniSchema,\n    },\n    [Models.O1_PreviewLiteral]: {\n      model: Models.O1_Preview,\n      modelOptions: Models.O1_PreviewOptions,\n      modelSchema: Models.O1_PreviewSchema,\n    },\n    [Models.O1Literal]: {\n      model: Models.O1,\n      modelOptions: Models.O1Options,\n      modelSchema: Models.O1Schema,\n    },\n    [Models.O1_2024_12_17Literal]: {\n      model: Models.O1_2024_12_17,\n      modelOptions: Models.O1_2024_12_17Options,\n      modelSchema: Models.O1_2024_12_17Schema,\n    },\n    [Models.O1_Mini_2024_09_12Literal]: {\n      model: Models.O1_Mini_2024_09_12,\n      modelOptions: Models.O1_Mini_2024_09_12Options,\n      modelSchema: Models.O1_Mini_2024_09_12Schema,\n    },\n  };\n\n  private readonly embeddingModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): EmbeddingModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: EmbeddingModelSchemaType;\n    }\n  > = {\n    [Models.Text_Embedding_Ada002Literal]: {\n      model: Models.Text_Embedding_Ada002,\n      modelOptions: Models.Text_Embedding_Ada002_Options,\n      modelSchema: Models.Text_Embedding_Ada002Schema,\n    },\n    [Models.Text_Embedding_3_SmallLiteral]: {\n      model: Models.Text_Embedding_3_Small,\n      modelOptions: Models.Text_Embedding_3_Small_Options,\n      modelSchema: Models.Text_Embedding_3_SmallSchema,\n    },\n    [Models.Text_Embedding_3_LargeLiteral]: {\n      model: Models.Text_Embedding_3_Large,\n      modelOptions: Models.Text_Embedding_3_Large_Options,\n      modelSchema: Models.Text_Embedding_3_LargeSchema,\n    },\n  };\n\n  chatModelLiterals(): string[] {\n    return Object.keys(this.chatModelFactories);\n  }\n\n  chatModelSchemas(): Record<string, ChatModelSchemaType> {\n    return Object.keys(this.chatModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.chatModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, ChatModelSchemaType>\n    );\n  }\n\n  chatModel(options: C): ChatModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.chatModelFactories)) {\n      throw new ProviderError({\n        info: `OpenAI chat model: ${modelName} not found`,\n        cause: new Error(`OpenAI chat model: ${modelName} not found, available chat models: \n          [${this.chatModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.chatModelFactories[modelName].model;\n    const parsedOptions = this.chatModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n\n  embeddingModelLiterals(): string[] {\n    return Object.keys(this.embeddingModelFactories);\n  }\n\n  embeddingModelSchemas(): Record<string, EmbeddingModelSchemaType> {\n    return Object.keys(this.embeddingModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.embeddingModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, EmbeddingModelSchemaType>\n    );\n  }\n\n  embeddingModel(options: E): EmbeddingModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.embeddingModelFactories)) {\n      throw new ProviderError({\n        info: `OpenAI embedding model: ${modelName} not found`,\n        cause: new Error(`OpenAI embedding model: ${modelName} not found, available embedding models: \n          [${this.embeddingModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.embeddingModelFactories[modelName].model;\n    const parsedOptions = this.embeddingModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n}\n\nexport { OpenAI, ProviderLiteral };\n","import { z } from \"zod\";\n\nimport {\n  ChatModelSchemaType,\n  ChatModelV1,\n  getMimeTypeFromBase64,\n  HeadersType,\n  InvalidConfigError,\n  InvalidMessagesError,\n  InvalidModelRequestError,\n  InvalidToolsError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  SelectStringConfigItemDefType,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\n\nimport {\n  AssistantRoleLiteral,\n  Base64ImageContentTypeLiteral,\n  Base64ImageContentValueType,\n  ChatLogProbsType,\n  ChatResponseType,\n  ChatUsageType,\n  Config,\n  ConfigType,\n  ContentType,\n  createTextContent,\n  createToolCallContent,\n  createPartialTextMessage,\n  createPartialToolCallMessage,\n  ImageModalityLiteral,\n  Message,\n  MessageType,\n  PartialChatResponseType,\n  SystemRoleLiteral,\n  TextModalityLiteral,\n  Tool,\n  ToolCallContentType,\n  ToolCallModalityLiteral,\n  ToolResponseContentType,\n  ToolResponseModalityLiteral,\n  ToolRoleLiteral,\n  ToolType,\n  UrlImageContentTypeLiteral,\n  UserRoleLiteral,\n} from \"@adaline/types\";\n\nimport {\n  OpenAIChatRequest,\n  OpenAIChatRequestImageContentType,\n  OpenAIChatRequestTextContentType,\n  OpenAIChatRequestToolType,\n  OpenAIChatRequestType,\n  OpenAICompleteChatResponse,\n  OpenAICompleteChatResponseType,\n  OpenAIStreamChatResponse,\n  OpenAIStreamChatResponseType,\n} from \"./types\";\n\nimport { OpenAI } from \"./../../provider/provider.openai\";\n\nconst BaseChatModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  completeChatUrl: z.string().url().optional(),\n  streamChatUrl: z.string().url().optional(),\n  organization: z.string().optional(),\n});\ntype BaseChatModelOptionsType = z.infer<typeof BaseChatModelOptions>;\n\nclass BaseChatModel implements ChatModelV1<ChatModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: ChatModelSchemaType;\n  modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly streamChatUrl: string;\n  private readonly completeChatUrl: string;\n  private readonly organization: string | undefined;\n\n  constructor(modelSchema: ChatModelSchemaType, options: BaseChatModelOptionsType) {\n    const parsedOptions = BaseChatModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || OpenAI.baseUrl);\n    this.streamChatUrl = urlWithoutTrailingSlash(parsedOptions.streamChatUrl || `${this.baseUrl}/chat/completions`);\n    this.completeChatUrl = urlWithoutTrailingSlash(parsedOptions.completeChatUrl || `${this.baseUrl}/chat/completions`);\n    this.organization = parsedOptions.organization;\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      Authorization: `Bearer ${this.apiKey}`,\n      \"Content-Type\": \"application/json\",\n      ...(this.organization ? { \"OpenAI-Organization\": this.organization } : {}),\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelName,\n    };\n  }\n\n  // x-ratelimit-limit-requests\tThe maximum number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-limit-tokens\tThe maximum number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-requests The remaining number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-tokens\tThe remaining number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-reset-requests\tThe time until the rate limit (based on requests) resets to its initial state.\n  // x-ratelimit-reset-tokens\tThe time until the rate limit (based on tokens) resets to its initial state.\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    // parse duration from header value of format \"6m0s\" or \"21s\" or \"41ms\" or \"2s81ms\" or \"5h50m30ms\" and such\n    const parseDuration = (duration: string): number => {\n      const regex = /(\\d+)(h|m|s|ms)/g;\n      const timeUnits: { [unit: string]: number } = {\n        h: 3600000, // 1 hour = 60 * 60 * 1000 ms\n        m: 60000, // 1 minute = 60 * 1000 ms\n        s: 1000, // 1 second = 1000 ms\n        ms: 1, // milliseconds\n      };\n\n      let match;\n      let totalMs = 0;\n      while ((match = regex.exec(duration)) !== null) {\n        const value = parseInt(match[1]);\n        const unit = match[2];\n        totalMs += value * timeUnits[unit];\n      }\n\n      return totalMs;\n    };\n\n    let resetRequestsDelayMs = 0;\n    let resetTokensDelayMs = 0;\n    const shouldRetry = true;\n    if (responseHeaders[\"x-ratelimit-reset-requests\"]) {\n      resetRequestsDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-requests\"]);\n    }\n    if (responseHeaders[\"x-ratelimit-reset-tokens\"]) {\n      resetTokensDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-tokens\"]);\n    }\n\n    // if rate limited by requests, then it's reset must be the higher of two and visa versa\n    const delayMs = Math.max(resetRequestsDelayMs, resetTokensDelayMs);\n    return { shouldRetry, delayMs };\n  }\n\n  getTokenCount(messages: MessageType[]): number {\n    return messages.reduce((acc, message) => {\n      return acc + message.content.map((content) => (content.modality === \"text\" ? content.value : \"\")).join(\" \").length;\n    }, 0);\n  }\n\n  transformModelRequest(request: OpenAIChatRequestType): {\n    modelName: string | undefined;\n    config: ConfigType;\n    messages: MessageType[];\n    tools: ToolType[] | undefined;\n  } {\n    const safeRequest = OpenAIChatRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    if (parsedRequest.tool_choice && (!parsedRequest.tools || parsedRequest.tools.length === 0)) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'tools' are required when 'tool_choice' is specified\"),\n      });\n    }\n\n    const _config: ConfigType = {};\n    if (parsedRequest.response_format) {\n      _config.responseFormat = parsedRequest.response_format.type;\n      if (parsedRequest.response_format.type === \"json_schema\") {\n        _config.responseSchema = {\n          name: parsedRequest.response_format.json_schema.name,\n          description: parsedRequest.response_format.json_schema.description || \"\",\n          strict: parsedRequest.response_format.json_schema.strict,\n          schema: parsedRequest.response_format.json_schema.schema,\n        };\n      }\n    }\n\n    if (parsedRequest.tool_choice) {\n      if (typeof parsedRequest.tool_choice === \"string\") {\n        _config.toolChoice = parsedRequest.tool_choice;\n      } else {\n        _config.toolChoice = parsedRequest.tool_choice.function.name;\n      }\n    }\n\n    _config.seed = parsedRequest.seed;\n    _config.maxTokens = parsedRequest.max_tokens;\n    _config.temperature = parsedRequest.temperature;\n    _config.topP = parsedRequest.top_p;\n    _config.presencePenalty = parsedRequest.presence_penalty;\n    _config.frequencyPenalty = parsedRequest.frequency_penalty;\n    _config.stop = parsedRequest.stop;\n    _config.logProbs = parsedRequest.logprobs;\n    _config.topLogProbs = parsedRequest.top_logprobs;\n\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    const messages: MessageType[] = [];\n    const toolCallMap: { [id: string]: ToolCallContentType } = {};\n    parsedRequest.messages.forEach((message) => {\n      const role = message.role;\n      switch (role) {\n        case \"system\":\n          {\n            const content = message.content as string | OpenAIChatRequestTextContentType[];\n            if (typeof content === \"string\") {\n              messages.push({\n                role: role,\n                content: [{ modality: TextModalityLiteral, value: content }],\n              });\n            } else {\n              const _content = content.map((c) => {\n                return { modality: TextModalityLiteral, value: c.text };\n              });\n              messages.push({ role: role, content: _content });\n            }\n          }\n          break;\n\n        case \"user\":\n          {\n            const content = message.content as string | (OpenAIChatRequestTextContentType | OpenAIChatRequestImageContentType)[];\n            if (typeof content === \"string\") {\n              messages.push({\n                role: role,\n                content: [{ modality: TextModalityLiteral, value: content }],\n              });\n            } else {\n              const _content = content.map((c) => {\n                if (c.type === \"text\") {\n                  return { modality: TextModalityLiteral, value: c.text };\n                } else {\n                  if (c.image_url.url.startsWith(\"data:\")) {\n                    return {\n                      modality: ImageModalityLiteral,\n                      detail: c.image_url.detail || \"auto\",\n                      value: {\n                        type: Base64ImageContentTypeLiteral,\n                        base64: c.image_url.url,\n                        media_type: getMimeTypeFromBase64(c.image_url.url) as Base64ImageContentValueType[\"media_type\"],\n                      },\n                    };\n                  } else {\n                    return {\n                      modality: ImageModalityLiteral,\n                      detail: c.image_url.detail || \"auto\",\n                      value: { type: UrlImageContentTypeLiteral, url: c.image_url.url },\n                    };\n                  }\n                }\n              });\n              messages.push({ role: role, content: _content });\n            }\n          }\n          break;\n\n        case \"assistant\":\n          {\n            const assistantContent: ContentType[] = [];\n\n            if (!message.content && !message.tool_calls) {\n              throw new InvalidModelRequestError({\n                info: `Invalid model request for model : '${this.modelName}'`,\n                cause: new Error(\"one of'content' or 'tool_calls' must be provided\"),\n              });\n            }\n\n            if (message.content) {\n              const content = message.content as string | OpenAIChatRequestTextContentType[];\n              if (typeof content === \"string\") {\n                assistantContent.push({ modality: TextModalityLiteral, value: content });\n              } else {\n                content.forEach((c) => {\n                  assistantContent.push({ modality: TextModalityLiteral, value: c.text });\n                });\n              }\n            }\n\n            if (message.tool_calls) {\n              const toolCalls = message.tool_calls;\n              toolCalls.forEach((toolCall, index) => {\n                const toolCallContent: ToolCallContentType = {\n                  modality: ToolCallModalityLiteral,\n                  id: toolCall.id,\n                  index: index,\n                  name: toolCall.function.name,\n                  arguments: toolCall.function.arguments,\n                };\n                assistantContent.push(toolCallContent);\n                toolCallMap[toolCallContent.id] = toolCallContent;\n              });\n            }\n            messages.push({ role: role, content: assistantContent });\n          }\n          break;\n\n        case \"tool\":\n          {\n            const toolResponse = message;\n            messages.push({\n              role: role,\n              content: [\n                {\n                  modality: ToolResponseModalityLiteral,\n                  id: toolResponse.tool_call_id,\n                  index: toolCallMap[toolResponse.tool_call_id].index,\n                  name: toolCallMap[toolResponse.tool_call_id].name,\n                  data: toolResponse.content,\n                },\n              ],\n            });\n          }\n          break;\n      }\n    });\n\n    const tools: ToolType[] = [];\n    if (parsedRequest.tools) {\n      parsedRequest.tools.forEach((tool: OpenAIChatRequestToolType) => {\n        tools.push({\n          type: \"function\",\n          definition: {\n            schema: {\n              name: tool.function.name,\n              description: tool.function.description || \"\",\n              strict: tool.function.strict,\n              parameters: tool.function.parameters,\n            },\n          },\n        });\n      });\n    }\n\n    return {\n      modelName,\n      config,\n      messages,\n      tools: tools.length > 0 ? tools : undefined,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, messages?: MessageType[], tools?: ToolType[]): ParamsType {\n    const _toolChoice = config.toolChoice;\n    delete config.toolChoice; // can have a specific tool name that is not in the model schema, validated at transformation\n\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    if (_toolChoice !== undefined) {\n      parsedConfig.toolChoice = _toolChoice;\n    }\n\n    Object.keys(parsedConfig).forEach((key) => {\n      if (!(key in this.modelSchema.config.def)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = (parsedConfig as ConfigType)[key];\n\n      if (paramKey === \"max_tokens\" && def.type === \"range\" && paramValue === 0) {\n        acc[paramKey] = def.max;\n      } else {\n        acc[paramKey] = paramValue;\n      }\n\n      return acc;\n    }, {} as ParamsType);\n\n    if (transformedConfig.top_logprobs && !transformedConfig.logprobs) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: new Error(\"'logprobs' must be 'true' when 'top_logprobs' is specified\"),\n      });\n    }\n\n    if (\"tool_choice\" in transformedConfig && transformedConfig.tool_choice !== undefined) {\n      const toolChoice = transformedConfig.tool_choice as string;\n      if (!tools || (tools && tools.length === 0)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(\"'tools' are required when 'toolChoice' is specified\"),\n        });\n      } else if (tools && tools.length > 0) {\n        const configToolChoice = this.modelSchema.config.def.toolChoice as SelectStringConfigItemDefType;\n        if (!configToolChoice.choices.includes(toolChoice)) {\n          if (tools.map((tool) => tool.definition.schema.name).includes(toolChoice)) {\n            transformedConfig.tool_choice = { type: \"function\", function: { name: toolChoice } };\n          } else {\n            throw new InvalidConfigError({\n              info: `Invalid config for model : '${this.modelName}'`,\n              cause: new Error(`toolChoice : '${toolChoice}' is not part of provided 'tools' names or \n                one of [${configToolChoice.choices.join(\", \")}]`),\n            });\n          }\n        }\n      }\n    }\n\n    if (\"response_format\" in transformedConfig && transformedConfig.response_format !== undefined) {\n      const responseFormat = transformedConfig.response_format as string;\n      if (responseFormat === \"json_schema\") {\n        if (!(\"response_schema\" in transformedConfig)) {\n          throw new InvalidConfigError({\n            info: `Invalid config for model : '${this.modelName}'`,\n            cause: new Error(\"'responseSchema' is required in config when 'responseFormat' is 'json_schema'\"),\n          });\n        } else {\n          transformedConfig.response_format = {\n            type: \"json_schema\",\n            json_schema: transformedConfig.response_schema,\n          };\n          delete transformedConfig.response_schema;\n        }\n      } else {\n        transformedConfig.response_format = { type: responseFormat };\n      }\n    }\n\n    return transformedConfig;\n  }\n\n  transformMessages(messages: MessageType[]): ParamsType {\n    if (!messages || (messages && messages.length === 0)) {\n      return { messages: [] };\n    }\n\n    const parsedMessages = messages.map((message) => {\n      const parsedMessage = Message().safeParse(message);\n      if (!parsedMessage.success) {\n        throw new InvalidMessagesError({ info: \"Invalid messages\", cause: parsedMessage.error });\n      }\n      return parsedMessage.data;\n    });\n\n    parsedMessages.forEach((message) => {\n      message.content.forEach((content) => {\n        if (!this.modelSchema.modalities.includes(content.modality)) {\n          throw new InvalidMessagesError({\n            info: `Invalid message content for model : '${this.modelName}'`,\n            cause: new Error(`model : '${this.modelName}' does not support modality : '${content.modality}', \n              available modalities : [${this.modelSchema.modalities.join(\", \")}]`),\n          });\n        }\n      });\n    });\n\n    parsedMessages.forEach((message) => {\n      if (!Object.keys(this.modelSchema.roles).includes(message.role)) {\n        throw new InvalidMessagesError({\n          info: `Invalid message content for model : '${this.modelName}'`,\n          cause: new Error(`model : '${this.modelName}' does not support role : '${message.role}', \n            available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedMessages = parsedMessages.map((message) => {\n      switch (message.role) {\n        case SystemRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: textContent,\n          };\n        }\n\n        case AssistantRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          const toolCalls: { id: string; type: \"function\"; function: { name: string; arguments: string } }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else if (content.modality === ToolCallModalityLiteral) {\n              toolCalls.push({\n                id: content.id,\n                type: \"function\",\n                function: { name: content.name, arguments: content.arguments },\n              });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: textContent,\n            ...(toolCalls.length > 0 ? { tool_calls: toolCalls } : {}),\n          };\n        }\n\n        case UserRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          const imageContent: { type: \"image_url\"; image_url: { url: string; detail: string } }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else if (content.modality === ImageModalityLiteral) {\n              imageContent.push({\n                type: \"image_url\",\n                image_url: {\n                  url: content.value.type === \"url\" ? content.value.url : content.value.base64,\n                  detail: content.detail,\n                },\n              });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          const combinedContent = [...textContent, ...imageContent];\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: combinedContent,\n          };\n        }\n\n        case ToolRoleLiteral: {\n          if (message.content.length !== 1) {\n            throw new InvalidMessagesError({\n              info: `Invalid message for role : '${message.role}'`,\n              cause: new Error(`role : '${message.role}' must have exactly one content item`),\n            });\n          }\n\n          if (message.content[0].modality !== ToolResponseModalityLiteral) {\n            throw new InvalidMessagesError({\n              info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n              cause: new Error(`role : '${message.role}' must have content with modality : '${ToolResponseModalityLiteral}'`),\n            });\n          }\n\n          const toolResponse = message.content[0] as ToolResponseContentType;\n          return {\n            role: this.modelSchema.roles[message.role],\n            tool_call_id: toolResponse.id,\n            content: toolResponse.data,\n          };\n        }\n\n        default: {\n          throw new InvalidMessagesError({\n            info: `Invalid message 'role' for model : ${this.modelName}`,\n            cause: new Error(`role : '${message.role}' is not supported, \n              available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n          });\n        }\n      }\n    });\n\n    return { messages: transformedMessages };\n  }\n\n  transformTools(tools: ToolType[]): ParamsType {\n    if (!this.modelSchema.modalities.includes(ToolCallModalityLiteral)) {\n      throw new InvalidToolsError({\n        info: `Invalid tool 'modality' for model : ${this.modelName}`,\n        cause: new Error(`model : '${this.modelName}' does not support tool modality : '${ToolCallModalityLiteral}'`),\n      });\n    }\n\n    if (!tools || (tools && tools.length === 0)) {\n      return { tools: [] as ToolType[] };\n    }\n\n    const parsedTools = tools.map((tool) => {\n      const parsedTool = Tool().safeParse(tool);\n      if (!parsedTool.success) {\n        throw new InvalidToolsError({ info: \"Invalid tools\", cause: parsedTool.error });\n      }\n      return parsedTool.data;\n    });\n\n    const transformedTools = parsedTools.map((tool) => ({\n      type: \"function\",\n      function: tool.definition.schema,\n    }));\n\n    return { tools: transformedTools };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getCompleteChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  transformCompleteChatResponse(response: any): ChatResponseType {\n    const safe = OpenAICompleteChatResponse.safeParse(response);\n    if (safe.success) {\n      if (safe.data.choices.length === 0) {\n        throw new ModelResponseError({\n          info: \"Invalid response from model\",\n          cause: new Error(`No choices in response : ${JSON.stringify(safe.data)}`),\n        });\n      }\n\n      const parsedResponse: OpenAICompleteChatResponseType = safe.data;\n      const messages: MessageType[] = [\n        {\n          role: AssistantRoleLiteral,\n          content: [],\n        },\n      ];\n      const message = parsedResponse.choices[0].message;\n      if (message.content) {\n        messages[0].content.push(createTextContent(message.content));\n      }\n\n      if (message.refusal) {\n        messages[0].content.push(createTextContent(message.refusal));\n      }\n\n      if (message.tool_calls) {\n        message.tool_calls.forEach((toolCall, index) => {\n          messages[0].content.push(\n            createToolCallContent(\n              index,\n              toolCall.id,\n              toolCall.function.name,\n              toolCall.function.arguments\n            )\n          );\n        });\n      }\n\n      const usage: ChatUsageType = {\n        promptTokens: parsedResponse.usage.prompt_tokens,\n        completionTokens: parsedResponse.usage.completion_tokens,\n        totalTokens: parsedResponse.usage.total_tokens,\n      };\n\n      const logProbs: ChatLogProbsType = [];\n      const _logProbs = parsedResponse.choices[0].logprobs;\n      if (_logProbs) {\n        if (_logProbs.content) {\n          logProbs.push(\n            ..._logProbs.content.map((logProb) => ({\n              token: logProb.token,\n              logProb: logProb.logprob,\n              bytes: logProb.bytes,\n              topLogProbs: logProb.top_logprobs.map((topLogProb) => ({\n                token: topLogProb.token,\n                logProb: topLogProb.logprob,\n                bytes: topLogProb.bytes,\n              })),\n            }))\n          );\n        }\n        if (_logProbs.refusal) {\n          logProbs.push(\n            ..._logProbs.refusal.map((logProb) => ({\n              token: logProb.token,\n              logProb: logProb.logprob,\n              bytes: logProb.bytes,\n              topLogProbs: logProb.top_logprobs.map((topLogProb) => ({\n                token: topLogProb.token,\n                logProb: topLogProb.logprob,\n                bytes: topLogProb.bytes,\n              })),\n            }))\n          );\n        }\n      }\n\n      return {\n        messages: messages,\n        usage: usage,\n        logProbs: logProbs,\n      };\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.streamChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getStreamChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        stream: true,\n        stream_options: { include_usage: true },\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  async *transformStreamChatResponseChunk(\n    chunk: string,\n    buffer: string\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    // merge last buffer message and split into lines\n    const lines = (buffer + chunk).split(\"\\n\").filter((line) => line.trim() !== \"\");\n    for (const line of lines) {\n      if (line === \"data: [DONE]\") {\n        // end of stream\n        return;\n      } else if (line.startsWith(\"data: {\") && line.endsWith(\"}\")) {\n        // line contains message\n        let structuredLine: any;\n        try {\n          // remove the 'data :' prefix from string JSON\n          structuredLine = JSON.parse(line.substring(\"data: \".length));\n        } catch (error) {\n          // malformed JSON error\n          throw new ModelResponseError({\n            info: `Malformed JSON received in stream : ${structuredLine}`,\n            cause: error,\n          });\n        }\n\n        const safe = OpenAIStreamChatResponse.safeParse(structuredLine);\n        if (safe.success) {\n          const partialResponse: PartialChatResponseType = { partialMessages: [] };\n          const parsedResponse: OpenAIStreamChatResponseType = safe.data;\n          if (parsedResponse.choices.length > 0) {\n            const message = parsedResponse.choices[0].delta;\n            if (message !== undefined && Object.keys(message).length !== 0) {\n              if (\"content\" in message && message.content !== null) {\n                partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, message.content as string));\n              } else if (\"refusal\" in message && message.refusal !== null) {\n                partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, message.refusal as string));\n              } else if (\"tool_calls\" in message && message.tool_calls !== undefined) {\n                const toolCall = message.tool_calls.at(0)!;\n                partialResponse.partialMessages.push(\n                  createPartialToolCallMessage(\n                    AssistantRoleLiteral,\n                    toolCall.index,\n                    toolCall.id,\n                    toolCall.function?.name,\n                    toolCall.function?.arguments\n                  )\n                );\n              }\n            }\n          }\n\n          if (parsedResponse.usage) {\n            partialResponse.usage = {\n              promptTokens: parsedResponse.usage.prompt_tokens,\n              completionTokens: parsedResponse.usage.completion_tokens,\n              totalTokens: parsedResponse.usage.total_tokens,\n            };\n          }\n\n          yield { partialResponse: partialResponse, buffer: buffer };\n        } else {\n          throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n        }\n      } else {\n        // line starts with unknown event -- ignore\n      }\n    }\n  }\n}\n\nexport { BaseChatModel, BaseChatModelOptions, type BaseChatModelOptionsType };\n","import { ChatModelSchemaType, HeadersType, InvalidModelRequestError, ModelError, ParamsType, UrlType } from \"@adaline/provider\";\nimport { ConfigType, MessageType, PartialChatResponseType, ToolType } from \"@adaline/types\";\n\nimport { BaseChatModel, BaseChatModelOptionsType } from \"./base-chat-model.openai\";\nimport { OpenAIChatOSeriesRequest, OpenAIChatOSeriesRequestType } from \"./types\";\n\nclass BaseOSeriesChatModel extends BaseChatModel {\n  constructor(modelSchema: ChatModelSchemaType, options: BaseChatModelOptionsType) {\n    super(modelSchema, options);\n  }\n\n  transformModelRequest(request: OpenAIChatOSeriesRequestType): {\n    modelName: string | undefined;\n    config: ConfigType;\n    messages: MessageType[];\n    tools: ToolType[] | undefined;\n  } {\n    const safeRequest = OpenAIChatOSeriesRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n    const baseRequest = {\n      ...parsedRequest,\n      max_tokens: parsedRequest.max_completion_tokens,\n    };\n    delete baseRequest.max_completion_tokens;\n\n    return super.transformModelRequest(baseRequest);\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformTools(tools: ToolType[]): ParamsType {\n    throw new ModelError({\n      info: `Model: '${this.modelSchema.name}' does not support 'tools'.`,\n      cause: new Error(`Model: '${this.modelSchema.name}' does not support 'tools'.`),\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    throw new ModelError({\n      info: `Model: '${this.modelSchema.name}' does not support streaming.`,\n      cause: new Error(`Model: '${this.modelSchema.name}' does not support streaming.`),\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    throw new ModelError({\n      info: `Model: '${this.modelSchema.name}' does not support streaming.`,\n      cause: new Error(`Model: '${this.modelSchema.name}' does not support streaming.`),\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    throw new ModelError({\n      info: `Model: '${this.modelSchema.name}' does not support streaming.`,\n      cause: new Error(`Model: '${this.modelSchema.name}' does not support streaming.`),\n    });\n  }\n\n  async *transformStreamChatResponseChunk(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    chunk: string,\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    buffer: string\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    throw new ModelError({\n      info: `Model: '${this.modelSchema.name}' does not support streaming.`,\n      cause: new Error(`Model: '${this.modelSchema.name}' does not support streaming.`),\n    });\n\n    yield { partialResponse: { partialMessages: [] }, buffer: \"\" };\n  }\n}\n\nexport { BaseOSeriesChatModel };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_Turbo_0125Literal = \"gpt-3.5-turbo-0125\";\nconst GPT_3_5_Turbo_0125Description =\n  \"The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a \\\n  text encoding issue for non-English language function calls. Training data up to Sept 2021.\";\n\nconst GPT_3_5_Turbo_0125Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_Turbo_0125Literal,\n  description: GPT_3_5_Turbo_0125Description,\n  maxInputTokens: 4092,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n});\n\nconst GPT_3_5_Turbo_0125Options = BaseChatModelOptions;\ntype GPT_3_5_Turbo_0125OptionsType = z.infer<typeof GPT_3_5_Turbo_0125Options>;\n\nclass GPT_3_5_Turbo_0125 extends BaseChatModel {\n  constructor(options: GPT_3_5_Turbo_0125OptionsType) {\n    super(GPT_3_5_Turbo_0125Schema, options);\n  }\n}\n\nexport {\n  GPT_3_5_Turbo_0125,\n  GPT_3_5_Turbo_0125Options,\n  GPT_3_5_Turbo_0125Schema,\n  GPT_3_5_Turbo_0125Literal,\n  type GPT_3_5_Turbo_0125OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_Turbo_1106Literal = \"gpt-3.5-turbo-1106\";\nconst GPT_3_5_Turbo_1106Description =\n  \"The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.\\\n   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.\";\n\nconst GPT_3_5_Turbo_1106Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_Turbo_1106Literal,\n  description: GPT_3_5_Turbo_1106Description,\n  maxInputTokens: 4092,\n  maxOutputTokens: 16385,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(16385, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(16385, 4).schema,\n  },\n});\n\nconst GPT_3_5_Turbo_1106Options = BaseChatModelOptions;\ntype GPT_3_5_Turbo_1106OptionsType = z.infer<typeof GPT_3_5_Turbo_1106Options>;\n\nclass GPT_3_5_Turbo_1106 extends BaseChatModel {\n  constructor(options: GPT_3_5_Turbo_1106OptionsType) {\n    super(GPT_3_5_Turbo_1106Schema, options);\n  }\n}\n\nexport {\n  GPT_3_5_Turbo_1106,\n  GPT_3_5_Turbo_1106Options,\n  GPT_3_5_Turbo_1106Schema,\n  GPT_3_5_Turbo_1106Literal,\n  type GPT_3_5_Turbo_1106OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_TurboLiteral = \"gpt-3.5-turbo\";\nconst GPT_3_5_TurboDescription = \"Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.\";\n\nconst GPT_3_5_TurboSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_TurboLiteral,\n  description: GPT_3_5_TurboDescription,\n  maxInputTokens: 4092,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n});\n\nconst GPT_3_5_TurboOptions = BaseChatModelOptions;\ntype GPT_3_5_TurboOptionsType = z.infer<typeof GPT_3_5_TurboOptions>;\n\nclass GPT_3_5_Turbo extends BaseChatModel {\n  constructor(options: GPT_3_5_TurboOptionsType) {\n    super(GPT_3_5_TurboSchema, options);\n  }\n}\n\nexport { GPT_3_5_Turbo, GPT_3_5_TurboOptions, GPT_3_5_TurboSchema, GPT_3_5_TurboLiteral, type GPT_3_5_TurboOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_0125_PreviewLiteral = \"gpt-4-0125-preview\";\nconst GPT_4_0125_PreviewDescription =\n  \"The latest GPT-4 model intended to reduce cases of “laziness” where the model doesn’t complete a task. Training data up to Apr 2023.\";\n\nconst GPT_4_0125_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_0125_PreviewLiteral,\n  description: GPT_4_0125_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n});\n\nconst GPT_4_0125_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_0125_PreviewOptionsType = z.infer<typeof GPT_4_0125_PreviewOptions>;\n\nclass GPT_4_0125_Preview extends BaseChatModel {\n  constructor(options: GPT_4_0125_PreviewOptionsType) {\n    super(GPT_4_0125_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_0125_Preview,\n  GPT_4_0125_PreviewOptions,\n  GPT_4_0125_PreviewSchema,\n  GPT_4_0125_PreviewLiteral,\n  type GPT_4_0125_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_0613Literal = \"gpt-4-0613\";\nconst GPT_4_0613Description =\n  \"Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.\";\n\nconst GPT_4_0613Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_0613Literal,\n  description: GPT_4_0613Description,\n  maxInputTokens: 8192,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n});\n\nconst GPT_4_0613Options = BaseChatModelOptions;\ntype GPT_4_0613OptionsType = z.infer<typeof GPT_4_0613Options>;\n\nclass GPT_4_0613 extends BaseChatModel {\n  constructor(options: GPT_4_0613OptionsType) {\n    super(GPT_4_0613Schema, options);\n  }\n}\n\nexport { GPT_4_0613, GPT_4_0613Options, GPT_4_0613Schema, GPT_4_0613Literal, type GPT_4_0613OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_1106_PreviewLiteral = \"gpt-4-1106-preview\";\nconst GPT_4_1106_PreviewDescription =\n  \"GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. \\\n  Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.\";\n\nconst GPT_4_1106_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_1106_PreviewLiteral,\n  description: GPT_4_1106_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n});\n\nconst GPT_4_1106_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_1106_PreviewOptionsType = z.infer<typeof GPT_4_1106_PreviewOptions>;\n\nclass GPT_4_1106_Preview extends BaseChatModel {\n  constructor(options: GPT_4_1106_PreviewOptionsType) {\n    super(GPT_4_1106_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_1106_Preview,\n  GPT_4_1106_PreviewOptions,\n  GPT_4_1106_PreviewSchema,\n  GPT_4_1106_PreviewLiteral,\n  type GPT_4_1106_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_Turbo_2024_04_09Literal = \"gpt-4-turbo-2024-04-09\";\nconst GPT_4_Turbo_2024_04_09Description =\n  \"GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version. \\\n  Training data up to Dec 2023.\";\n\nconst GPT_4_Turbo_2024_04_09Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_Turbo_2024_04_09Literal,\n  description: GPT_4_Turbo_2024_04_09Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4096,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4096, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4096, 4).schema,\n  },\n});\n\nconst GPT_4_Turbo_2024_04_09Options = BaseChatModelOptions;\ntype GPT_4_Turbo_2024_04_09OptionsType = z.infer<typeof GPT_4_Turbo_2024_04_09Options>;\n\nclass GPT_4_Turbo_2024_04_09 extends BaseChatModel {\n  constructor(options: GPT_4_Turbo_2024_04_09OptionsType) {\n    super(GPT_4_Turbo_2024_04_09Schema, options);\n  }\n}\n\nexport {\n  GPT_4_Turbo_2024_04_09,\n  GPT_4_Turbo_2024_04_09Options,\n  GPT_4_Turbo_2024_04_09Schema,\n  GPT_4_Turbo_2024_04_09Literal,\n  type GPT_4_Turbo_2024_04_09OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_Turbo_PreviewLiteral = \"gpt-4-turbo-preview\";\nconst GPT_4_Turbo_PreviewDescription = \"Currently points to gpt-4-0125-preview. Training data up to Apr 2023.\";\n\nconst GPT_4_Turbo_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_Turbo_PreviewLiteral,\n  description: GPT_4_Turbo_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n});\n\nconst GPT_4_Turbo_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_Turbo_PreviewOptionsType = z.infer<typeof GPT_4_Turbo_PreviewOptions>;\n\nclass GPT_4_Turbo_Preview extends BaseChatModel {\n  constructor(options: GPT_4_Turbo_PreviewOptionsType) {\n    super(GPT_4_Turbo_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_Turbo_Preview,\n  GPT_4_Turbo_PreviewOptions,\n  GPT_4_Turbo_PreviewSchema,\n  GPT_4_Turbo_PreviewLiteral,\n  type GPT_4_Turbo_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_TurboLiteral = \"gpt-4-turbo\";\nconst GPT_4_TurboDescription =\n  \"The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling. \\\n  Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.\";\n\nconst GPT_4_TurboSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_TurboLiteral,\n  description: GPT_4_TurboDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n});\n\nconst GPT_4_TurboOptions = BaseChatModelOptions;\ntype GPT_4_TurboOptionsType = z.infer<typeof GPT_4_TurboOptions>;\n\nclass GPT_4_Turbo extends BaseChatModel {\n  constructor(options: GPT_4_TurboOptionsType) {\n    super(GPT_4_TurboSchema, options);\n  }\n}\n\nexport { GPT_4_Turbo, GPT_4_TurboOptions, GPT_4_TurboSchema, GPT_4_TurboLiteral, type GPT_4_TurboOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4Literal = \"gpt-4\";\nconst GPT_4Description = \"Currently points to gpt-4-0613. Training data up to Sept 2021.\";\n\nconst GPT_4Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4Literal,\n  description: GPT_4Description,\n  maxInputTokens: 8192,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n});\n\nconst GPT_4Options = BaseChatModelOptions;\ntype GPT_4OptionsType = z.infer<typeof GPT_4Options>;\n\nclass GPT_4 extends BaseChatModel {\n  constructor(options: GPT_4OptionsType) {\n    super(GPT_4Schema, options);\n  }\n}\n\nexport { GPT_4, GPT_4Options, GPT_4Schema, GPT_4Literal, type GPT_4OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_2024_05_13Literal = \"gpt-4o-2024-05-13\";\nconst GPT_4o_2024_05_13Description = \"Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.\";\n\nconst GPT_4o_2024_05_13Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_2024_05_13Literal,\n  description: GPT_4o_2024_05_13Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n});\n\nconst GPT_4o_2024_05_13Options = BaseChatModelOptions;\ntype GPT_4o_2024_05_13OptionsType = z.infer<typeof GPT_4o_2024_05_13Options>;\n\nclass GPT_4o_2024_05_13 extends BaseChatModel {\n  constructor(options: GPT_4o_2024_05_13OptionsType) {\n    super(GPT_4o_2024_05_13Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_2024_05_13,\n  GPT_4o_2024_05_13Options,\n  GPT_4o_2024_05_13Schema,\n  GPT_4o_2024_05_13Literal,\n  type GPT_4o_2024_05_13OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_2024_08_06Literal = \"gpt-4o-2024-08-06\";\nconst GPT_4o_2024_08_06Description = \"Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.\";\n\nconst GPT_4o_2024_08_06Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_2024_08_06Literal,\n  description: GPT_4o_2024_08_06Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n});\n\nconst GPT_4o_2024_08_06Options = BaseChatModelOptions;\ntype GPT_4o_2024_08_06OptionsType = z.infer<typeof GPT_4o_2024_08_06Options>;\n\nclass GPT_4o_2024_08_06 extends BaseChatModel {\n  constructor(options: GPT_4o_2024_08_06OptionsType) {\n    super(GPT_4o_2024_08_06Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_2024_08_06,\n  GPT_4o_2024_08_06Options,\n  GPT_4o_2024_08_06Schema,\n  GPT_4o_2024_08_06Literal,\n  type GPT_4o_2024_08_06OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_Mini_2024_07_18Literal = \"gpt-4o-mini-2024-07-18\";\nconst GPT_4o_MiniDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4o_Mini_2024_07_18Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_Mini_2024_07_18Literal,\n  description: GPT_4o_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n});\n\nconst GPT_4o_Mini_2024_07_18Options = BaseChatModelOptions;\ntype GPT_4o_Mini_2024_07_18OptionsType = z.infer<typeof GPT_4o_Mini_2024_07_18Options>;\n\nclass GPT_4o_Mini_2024_07_18 extends BaseChatModel {\n  constructor(options: GPT_4o_Mini_2024_07_18OptionsType) {\n    super(GPT_4o_Mini_2024_07_18Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_Mini_2024_07_18,\n  GPT_4o_Mini_2024_07_18Options,\n  GPT_4o_Mini_2024_07_18Schema,\n  GPT_4o_Mini_2024_07_18Literal,\n  type GPT_4o_Mini_2024_07_18OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_MiniLiteral = \"gpt-4o-mini\";\nconst GPT_4o_MiniDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4o_MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_MiniLiteral,\n  description: GPT_4o_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n});\n\nconst GPT_4o_MiniOptions = BaseChatModelOptions;\ntype GPT_4o_MiniOptionsType = z.infer<typeof GPT_4o_MiniOptions>;\n\nclass GPT_4o_Mini extends BaseChatModel {\n  constructor(options: GPT_4o_MiniOptionsType) {\n    super(GPT_4o_MiniSchema, options);\n  }\n}\n\nexport { GPT_4o_Mini, GPT_4o_MiniOptions, GPT_4o_MiniSchema, GPT_4o_MiniLiteral, type GPT_4o_MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4oLiteral = \"gpt-4o\";\nconst GPT_4oDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4oSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4oLiteral,\n  description: GPT_4oDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n});\n\nconst GPT_4oOptions = BaseChatModelOptions;\ntype GPT_4oOptionsType = z.infer<typeof GPT_4oOptions>;\n\nclass GPT_4o extends BaseChatModel {\n  constructor(options: GPT_4oOptionsType) {\n    super(GPT_4oSchema, options);\n  }\n}\n\nexport { GPT_4o, GPT_4oOptions, GPT_4oSchema, GPT_4oLiteral, type GPT_4oOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O1_2024_12_17Literal = \"o1-2024-12-17\";\nconst O1_2024_12_17Description =\n  \"A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.\";\n\nconst O1_2024_12_17Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O1_2024_12_17Literal,\n  description: O1_2024_12_17Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(100000, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(100000, 4).schema,\n  },\n});\n\nconst O1_2024_12_17Options = BaseChatModelOptions;\ntype O1_2024_12_17OptionsType = z.infer<typeof O1_2024_12_17Options>;\n\nclass O1_2024_12_17 extends BaseChatModel {\n  constructor(options: O1_2024_12_17OptionsType) {\n    super(O1_2024_12_17Schema, options);\n  }\n}\n\nexport { O1_2024_12_17, O1_2024_12_17Literal, O1_2024_12_17Options, O1_2024_12_17Schema, type O1_2024_12_17OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { BaseOSeriesChatModel } from \"./base-o-series-chat-model.openai\";\nimport {\n  OpenAIChatModelOSSeriesRoles,\n  OpenAIChatModelOSSeriesRolesMap,\n  OpenAIChatModelTextModalities,\n  OpenAIChatModelTextModalitiesEnum,\n} from \"./types\";\n\nconst O1_Mini_2024_09_12Literal = \"o1-mini-2024-09-12\";\nconst O1_Mini_2024_09_12Description =\n  \"Enhanced version of o1-mini optimized for faster reasoning in coding, math, and science. Training data up to September 2024.\";\n\nconst O1_Mini_2024_09_12Schema = ChatModelSchema(OpenAIChatModelOSSeriesRoles, OpenAIChatModelTextModalitiesEnum).parse({\n  name: O1_Mini_2024_09_12Literal,\n  description: O1_Mini_2024_09_12Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 65536,\n  roles: OpenAIChatModelOSSeriesRolesMap,\n  modalities: OpenAIChatModelTextModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(65536, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(65536, 4).schema,\n  },\n});\n\nconst O1_Mini_2024_09_12Options = BaseChatModelOptions;\ntype O1_Mini_2024_09_12OptionsType = z.infer<typeof O1_Mini_2024_09_12Options>;\n\nclass O1_Mini_2024_09_12 extends BaseOSeriesChatModel {\n  constructor(options: O1_Mini_2024_09_12OptionsType) {\n    super(O1_Mini_2024_09_12Schema, options);\n  }\n}\n\nexport {\n  O1_Mini_2024_09_12,\n  O1_Mini_2024_09_12Literal,\n  O1_Mini_2024_09_12Options,\n  O1_Mini_2024_09_12Schema,\n  type O1_Mini_2024_09_12OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { BaseOSeriesChatModel } from \"./base-o-series-chat-model.openai\";\nimport {\n  OpenAIChatModelOSSeriesRoles,\n  OpenAIChatModelOSSeriesRolesMap,\n  OpenAIChatModelTextModalities,\n  OpenAIChatModelTextModalitiesEnum,\n} from \"./types\";\n\nconst O1_MiniLiteral = \"o1-mini\";\nconst O1_MiniDescription =\n  \"Faster and cheaper reasoning model particularly good at coding, math, and science. Training data up to Oct 2023.\";\n\nconst O1_MiniSchema = ChatModelSchema(OpenAIChatModelOSSeriesRoles, OpenAIChatModelTextModalitiesEnum).parse({\n  name: O1_MiniLiteral,\n  description: O1_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelOSSeriesRolesMap,\n  modalities: OpenAIChatModelTextModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(4092, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(4092, 4).schema,\n  },\n});\n\nconst O1_MiniOptions = BaseChatModelOptions;\ntype O1_MiniOptionsType = z.infer<typeof O1_MiniOptions>;\n\nclass O1_Mini extends BaseOSeriesChatModel {\n  constructor(options: O1_MiniOptionsType) {\n    super(O1_MiniSchema, options);\n  }\n}\n\nexport { O1_Mini, O1_MiniOptions, O1_MiniSchema, O1_MiniLiteral, type O1_MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { BaseOSeriesChatModel } from \"./base-o-series-chat-model.openai\";\nimport {\n  OpenAIChatModelOSSeriesRoles,\n  OpenAIChatModelOSSeriesRolesMap,\n  OpenAIChatModelTextModalities,\n  OpenAIChatModelTextModalitiesEnum,\n} from \"./types\";\n\nconst O1_PreviewLiteral = \"o1-preview\";\nconst O1_PreviewDescription = \"Reasoning model designed to solve hard problems across domains. Training data up to Oct 2023.\";\n\nconst O1_PreviewSchema = ChatModelSchema(OpenAIChatModelOSSeriesRoles, OpenAIChatModelTextModalitiesEnum).parse({\n  name: O1_PreviewLiteral,\n  description: O1_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelOSSeriesRolesMap,\n  modalities: OpenAIChatModelTextModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(4092, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(4092, 4).schema,\n  },\n});\n\nconst O1_PreviewOptions = BaseChatModelOptions;\ntype O1_PreviewOptionsType = z.infer<typeof O1_PreviewOptions>;\n\nclass O1_Preview extends BaseOSeriesChatModel {\n  constructor(options: O1_PreviewOptionsType) {\n    super(O1_PreviewSchema, options);\n  }\n}\n\nexport { O1_Preview, O1_PreviewOptions, O1_PreviewSchema, O1_PreviewLiteral, type O1_PreviewOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { BaseOSeriesChatModel } from \"./base-o-series-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O1Literal = \"o1\";\nconst O1Description =\n  \"Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.\";\n\nconst O1Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O1Literal,\n  description: O1Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O1Options = BaseChatModelOptions;\ntype O1OptionsType = z.infer<typeof O1Options>;\n\nclass O1 extends BaseOSeriesChatModel {\n  constructor(options: O1OptionsType) {\n    super(O1Schema, options);\n  }\n}\n\nexport { O1, O1Literal, O1Options, O1Schema, type O1OptionsType };\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchemaType } from \"@adaline/provider\";\nimport { EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral } from \"@adaline/types\";\n\nconst OpenAIEmbeddingModelModalities: EmbeddingModelSchemaType[\"modalities\"] = [\n  EmbeddingTextModalityLiteral,\n  EmbeddingTokenModalityLiteral,\n];\n\nconst OpenAIEmbeddingModelModalitiesEnum = z.enum([EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral]);\n\nexport { OpenAIEmbeddingModelModalitiesEnum, OpenAIEmbeddingModelModalities };\n","import { z } from \"zod\";\n\nconst OpenAIGetEmbeddingsResponse = z.object({\n  object: z.literal(\"list\"),\n  model: z.string(),\n  data: z.array(\n    z.object({\n      index: z.number(),\n      object: z.literal(\"embedding\"),\n      embedding: z.array(z.number()).or(z.string().base64()),\n    })\n  ),\n  usage: z.object({\n    prompt_tokens: z.number().nonnegative(),\n    total_tokens: z.number().nonnegative(),\n  }),\n});\n\nexport { OpenAIGetEmbeddingsResponse };\n","import { z } from \"zod\";\n\nconst OpenAIEmbeddingRequestInput = z\n  .string()\n  .min(1)\n  .or(z.array(z.string().min(1)).min(1))\n  .or(z.array(z.number().int().nonnegative()).min(1))\n  .or(z.array(z.array(z.number().int().nonnegative()).min(1)).min(1));\ntype OpenAIEmbeddingRequestInputType = z.infer<typeof OpenAIEmbeddingRequestInput>;\n\nconst OpenAIEmbeddingRequest = z.object({\n  model: z.string().min(1).optional(),\n  input: OpenAIEmbeddingRequestInput,\n  encoding_format: z.enum([\"float\", \"base64\"]).optional(),\n  dimensions: z.number().int().min(1).optional(),\n});\ntype OpenAIEmbeddingRequestType = z.infer<typeof OpenAIEmbeddingRequest>;\n\nexport { OpenAIEmbeddingRequest, OpenAIEmbeddingRequestInput, type OpenAIEmbeddingRequestType, type OpenAIEmbeddingRequestInputType };\n","import { z } from \"zod\";\n\nimport {\n  EmbeddingModelSchemaType,\n  EmbeddingModelV1,\n  HeadersType,\n  InvalidConfigError,\n  InvalidEmbeddingRequestsError,\n  InvalidModelRequestError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\n\nimport {\n  Base64EmbeddingLiteral,\n  Base64EmbeddingType,\n  Config,\n  ConfigType,\n  EmbeddingRequests,\n  EmbeddingRequestsType,\n  EmbeddingResponseType,\n  EmbeddingTextModalityLiteral,\n  EmbeddingTokenModalityLiteral,\n  FloatEmbeddingLiteral,\n  FloatEmbeddingType,\n} from \"@adaline/types\";\n\nimport { OpenAIEmbeddingRequest, OpenAIGetEmbeddingsResponse } from \"./types\";\n\nimport { OpenAI } from \"./../../provider/provider.openai\";\n\nconst BaseEmbeddingModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  getEmbeddingsUrl: z.string().url().optional(),\n});\ntype BaseEmbeddingModelOptionsType = z.infer<typeof BaseEmbeddingModelOptions>;\n\nclass BaseEmbeddingModel implements EmbeddingModelV1<EmbeddingModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: EmbeddingModelSchemaType;\n  modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly getEmbeddingsUrl: string;\n\n  constructor(modelSchema: EmbeddingModelSchemaType, options: BaseEmbeddingModelOptionsType) {\n    const parsedOptions = BaseEmbeddingModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || OpenAI.baseUrl);\n    this.getEmbeddingsUrl = urlWithoutTrailingSlash(parsedOptions.getEmbeddingsUrl || `${this.baseUrl}/embeddings`);\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      Authorization: `Bearer ${this.apiKey}`,\n      \"Content-Type\": \"application/json\",\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelSchema.name,\n    };\n  }\n\n  // x-ratelimit-limit-requests\tThe maximum number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-limit-tokens\tThe maximum number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-requests The remaining number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-tokens\tThe remaining number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-reset-requests\tThe time until the rate limit (based on requests) resets to its initial state.\n  // x-ratelimit-reset-tokens\tThe time until the rate limit (based on tokens) resets to its initial state.\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    // parse duration from header value of format \"6m0s\" or \"21s\" or \"41ms\" or \"2s81ms\" or \"5h50m30ms\" and such\n    const parseDuration = (duration: string): number => {\n      const regex = /(\\d+)(h|m|s|ms)/g;\n      const timeUnits: { [unit: string]: number } = {\n        h: 3600000, // 1 hour = 60 * 60 * 1000 ms\n        m: 60000, // 1 minute = 60 * 1000 ms\n        s: 1000, // 1 second = 1000 ms\n        ms: 1, // milliseconds\n      };\n\n      let match;\n      let totalMs = 0;\n      while ((match = regex.exec(duration)) !== null) {\n        const value = parseInt(match[1]);\n        const unit = match[2];\n        totalMs += value * timeUnits[unit];\n      }\n\n      return totalMs;\n    };\n\n    let resetRequestsDelayMs = 0;\n    let resetTokensDelayMs = 0;\n    const shouldRetry = true;\n    if (responseHeaders[\"x-ratelimit-reset-requests\"]) {\n      resetRequestsDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-requests\"]);\n    }\n    if (responseHeaders[\"x-ratelimit-reset-tokens\"]) {\n      resetTokensDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-tokens\"]);\n    }\n\n    // if rate limited by requests, then it's reset must be the higher of two and visa versa\n    const delayMs = Math.max(resetRequestsDelayMs, resetTokensDelayMs);\n    return { shouldRetry, delayMs };\n  }\n\n  getTokenCount(requests: EmbeddingRequestsType): number {\n    return requests.requests.reduce((acc, request) => acc + request.length, 0);\n  }\n\n  transformModelRequest(request: any): {\n    modelName: string | undefined;\n    config: ConfigType;\n    embeddingRequests: EmbeddingRequestsType;\n  } {\n    const safeRequest = OpenAIEmbeddingRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    const _config = {\n      encodingFormat: parsedRequest.encoding_format,\n      dimensions: parsedRequest.dimensions,\n    };\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    let embeddingRequests: EmbeddingRequestsType;\n    let embeddingFormat: typeof EmbeddingTextModalityLiteral | typeof EmbeddingTokenModalityLiteral;\n    if (typeof parsedRequest.input === \"string\") {\n      embeddingFormat = EmbeddingTextModalityLiteral;\n    } else {\n      if (typeof parsedRequest.input[0] === \"string\") {\n        embeddingFormat = EmbeddingTextModalityLiteral;\n      } else {\n        embeddingFormat = EmbeddingTokenModalityLiteral;\n      }\n    }\n\n    if (embeddingFormat === EmbeddingTextModalityLiteral) {\n      if (typeof parsedRequest.input === \"string\") {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: [parsedRequest.input],\n        };\n      } else {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: parsedRequest.input as string[],\n        };\n      }\n    } else {\n      if (typeof parsedRequest.input[0] === \"number\") {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: [parsedRequest.input as number[]],\n        };\n      } else {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: parsedRequest.input as number[][],\n        };\n      }\n    }\n\n    return {\n      modelName,\n      config,\n      embeddingRequests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, requests?: EmbeddingRequestsType): ParamsType {\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelSchema.name}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    Object.keys(parsedConfig as ConfigType).forEach((key) => {\n      if (!this.modelSchema.config.def[key]) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelSchema.name}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = parsedConfig[key];\n      acc[paramKey] = paramValue;\n      return acc;\n    }, {} as ParamsType);\n\n    return transformedConfig;\n  }\n\n  transformEmbeddingRequests(requests: EmbeddingRequestsType): ParamsType {\n    const _parsedRequests = EmbeddingRequests().safeParse(requests);\n    if (!_parsedRequests.success) {\n      throw new InvalidEmbeddingRequestsError({ info: \"Invalid embedding requests\", cause: _parsedRequests.error });\n    }\n\n    // Note from OpenAI API Reference:\n    // The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002),\n    // cannot be an empty string, and any array must be 2048 dimensions or less.\n    // TODO: add max tokens check in requests based on model schema when token calculation is accurate\n\n    const parsedRequests = _parsedRequests.data as EmbeddingRequestsType;\n    return {\n      input: parsedRequests.requests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsUrl(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.getEmbeddingsUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsHeaders(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getGetEmbeddingsData(config: ConfigType, requests: EmbeddingRequestsType): Promise<ParamsType> {\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...this.transformConfig(config, requests),\n        ...this.transformEmbeddingRequests(requests),\n      });\n    });\n  }\n\n  transformGetEmbeddingsResponse(response: any): EmbeddingResponseType {\n    let encodingFormat: typeof Base64EmbeddingLiteral | typeof FloatEmbeddingLiteral;\n    const safe = OpenAIGetEmbeddingsResponse.safeParse(response);\n    if (safe.success) {\n      const parsedResponse = safe.data;\n      encodingFormat = typeof parsedResponse.data[0].embedding === \"string\" ? Base64EmbeddingLiteral : FloatEmbeddingLiteral;\n      const embeddings = parsedResponse.data.map((item) => {\n        if (typeof item.embedding === \"string\") {\n          return {\n            index: item.index,\n            embedding: item.embedding,\n          } as Base64EmbeddingType;\n        } else {\n          return {\n            index: item.index,\n            embedding: item.embedding,\n          } as FloatEmbeddingType;\n        }\n      });\n\n      return {\n        encodingFormat: encodingFormat,\n        embeddings: embeddings,\n        usage: {\n          totalTokens: parsedResponse.usage.total_tokens,\n        },\n      } as EmbeddingResponseType;\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n}\n\nexport { BaseEmbeddingModel, BaseEmbeddingModelOptions, type BaseEmbeddingModelOptionsType };\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_Ada002Literal = \"text-embedding-ada-002\";\nconst Text_Embedding_Ada002Description = \"Most capable 2nd generation embedding model, replacing 16 first generation models\";\n\nconst Text_Embedding_Ada002Schema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_Ada002Literal,\n  description: Text_Embedding_Ada002Description,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 1536,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.base().def,\n    schema: OpenAIEmbeddingModelConfigs.base().schema,\n  },\n});\n\nconst Text_Embedding_Ada002_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_Ada002_OptionsType = z.infer<typeof Text_Embedding_Ada002_Options>;\n\nclass Text_Embedding_Ada002 extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_Ada002_OptionsType) {\n    super(Text_Embedding_Ada002Schema, options);\n  }\n}\n\nexport {\n  Text_Embedding_Ada002,\n  Text_Embedding_Ada002_Options,\n  Text_Embedding_Ada002Schema,\n  Text_Embedding_Ada002Literal,\n  type Text_Embedding_Ada002_OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_3_SmallLiteral = \"text-embedding-3-small\";\nconst Text_Embedding_3_SmallDescription = \"Increased performance over 2nd generation ada embedding model\";\n\nconst Text_Embedding_3_SmallSchema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_3_SmallLiteral,\n  description: Text_Embedding_3_SmallDescription,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 1536,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.dimensions(1536).def,\n    schema: OpenAIEmbeddingModelConfigs.dimensions(1536).schema,\n  },\n});\n\nconst Text_Embedding_3_Small_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_3_Small_OptionsType = z.infer<typeof Text_Embedding_3_Small_Options>;\n\nclass Text_Embedding_3_Small extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_3_Small_OptionsType) {\n    super(Text_Embedding_3_SmallSchema, options);\n  }\n}\n\nexport {\n  Text_Embedding_3_Small,\n  Text_Embedding_3_Small_Options,\n  Text_Embedding_3_SmallSchema,\n  Text_Embedding_3_SmallLiteral,\n  type Text_Embedding_3_Small_OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_3_LargeLiteral = \"text-embedding-3-large\";\nconst Text_Embedding_3_LargeDescription = \"Most capable embedding model for both english and non-english tasks\";\n\nconst Text_Embedding_3_LargeSchema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_3_LargeLiteral,\n  description: Text_Embedding_3_LargeDescription,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 3072,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.dimensions(3072).def,\n    schema: OpenAIEmbeddingModelConfigs.dimensions(3072).schema,\n  },\n});\n\nconst Text_Embedding_3_Large_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_3_Large_OptionsType = z.infer<typeof Text_Embedding_3_Large_Options>;\n\nclass Text_Embedding_3_Large extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_3_Large_OptionsType) {\n    super(Text_Embedding_3_LargeSchema, options);\n  }\n}\n\nexport {\n  Text_Embedding_3_Large,\n  Text_Embedding_3_Large_Options,\n  Text_Embedding_3_LargeSchema,\n  Text_Embedding_3_LargeLiteral,\n  type Text_Embedding_3_Large_OptionsType,\n};\n"]}