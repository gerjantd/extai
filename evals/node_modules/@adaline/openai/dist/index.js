'use strict';

var zod = require('zod');
var provider = require('@adaline/provider');
var types = require('@adaline/types');

var en=Object.defineProperty,on=Object.defineProperties;var tn=Object.getOwnPropertyDescriptors;var Xo=Object.getOwnPropertySymbols;var nn=Object.prototype.hasOwnProperty,sn=Object.prototype.propertyIsEnumerable;var an=(n,e)=>(e=Symbol[n])?e:Symbol.for("Symbol."+n);var Qo=(n,e,t)=>e in n?en(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,M=(n,e)=>{for(var t in e||(e={}))nn.call(e,t)&&Qo(n,t,e[t]);if(Xo)for(var t of Xo(e))sn.call(e,t)&&Qo(n,t,e[t]);return n},G=(n,e)=>on(n,tn(e));var A=(n,e,t)=>new Promise((o,s)=>{var a=l=>{try{i(t.next(l));}catch(h){s(h);}},d=l=>{try{i(t.throw(l));}catch(h){s(h);}},i=l=>l.done?o(l.value):Promise.resolve(l.value).then(a,d);i((t=t.apply(n,e)).next());}),rn=function(n,e){this[0]=n,this[1]=e;},ee=(n,e,t)=>{var o=(d,i,l,h)=>{try{var c=t[d](i),g=(i=c.value)instanceof rn,y=c.done;Promise.resolve(g?i[0]:i).then(O=>g?o(d==="return"?d:"next",i[1]?{done:O.done,value:O.value}:O,l,h):l({value:O,done:y})).catch(O=>o("throw",O,l,h));}catch(O){h(O);}},s=d=>a[d]=i=>new Promise((l,h)=>o(d,i,l,h)),a={};return t=t.apply(n,e),a[an("asyncIterator")]=()=>a,s("next"),s("throw"),s("return"),a};var je=provider.RangeConfigItem({param:"temperature",title:provider.CHAT_CONFIG.TEMPERATURE.title,description:provider.CHAT_CONFIG.TEMPERATURE.description,min:0,max:2,step:.01,default:1}),Fe=n=>provider.RangeConfigItem({param:"max_tokens",title:provider.CHAT_CONFIG.MAX_TOKENS.title,description:provider.CHAT_CONFIG.MAX_TOKENS.description,min:0,max:n,step:1,default:0}),De=n=>provider.MultiStringConfigItem({param:"stop",title:provider.CHAT_CONFIG.STOP(n).title,description:provider.CHAT_CONFIG.STOP(n).description,max:n}),Ne=provider.RangeConfigItem({param:"top_p",title:provider.CHAT_CONFIG.TOP_P.title,description:provider.CHAT_CONFIG.TOP_P.description,min:0,max:1,step:.01,default:1}),$e=provider.RangeConfigItem({param:"frequency_penalty",title:provider.CHAT_CONFIG.FREQUENCY_PENALTY.title,description:provider.CHAT_CONFIG.FREQUENCY_PENALTY.description,min:-2,max:2,step:.01,default:0}),Ue=provider.RangeConfigItem({param:"presence_penalty",title:provider.CHAT_CONFIG.PRESENCE_PENALTY.title,description:provider.CHAT_CONFIG.PRESENCE_PENALTY.description,min:-2,max:2,step:.01,default:0}),He=provider.RangeConfigItem({param:"seed",title:provider.CHAT_CONFIG.SEED.title,description:provider.CHAT_CONFIG.SEED.description,min:0,max:1e6,step:1,default:0}),Ve=provider.SelectBooleanConfigItem({param:"logprobs",title:provider.CHAT_CONFIG.LOG_PROBS.title,description:provider.CHAT_CONFIG.LOG_PROBS.description,default:!1}),Ke=provider.RangeConfigItem({param:"top_logprobs",title:provider.CHAT_CONFIG.TOP_LOG_PROBS.title,description:provider.CHAT_CONFIG.TOP_LOG_PROBS.description,min:0,max:20,step:1,default:0}),Je=provider.SelectStringConfigItem({param:"tool_choice",title:"Tool choice",description:"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.",default:"auto",choices:["auto","required","none"]});var D=(n,e)=>zod.z.object({temperature:je.schema,maxTokens:Fe(n).schema,stop:De(e).schema,topP:Ne.schema,frequencyPenalty:$e.schema,presencePenalty:Ue.schema,seed:He.schema.transform(t=>t===0?void 0:t),logProbs:Ve.schema,topLogProbs:Ke.schema,toolChoice:Je.schema}),N=(n,e)=>({temperature:je.def,maxTokens:Fe(n).def,stop:De(e).def,topP:Ne.def,frequencyPenalty:$e.def,presencePenalty:Ue.def,seed:He.def,logProbs:Ve.def,topLogProbs:Ke.def,toolChoice:Je.def});var Zo=provider.ObjectSchemaConfigItem({param:"response_schema",title:provider.CHAT_CONFIG.RESPONSE_SCHEMA.title,description:provider.CHAT_CONFIG.RESPONSE_SCHEMA.description,objectSchema:types.ResponseSchema}),et=provider.SelectStringConfigItem({param:"response_format",title:provider.CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,description:provider.CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,default:"text",choices:["text","json_object","json_schema"]}),te=(n,e)=>G(M({},N(n,e)),{responseFormat:et.def,responseSchema:Zo.def}),ne=(n,e)=>D(n,e).extend({responseFormat:et.schema,responseSchema:Zo.schema});var tt=provider.RangeConfigItem({param:"temperature",title:provider.CHAT_CONFIG.TEMPERATURE.title,description:provider.CHAT_CONFIG.TEMPERATURE.description,min:1,max:1,step:.01,default:1}),nt=n=>provider.RangeConfigItem({param:"max_completion_tokens",title:provider.CHAT_CONFIG.MAX_TOKENS.title,description:provider.CHAT_CONFIG.MAX_TOKENS.description,min:0,max:n,step:1,default:0}),st=(n,e)=>G(M({},te(n,e)),{temperature:tt.def,maxTokens:nt(n).def}),at=(n,e)=>ne(n,e).extend({temperature:tt.schema,maxTokens:nt(n).schema});var rt=provider.SelectStringConfigItem({param:"response_format",title:provider.CHAT_CONFIG.RESPONSE_FORMAT.title,description:provider.CHAT_CONFIG.RESPONSE_FORMAT.description,default:"text",choices:["text","json_object"]}),lt=(n,e)=>G(M({},N(n,e)),{responseFormat:rt.def}),pt=(n,e)=>D(n,e).extend({responseFormat:rt.schema});var We=provider.SelectStringConfigItem({param:"encoding_format",title:"Encoding format",description:"Select the encoding format for the word embedding.",default:"float",choices:["float","base64"]}),Ye=n=>provider.RangeConfigItem({param:"dimensions",title:"Dimensions",description:"Select the number of dimensions for the word embedding.",min:1,max:n,step:1,default:n});var ae=()=>zod.z.object({encodingFormat:We.schema}),ie=()=>({encodingFormat:We.def});var mt=n=>ae().extend({dimensions:Ye(n).schema}),dt=n=>G(M({},ie()),{dimensions:Ye(n).def});var m={base:(n,e)=>({def:N(n,e),schema:D(n,e)}),responseFormat:(n,e)=>({def:lt(n,e),schema:pt(n,e)}),responseSchema:(n,e)=>({def:te(n,e),schema:ne(n,e)}),oSeries:(n,e)=>({def:st(n,e),schema:at(n,e)})},q={base:()=>({def:ie(),schema:ae()}),dimensions:n=>({def:dt(n),schema:mt(n)})};var _=zod.z.enum([types.SystemRoleLiteral,types.UserRoleLiteral,types.AssistantRoleLiteral,types.ToolRoleLiteral]),T={system:types.SystemRoleLiteral,user:types.UserRoleLiteral,assistant:types.AssistantRoleLiteral,tool:types.ToolRoleLiteral},$=zod.z.enum([types.UserRoleLiteral,types.AssistantRoleLiteral]),U={user:types.UserRoleLiteral,assistant:types.AssistantRoleLiteral};var b=[types.TextModalityLiteral,types.ImageModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral],P=zod.z.enum([types.TextModalityLiteral,types.ImageModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral]),V=[types.TextModalityLiteral],K=zod.z.enum([types.TextModalityLiteral]),S=[types.TextModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral],x=zod.z.enum([types.TextModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral]);var de=zod.z.object({token:zod.z.string(),logprob:zod.z.number(),bytes:zod.z.array(zod.z.number()).nullable()}),_t=zod.z.object({content:zod.z.array(de.extend({top_logprobs:zod.z.array(de)})).nullable().optional(),refusal:zod.z.array(de.extend({top_logprobs:zod.z.array(de)})).nullable().optional()}).nullable(),yn=zod.z.array(zod.z.object({id:zod.z.string().min(1),type:zod.z.enum(["function"]),function:zod.z.object({name:zod.z.string(),arguments:zod.z.string()})})),Tt=zod.z.object({id:zod.z.string(),object:zod.z.literal("chat.completion"),created:zod.z.number(),model:zod.z.string(),system_fingerprint:zod.z.string().nullable(),choices:zod.z.array(zod.z.object({index:zod.z.number(),message:zod.z.object({role:zod.z.string(),content:zod.z.string().nullable().optional(),tool_calls:yn.optional(),refusal:zod.z.string().nullable().optional()}),logprobs:_t.optional(),finish_reason:zod.z.string()})),usage:zod.z.object({prompt_tokens:zod.z.number(),completion_tokens:zod.z.number(),total_tokens:zod.z.number()})}),Mn=zod.z.array(zod.z.object({index:zod.z.number().int(),id:zod.z.string().min(1).optional(),type:zod.z.enum(["function"]).optional(),function:zod.z.object({name:zod.z.string().min(1).optional(),arguments:zod.z.string().optional()}).optional()})),gt=zod.z.object({id:zod.z.string(),object:zod.z.string(),created:zod.z.number(),model:zod.z.string(),system_fingerprint:zod.z.string().nullable(),choices:zod.z.array(zod.z.object({index:zod.z.number(),delta:zod.z.object({content:zod.z.string().nullable().optional(),tool_calls:Mn.optional(),refusal:zod.z.string().nullable().optional()}).or(zod.z.object({})),logprobs:_t,finish_reason:zod.z.string().nullable()})),usage:zod.z.object({prompt_tokens:zod.z.number(),completion_tokens:zod.z.number(),total_tokens:zod.z.number()}).nullable().optional()});var On=zod.z.object({type:zod.z.literal("function"),function:zod.z.object({name:zod.z.string().min(1),description:zod.z.string().min(1).optional(),strict:zod.z.boolean().optional(),parameters:zod.z.any()})}),Cn=zod.z.enum(["none","auto","required"]),bn=zod.z.object({type:zod.z.literal("function"),function:zod.z.object({name:zod.z.string().min(1)})}),Pn=zod.z.object({type:zod.z.enum(["text","json_object"])}).or(zod.z.object({type:zod.z.literal("json_schema"),json_schema:zod.z.object({name:zod.z.string().min(1),description:zod.z.string().min(1).optional(),strict:zod.z.boolean().optional(),schema:zod.z.any()})})),Qe=zod.z.object({text:zod.z.string().min(1),type:zod.z.literal("text")}),In=zod.z.object({type:zod.z.literal("image_url"),image_url:zod.z.object({url:zod.z.string().url().min(1),detail:zod.z.enum(["low","high","auto"]).optional()})}),Sn=zod.z.object({id:zod.z.string().min(1),type:zod.z.literal("function"),function:zod.z.object({name:zod.z.string().min(1),arguments:zod.z.string().min(1)})}),xn=zod.z.object({role:zod.z.literal("system"),content:zod.z.string().min(1).or(zod.z.array(Qe).min(1))}),An=zod.z.object({role:zod.z.literal("user"),content:zod.z.string().min(1).or(zod.z.array(zod.z.union([Qe,In])).min(1))}),En=zod.z.object({role:zod.z.literal("assistant"),content:zod.z.string().min(1).or(zod.z.array(Qe).min(1)).optional(),tool_calls:zod.z.array(Sn).min(1).optional()}),Rn=zod.z.object({role:zod.z.literal("tool"),tool_call_id:zod.z.string().min(1),content:zod.z.string().min(1)}),wn=zod.z.union([xn,An,En,Rn]),ce=zod.z.object({model:zod.z.string().min(1).optional(),messages:zod.z.array(wn).min(1),frequency_penalty:zod.z.number().min(-2).max(2).nullable().optional(),logprobs:zod.z.boolean().nullable().optional(),top_logprobs:zod.z.number().min(0).max(20).nullable().optional(),max_tokens:zod.z.number().min(0).nullable().optional(),presence_penalty:zod.z.number().min(-2).max(2).nullable().optional(),response_format:Pn.optional(),seed:zod.z.number().nullable().optional(),stop:zod.z.string().or(zod.z.array(zod.z.string()).max(4)).nullable().optional(),temperature:zod.z.number().min(0).max(2).nullable().optional(),top_p:zod.z.number().min(0).max(1).nullable().optional(),tools:zod.z.array(On).optional(),tool_choice:Cn.or(bn).optional()});var yt=ce.omit({max_tokens:!0}).extend({max_completion_tokens:zod.z.number().min(0).nullable().optional()});var vn="openai",B=class{constructor(){this.version="v1";this.name=vn;this.chatModelFactories={[no]:{model:fe,modelOptions:bt,modelSchema:so},[Ze]:{model:he,modelOptions:Ot,modelSchema:eo},[oo]:{model:ue,modelOptions:Ct,modelSchema:to},[ao]:{model:_e,modelOptions:Pt,modelSchema:io},[ro]:{model:Te,modelOptions:It,modelSchema:lo},[po]:{model:ge,modelOptions:St,modelSchema:mo},[co]:{model:ye,modelOptions:xt,modelSchema:ho},[uo]:{model:Me,modelOptions:At,modelSchema:fo},[_o]:{model:Oe,modelOptions:Et,modelSchema:To},[go]:{model:Ce,modelOptions:Rt,modelSchema:yo},[Co]:{model:Pe,modelOptions:Gt,modelSchema:bo},[So]:{model:Se,modelOptions:qt,modelSchema:xo},[Ao]:{model:xe,modelOptions:kt,modelSchema:Eo},[Po]:{model:Ie,modelOptions:vt,modelSchema:Io},[Mo]:{model:be,modelOptions:wt,modelSchema:Oo},[qo]:{model:Re,modelOptions:Bt,modelSchema:ko},[Lo]:{model:we,modelOptions:jt,modelSchema:zo},[Bo]:{model:Ge,modelOptions:Ft,modelSchema:jo},[Ro]:{model:Ae,modelOptions:Lt,modelSchema:wo},[Go]:{model:Ee,modelOptions:zt,modelSchema:vo}};this.embeddingModelFactories={[Fo]:{model:ve,modelOptions:Dt,modelSchema:Do},[No]:{model:qe,modelOptions:Nt,modelSchema:$o},[Uo]:{model:ke,modelOptions:$t,modelSchema:Ho}};}chatModelLiterals(){return Object.keys(this.chatModelFactories)}chatModelSchemas(){return Object.keys(this.chatModelFactories).reduce((e,t)=>(e[t]=this.chatModelFactories[t].modelSchema,e),{})}chatModel(e){let t=e.modelName;if(!(t in this.chatModelFactories))throw new provider.ProviderError({info:`OpenAI chat model: ${t} not found`,cause:new Error(`OpenAI chat model: ${t} not found, available chat models: 
          [${this.chatModelLiterals().join(", ")}]`)});let o=this.chatModelFactories[t].model,s=this.chatModelFactories[t].modelOptions.parse(e);return new o(s)}embeddingModelLiterals(){return Object.keys(this.embeddingModelFactories)}embeddingModelSchemas(){return Object.keys(this.embeddingModelFactories).reduce((e,t)=>(e[t]=this.embeddingModelFactories[t].modelSchema,e),{})}embeddingModel(e){let t=e.modelName;if(!(t in this.embeddingModelFactories))throw new provider.ProviderError({info:`OpenAI embedding model: ${t} not found`,cause:new Error(`OpenAI embedding model: ${t} not found, available embedding models: 
          [${this.embeddingModelLiterals().join(", ")}]`)});let o=this.embeddingModelFactories[t].model,s=this.embeddingModelFactories[t].modelOptions.parse(e);return new o(s)}};B.baseUrl="https://api.openai.com/v1";var u=zod.z.object({modelName:zod.z.string(),apiKey:zod.z.string(),baseUrl:zod.z.string().url().optional(),completeChatUrl:zod.z.string().url().optional(),streamChatUrl:zod.z.string().url().optional(),organization:zod.z.string().optional()}),f=class{constructor(e,t){this.version="v1";let o=u.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=provider.urlWithoutTrailingSlash(o.baseUrl||B.baseUrl),this.streamChatUrl=provider.urlWithoutTrailingSlash(o.streamChatUrl||`${this.baseUrl}/chat/completions`),this.completeChatUrl=provider.urlWithoutTrailingSlash(o.completeChatUrl||`${this.baseUrl}/chat/completions`),this.organization=o.organization;}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return M({Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"},this.organization?{"OpenAI-Organization":this.organization}:{})}getDefaultParams(){return {model:this.modelName}}getRetryDelay(e){let t=i=>{let l=/(\d+)(h|m|s|ms)/g,h={h:36e5,m:6e4,s:1e3,ms:1},c,g=0;for(;(c=l.exec(i))!==null;){let y=parseInt(c[1]),O=c[2];g+=y*h[O];}return g},o=0,s=0,a=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(s=t(e["x-ratelimit-reset-tokens"]));let d=Math.max(o,s);return {shouldRetry:a,delayMs:d}}getTokenCount(e){return e.reduce((t,o)=>t+o.content.map(s=>s.modality==="text"?s.value:"").join(" ").length,0)}transformModelRequest(e){let t=ce.safeParse(e);if(!t.success)throw new provider.InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,s=o.model;if(o.tool_choice&&(!o.tools||o.tools.length===0))throw new provider.InvalidModelRequestError({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'tool_choice' is specified")});let a={};o.response_format&&(a.responseFormat=o.response_format.type,o.response_format.type==="json_schema"&&(a.responseSchema={name:o.response_format.json_schema.name,description:o.response_format.json_schema.description||"",strict:o.response_format.json_schema.strict,schema:o.response_format.json_schema.schema})),o.tool_choice&&(typeof o.tool_choice=="string"?a.toolChoice=o.tool_choice:a.toolChoice=o.tool_choice.function.name),a.seed=o.seed,a.maxTokens=o.max_tokens,a.temperature=o.temperature,a.topP=o.top_p,a.presencePenalty=o.presence_penalty,a.frequencyPenalty=o.frequency_penalty,a.stop=o.stop,a.logProbs=o.logprobs,a.topLogProbs=o.top_logprobs;let d=types.Config().parse(provider.removeUndefinedEntries(a)),i=[],l={};o.messages.forEach(c=>{let g=c.role;switch(g){case"system":{let y=c.content;if(typeof y=="string")i.push({role:g,content:[{modality:types.TextModalityLiteral,value:y}]});else {let O=y.map(I=>({modality:types.TextModalityLiteral,value:I.text}));i.push({role:g,content:O});}}break;case"user":{let y=c.content;if(typeof y=="string")i.push({role:g,content:[{modality:types.TextModalityLiteral,value:y}]});else {let O=y.map(I=>I.type==="text"?{modality:types.TextModalityLiteral,value:I.text}:I.image_url.url.startsWith("data:")?{modality:types.ImageModalityLiteral,detail:I.image_url.detail||"auto",value:{type:types.Base64ImageContentTypeLiteral,base64:I.image_url.url,media_type:provider.getMimeTypeFromBase64(I.image_url.url)}}:{modality:types.ImageModalityLiteral,detail:I.image_url.detail||"auto",value:{type:types.UrlImageContentTypeLiteral,url:I.image_url.url}});i.push({role:g,content:O});}}break;case"assistant":{let y=[];if(!c.content&&!c.tool_calls)throw new provider.InvalidModelRequestError({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("one of'content' or 'tool_calls' must be provided")});if(c.content){let O=c.content;typeof O=="string"?y.push({modality:types.TextModalityLiteral,value:O}):O.forEach(I=>{y.push({modality:types.TextModalityLiteral,value:I.text});});}c.tool_calls&&c.tool_calls.forEach((I,Zt)=>{let Be={modality:types.ToolCallModalityLiteral,id:I.id,index:Zt,name:I.function.name,arguments:I.function.arguments};y.push(Be),l[Be.id]=Be;}),i.push({role:g,content:y});}break;case"tool":{let y=c;i.push({role:g,content:[{modality:types.ToolResponseModalityLiteral,id:y.tool_call_id,index:l[y.tool_call_id].index,name:l[y.tool_call_id].name,data:y.content}]});}break}});let h=[];return o.tools&&o.tools.forEach(c=>{h.push({type:"function",definition:{schema:{name:c.function.name,description:c.function.description||"",strict:c.function.strict,parameters:c.function.parameters}}});}),{modelName:s,config:d,messages:i,tools:h.length>0?h:void 0}}transformConfig(e,t,o){let s=e.toolChoice;delete e.toolChoice;let a=this.modelSchema.config.schema.safeParse(e);if(!a.success)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:a.error});let d=a.data;s!==void 0&&(d.toolChoice=s),Object.keys(d).forEach(l=>{if(!(l in this.modelSchema.config.def))throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`Invalid config key : '${l}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})});let i=Object.keys(d).reduce((l,h)=>{let c=this.modelSchema.config.def[h],g=c.param,y=d[h];return g==="max_tokens"&&c.type==="range"&&y===0?l[g]=c.max:l[g]=y,l},{});if(i.top_logprobs&&!i.logprobs)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'logprobs' must be 'true' when 'top_logprobs' is specified")});if("tool_choice"in i&&i.tool_choice!==void 0){let l=i.tool_choice;if(!o||o&&o.length===0)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'toolChoice' is specified")});if(o&&o.length>0){let h=this.modelSchema.config.def.toolChoice;if(!h.choices.includes(l))if(o.map(c=>c.definition.schema.name).includes(l))i.tool_choice={type:"function",function:{name:l}};else throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`toolChoice : '${l}' is not part of provided 'tools' names or 
                one of [${h.choices.join(", ")}]`)})}}if("response_format"in i&&i.response_format!==void 0){let l=i.response_format;if(l==="json_schema")if("response_schema"in i)i.response_format={type:"json_schema",json_schema:i.response_schema},delete i.response_schema;else throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'responseSchema' is required in config when 'responseFormat' is 'json_schema'")});else i.response_format={type:l};}return i}transformMessages(e){if(!e||e&&e.length===0)return {messages:[]};let t=e.map(s=>{let a=types.Message().safeParse(s);if(!a.success)throw new provider.InvalidMessagesError({info:"Invalid messages",cause:a.error});return a.data});return t.forEach(s=>{s.content.forEach(a=>{if(!this.modelSchema.modalities.includes(a.modality))throw new provider.InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support modality : '${a.modality}', 
              available modalities : [${this.modelSchema.modalities.join(", ")}]`)})});}),t.forEach(s=>{if(!Object.keys(this.modelSchema.roles).includes(s.role))throw new provider.InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support role : '${s.role}', 
            available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}),{messages:t.map(s=>{switch(s.role){case types.SystemRoleLiteral:{let a=[];return s.content.forEach(d=>{if(d.modality===types.TextModalityLiteral)a.push({type:"text",text:d.value});else throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${s.role}' cannot have content with modality : '${d.modality}'`)})}),{role:this.modelSchema.roles[s.role],content:a}}case types.AssistantRoleLiteral:{let a=[],d=[];return s.content.forEach(i=>{if(i.modality===types.TextModalityLiteral)a.push({type:"text",text:i.value});else if(i.modality===types.ToolCallModalityLiteral)d.push({id:i.id,type:"function",function:{name:i.name,arguments:i.arguments}});else throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${s.role}' cannot have content with modality : '${i.modality}'`)})}),M({role:this.modelSchema.roles[s.role],content:a},d.length>0?{tool_calls:d}:{})}case types.UserRoleLiteral:{let a=[],d=[];s.content.forEach(l=>{if(l.modality===types.TextModalityLiteral)a.push({type:"text",text:l.value});else if(l.modality===types.ImageModalityLiteral)d.push({type:"image_url",image_url:{url:l.value.type==="url"?l.value.url:l.value.base64,detail:l.detail}});else throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${s.role}' cannot have content with modality : '${l.modality}'`)})});let i=[...a,...d];return {role:this.modelSchema.roles[s.role],content:i}}case types.ToolRoleLiteral:{if(s.content.length!==1)throw new provider.InvalidMessagesError({info:`Invalid message for role : '${s.role}'`,cause:new Error(`role : '${s.role}' must have exactly one content item`)});if(s.content[0].modality!==types.ToolResponseModalityLiteral)throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${s.role}' must have content with modality : '${types.ToolResponseModalityLiteral}'`)});let a=s.content[0];return {role:this.modelSchema.roles[s.role],tool_call_id:a.id,content:a.data}}default:throw new provider.InvalidMessagesError({info:`Invalid message 'role' for model : ${this.modelName}`,cause:new Error(`role : '${s.role}' is not supported, 
              available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}})}}transformTools(e){if(!this.modelSchema.modalities.includes(types.ToolCallModalityLiteral))throw new provider.InvalidToolsError({info:`Invalid tool 'modality' for model : ${this.modelName}`,cause:new Error(`model : '${this.modelName}' does not support tool modality : '${types.ToolCallModalityLiteral}'`)});return !e||e&&e.length===0?{tools:[]}:{tools:e.map(s=>{let a=types.Tool().safeParse(s);if(!a.success)throw new provider.InvalidToolsError({info:"Invalid tools",cause:a.error});return a.data}).map(s=>({type:"function",function:s.definition.schema}))}}getCompleteChatUrl(e,t,o){return A(this,null,function*(){return new Promise(s=>{s(this.completeChatUrl);})})}getCompleteChatHeaders(e,t,o){return A(this,null,function*(){return new Promise(s=>{s(this.getDefaultHeaders());})})}getCompleteChatData(e,t,o){return A(this,null,function*(){let s=this.transformConfig(e,t,o),a=this.transformMessages(t);if(a.messages&&a.messages.length===0)throw new provider.InvalidMessagesError({info:"Messages are required",cause:new Error("Messages are required")});let d=o?this.transformTools(o):{};return new Promise(i=>{i(M(M(M(M({},this.getDefaultParams()),s),a),d));})})}transformCompleteChatResponse(e){let t=Tt.safeParse(e);if(t.success){if(t.data.choices.length===0)throw new provider.ModelResponseError({info:"Invalid response from model",cause:new Error(`No choices in response : ${JSON.stringify(t.data)}`)});let o=t.data,s=[{role:types.AssistantRoleLiteral,content:[]}],a=o.choices[0].message;a.content&&s[0].content.push(types.createTextContent(a.content)),a.refusal&&s[0].content.push(types.createTextContent(a.refusal)),a.tool_calls&&a.tool_calls.forEach((h,c)=>{s[0].content.push(types.createToolCallContent(c,h.id,h.function.name,h.function.arguments));});let d={promptTokens:o.usage.prompt_tokens,completionTokens:o.usage.completion_tokens,totalTokens:o.usage.total_tokens},i=[],l=o.choices[0].logprobs;return l&&(l.content&&i.push(...l.content.map(h=>({token:h.token,logProb:h.logprob,bytes:h.bytes,topLogProbs:h.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))}))),l.refusal&&i.push(...l.refusal.map(h=>({token:h.token,logProb:h.logprob,bytes:h.bytes,topLogProbs:h.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))})))),{messages:s,usage:d,logProbs:i}}throw new provider.ModelResponseError({info:"Invalid response from model",cause:t.error})}getStreamChatUrl(e,t,o){return A(this,null,function*(){return new Promise(s=>{s(this.streamChatUrl);})})}getStreamChatHeaders(e,t,o){return A(this,null,function*(){return new Promise(s=>{s(this.getDefaultHeaders());})})}getStreamChatData(e,t,o){return A(this,null,function*(){let s=this.transformConfig(e,t,o),a=this.transformMessages(t);if(a.messages&&a.messages.length===0)throw new provider.InvalidMessagesError({info:"Messages are required",cause:new Error("Messages are required")});let d=o?this.transformTools(o):{};return new Promise(i=>{i(M(M(M(M({stream:!0,stream_options:{include_usage:!0}},this.getDefaultParams()),s),a),d));})})}transformStreamChatResponseChunk(e,t){return ee(this,null,function*(){var s,a;let o=(t+e).split(`
`).filter(d=>d.trim()!=="");for(let d of o){if(d==="data: [DONE]")return;if(d.startsWith("data: {")&&d.endsWith("}")){let i;try{i=JSON.parse(d.substring(6));}catch(h){throw new provider.ModelResponseError({info:`Malformed JSON received in stream : ${i}`,cause:h})}let l=gt.safeParse(i);if(l.success){let h={partialMessages:[]},c=l.data;if(c.choices.length>0){let g=c.choices[0].delta;if(g!==void 0&&Object.keys(g).length!==0){if("content"in g&&g.content!==null)h.partialMessages.push(types.createPartialTextMessage(types.AssistantRoleLiteral,g.content));else if("refusal"in g&&g.refusal!==null)h.partialMessages.push(types.createPartialTextMessage(types.AssistantRoleLiteral,g.refusal));else if("tool_calls"in g&&g.tool_calls!==void 0){let y=g.tool_calls.at(0);h.partialMessages.push(types.createPartialToolCallMessage(types.AssistantRoleLiteral,y.index,y.id,(s=y.function)==null?void 0:s.name,(a=y.function)==null?void 0:a.arguments));}}}c.usage&&(h.usage={promptTokens:c.usage.prompt_tokens,completionTokens:c.usage.completion_tokens,totalTokens:c.usage.total_tokens}),yield {partialResponse:h,buffer:t};}else throw new provider.ModelResponseError({info:"Invalid response from model",cause:l.error})}}})}};var v=class extends f{constructor(e,t){super(e,t);}transformModelRequest(e){let t=yt.safeParse(e);if(!t.success)throw new provider.InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,s=G(M({},o),{max_tokens:o.max_completion_tokens});return delete s.max_completion_tokens,super.transformModelRequest(s)}transformTools(e){throw new provider.ModelError({info:`Model: '${this.modelSchema.name}' does not support 'tools'.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support 'tools'.`)})}getStreamChatUrl(e,t,o){return A(this,null,function*(){throw new provider.ModelError({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}getStreamChatHeaders(e,t,o){return A(this,null,function*(){throw new provider.ModelError({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}getStreamChatData(e,t,o){return A(this,null,function*(){throw new provider.ModelError({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}transformStreamChatResponseChunk(e,t){return ee(this,null,function*(){throw new provider.ModelError({info:`Model: '${this.modelSchema.name}' does not support streaming.`,cause:new Error(`Model: '${this.modelSchema.name}' does not support streaming.`)})})}};var Ze="gpt-3.5-turbo-0125",Jn="The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a   text encoding issue for non-English language function calls. Training data up to Sept 2021.",eo=provider.ChatModelSchema(_,x).parse({name:Ze,description:Jn,maxInputTokens:4092,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.responseFormat(4092,4).def,schema:m.responseFormat(4092,4).schema}}),Ot=u,he=class extends f{constructor(e){super(eo,e);}};var oo="gpt-3.5-turbo-1106",Yn="The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.",to=provider.ChatModelSchema(_,x).parse({name:oo,description:Yn,maxInputTokens:4092,maxOutputTokens:16385,roles:T,modalities:S,config:{def:m.responseFormat(16385,4).def,schema:m.responseFormat(16385,4).schema}}),Ct=u,ue=class extends f{constructor(e){super(to,e);}};var no="gpt-3.5-turbo",Qn="Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.",so=provider.ChatModelSchema(_,x).parse({name:no,description:Qn,maxInputTokens:4092,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.responseFormat(4092,4).def,schema:m.responseFormat(4092,4).schema}}),bt=u,fe=class extends f{constructor(e){super(so,e);}};var ao="gpt-4-0125-preview",es="The latest GPT-4 model intended to reduce cases of \u201Claziness\u201D where the model doesn\u2019t complete a task. Training data up to Apr 2023.",io=provider.ChatModelSchema(_,x).parse({name:ao,description:es,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.base(4092,4).def,schema:m.base(4092,4).schema}}),Pt=u,_e=class extends f{constructor(e){super(io,e);}};var ro="gpt-4-0613",ts="Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.",lo=provider.ChatModelSchema(_,x).parse({name:ro,description:ts,maxInputTokens:8192,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.base(4092,4).def,schema:m.base(4092,4).schema}}),It=u,Te=class extends f{constructor(e){super(lo,e);}};var po="gpt-4-1106-preview",ss="GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.",mo=provider.ChatModelSchema(_,x).parse({name:po,description:ss,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.base(4092,4).def,schema:m.base(4092,4).schema}}),St=u,ge=class extends f{constructor(e){super(mo,e);}};var co="gpt-4-turbo-2024-04-09",is="GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.   Training data up to Dec 2023.",ho=provider.ChatModelSchema(_,P).parse({name:co,description:is,maxInputTokens:128e3,maxOutputTokens:4096,roles:T,modalities:b,config:{def:m.responseFormat(4096,4).def,schema:m.responseFormat(4096,4).schema}}),xt=u,ye=class extends f{constructor(e){super(ho,e);}};var uo="gpt-4-turbo-preview",ls="Currently points to gpt-4-0125-preview. Training data up to Apr 2023.",fo=provider.ChatModelSchema(_,x).parse({name:uo,description:ls,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.responseFormat(4092,4).def,schema:m.responseFormat(4092,4).schema}}),At=u,Me=class extends f{constructor(e){super(fo,e);}};var _o="gpt-4-turbo",ms="The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.   Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.",To=provider.ChatModelSchema(_,P).parse({name:_o,description:ms,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:b,config:{def:m.responseFormat(4092,4).def,schema:m.responseFormat(4092,4).schema}}),Et=u,Oe=class extends f{constructor(e){super(To,e);}};var go="gpt-4",cs="Currently points to gpt-4-0613. Training data up to Sept 2021.",yo=provider.ChatModelSchema(_,x).parse({name:go,description:cs,maxInputTokens:8192,maxOutputTokens:4092,roles:T,modalities:S,config:{def:m.base(4092,4).def,schema:m.base(4092,4).schema}}),Rt=u,Ce=class extends f{constructor(e){super(yo,e);}};var Mo="gpt-4o-2024-05-13",us="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Oo=provider.ChatModelSchema(_,P).parse({name:Mo,description:us,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:b,config:{def:m.responseSchema(4092,4).def,schema:m.responseSchema(4092,4).schema}}),wt=u,be=class extends f{constructor(e){super(Oo,e);}};var Co="gpt-4o-2024-08-06",_s="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",bo=provider.ChatModelSchema(_,P).parse({name:Co,description:_s,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:b,config:{def:m.responseSchema(4092,4).def,schema:m.responseSchema(4092,4).schema}}),Gt=u,Pe=class extends f{constructor(e){super(bo,e);}};var Po="gpt-4o-mini-2024-07-18",gs="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Io=provider.ChatModelSchema(_,P).parse({name:Po,description:gs,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:b,config:{def:m.responseSchema(4092,4).def,schema:m.responseSchema(4092,4).schema}}),vt=u,Ie=class extends f{constructor(e){super(Io,e);}};var So="gpt-4o-mini",Ms="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",xo=provider.ChatModelSchema(_,P).parse({name:So,description:Ms,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:b,config:{def:m.responseSchema(4092,4).def,schema:m.responseSchema(4092,4).schema}}),qt=u,Se=class extends f{constructor(e){super(xo,e);}};var Ao="gpt-4o",Cs="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Eo=provider.ChatModelSchema(_,P).parse({name:Ao,description:Cs,maxInputTokens:128e3,maxOutputTokens:4092,roles:T,modalities:b,config:{def:m.responseFormat(4092,4).def,schema:m.responseFormat(4092,4).schema}}),kt=u,xe=class extends f{constructor(e){super(Eo,e);}};var Ro="o1-2024-12-17",Ps="A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.",wo=provider.ChatModelSchema(_,P).parse({name:Ro,description:Ps,maxInputTokens:2e5,maxOutputTokens:1e5,roles:T,modalities:b,config:{def:m.responseFormat(1e5,4).def,schema:m.responseFormat(1e5,4).schema}}),Lt=u,Ae=class extends f{constructor(e){super(wo,e);}};var Go="o1-mini-2024-09-12",Ss="Enhanced version of o1-mini optimized for faster reasoning in coding, math, and science. Training data up to September 2024.",vo=provider.ChatModelSchema($,K).parse({name:Go,description:Ss,maxInputTokens:128e3,maxOutputTokens:65536,roles:U,modalities:V,config:{def:m.oSeries(65536,4).def,schema:m.oSeries(65536,4).schema}}),zt=u,Ee=class extends v{constructor(e){super(vo,e);}};var qo="o1-mini",As="Faster and cheaper reasoning model particularly good at coding, math, and science. Training data up to Oct 2023.",ko=provider.ChatModelSchema($,K).parse({name:qo,description:As,maxInputTokens:128e3,maxOutputTokens:4092,roles:U,modalities:V,config:{def:m.oSeries(4092,4).def,schema:m.oSeries(4092,4).schema}}),Bt=u,Re=class extends v{constructor(e){super(ko,e);}};var Lo="o1-preview",Rs="Reasoning model designed to solve hard problems across domains. Training data up to Oct 2023.",zo=provider.ChatModelSchema($,K).parse({name:Lo,description:Rs,maxInputTokens:128e3,maxOutputTokens:4092,roles:U,modalities:V,config:{def:m.oSeries(4092,4).def,schema:m.oSeries(4092,4).schema}}),jt=u,we=class extends v{constructor(e){super(zo,e);}};var Bo="o1",Gs="Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.",jo=provider.ChatModelSchema(_,P).parse({name:Bo,description:Gs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:T,modalities:b,config:{def:m.oSeries(1e5,4).def,schema:m.oSeries(1e5,4).schema}}),Ft=u,Ge=class extends v{constructor(e){super(jo,e);}};var W=[types.EmbeddingTextModalityLiteral,types.EmbeddingTokenModalityLiteral],Y=zod.z.enum([types.EmbeddingTextModalityLiteral,types.EmbeddingTokenModalityLiteral]);var Wt=zod.z.object({object:zod.z.literal("list"),model:zod.z.string(),data:zod.z.array(zod.z.object({index:zod.z.number(),object:zod.z.literal("embedding"),embedding:zod.z.array(zod.z.number()).or(zod.z.string().base64())})),usage:zod.z.object({prompt_tokens:zod.z.number().nonnegative(),total_tokens:zod.z.number().nonnegative()})});var qs=zod.z.string().min(1).or(zod.z.array(zod.z.string().min(1)).min(1)).or(zod.z.array(zod.z.number().int().nonnegative()).min(1)).or(zod.z.array(zod.z.array(zod.z.number().int().nonnegative()).min(1)).min(1)),Yt=zod.z.object({model:zod.z.string().min(1).optional(),input:qs,encoding_format:zod.z.enum(["float","base64"]).optional(),dimensions:zod.z.number().int().min(1).optional()});var F=zod.z.object({modelName:zod.z.string(),apiKey:zod.z.string(),baseUrl:zod.z.string().url().optional(),getEmbeddingsUrl:zod.z.string().url().optional()}),L=class{constructor(e,t){this.version="v1";let o=F.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=provider.urlWithoutTrailingSlash(o.baseUrl||B.baseUrl),this.getEmbeddingsUrl=provider.urlWithoutTrailingSlash(o.getEmbeddingsUrl||`${this.baseUrl}/embeddings`);}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return {Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"}}getDefaultParams(){return {model:this.modelSchema.name}}getRetryDelay(e){let t=i=>{let l=/(\d+)(h|m|s|ms)/g,h={h:36e5,m:6e4,s:1e3,ms:1},c,g=0;for(;(c=l.exec(i))!==null;){let y=parseInt(c[1]),O=c[2];g+=y*h[O];}return g},o=0,s=0,a=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(s=t(e["x-ratelimit-reset-tokens"]));let d=Math.max(o,s);return {shouldRetry:a,delayMs:d}}getTokenCount(e){return e.requests.reduce((t,o)=>t+o.length,0)}transformModelRequest(e){let t=Yt.safeParse(e);if(!t.success)throw new provider.InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,s=o.model,a={encodingFormat:o.encoding_format,dimensions:o.dimensions},d=types.Config().parse(provider.removeUndefinedEntries(a)),i,l;return typeof o.input=="string"?l=types.EmbeddingTextModalityLiteral:typeof o.input[0]=="string"?l=types.EmbeddingTextModalityLiteral:l=types.EmbeddingTokenModalityLiteral,l===types.EmbeddingTextModalityLiteral?typeof o.input=="string"?i={modality:l,requests:[o.input]}:i={modality:l,requests:o.input}:typeof o.input[0]=="number"?i={modality:l,requests:[o.input]}:i={modality:l,requests:o.input},{modelName:s,config:d,embeddingRequests:i}}transformConfig(e,t){let o=this.modelSchema.config.schema.safeParse(e);if(!o.success)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:o.error});let s=o.data;return Object.keys(s).forEach(d=>{if(!this.modelSchema.config.def[d])throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:new Error(`Invalid config key : '${d}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})}),Object.keys(s).reduce((d,i)=>{let h=this.modelSchema.config.def[i].param,c=s[i];return d[h]=c,d},{})}transformEmbeddingRequests(e){let t=types.EmbeddingRequests().safeParse(e);if(!t.success)throw new provider.InvalidEmbeddingRequestsError({info:"Invalid embedding requests",cause:t.error});return {input:t.data.requests}}getGetEmbeddingsUrl(e,t){return A(this,null,function*(){return new Promise(o=>{o(this.getEmbeddingsUrl);})})}getGetEmbeddingsHeaders(e,t){return A(this,null,function*(){return new Promise(o=>{o(this.getDefaultHeaders());})})}getGetEmbeddingsData(e,t){return A(this,null,function*(){return new Promise(o=>{o(M(M(M({},this.getDefaultParams()),this.transformConfig(e,t)),this.transformEmbeddingRequests(t)));})})}transformGetEmbeddingsResponse(e){let t,o=Wt.safeParse(e);if(o.success){let s=o.data;t=typeof s.data[0].embedding=="string"?types.Base64EmbeddingLiteral:types.FloatEmbeddingLiteral;let a=s.data.map(d=>typeof d.embedding=="string"?{index:d.index,embedding:d.embedding}:{index:d.index,embedding:d.embedding});return {encodingFormat:t,embeddings:a,usage:{totalTokens:s.usage.total_tokens}}}throw new provider.ModelResponseError({info:"Invalid response from model",cause:o.error})}};var Fo="text-embedding-ada-002",Hs="Most capable 2nd generation embedding model, replacing 16 first generation models",Do=provider.EmbeddingModelSchema(Y).parse({name:Fo,description:Hs,modalities:W,maxInputTokens:8192,maxOutputTokens:1536,config:{def:q.base().def,schema:q.base().schema}}),Dt=F,ve=class extends L{constructor(e){super(Do,e);}};var No="text-embedding-3-small",Ks="Increased performance over 2nd generation ada embedding model",$o=provider.EmbeddingModelSchema(Y).parse({name:No,description:Ks,modalities:W,maxInputTokens:8192,maxOutputTokens:1536,config:{def:q.dimensions(1536).def,schema:q.dimensions(1536).schema}}),Nt=F,qe=class extends L{constructor(e){super($o,e);}};var Uo="text-embedding-3-large",Ws="Most capable embedding model for both english and non-english tasks",Ho=provider.EmbeddingModelSchema(Y).parse({name:Uo,description:Ws,modalities:W,maxInputTokens:8192,maxOutputTokens:3072,config:{def:q.dimensions(3072).def,schema:q.dimensions(3072).schema}}),$t=F,ke=class extends L{constructor(e){super(Ho,e);}};

exports.BaseChatModel = f;
exports.BaseChatModelOptions = u;
exports.BaseEmbeddingModel = L;
exports.BaseEmbeddingModelOptions = F;
exports.BaseOSeriesChatModel = v;
exports.ChatModelBaseConfigDef = N;
exports.ChatModelBaseConfigSchema = D;
exports.ChatModelOSeriesConfigDef = st;
exports.ChatModelOSeriesConfigSchema = at;
exports.ChatModelResponseFormatConfigDef = lt;
exports.ChatModelResponseFormatConfigSchema = pt;
exports.ChatModelResponseSchemaConfigDef = te;
exports.ChatModelResponseSchemaConfigSchema = ne;
exports.EmbeddingModelBaseConfigDef = ie;
exports.EmbeddingModelBaseConfigSchema = ae;
exports.EmbeddingModelDimensionsConfigDef = dt;
exports.EmbeddingModelDimensionsConfigSchema = mt;
exports.GPT_3_5_Turbo = fe;
exports.GPT_3_5_TurboLiteral = no;
exports.GPT_3_5_TurboOptions = bt;
exports.GPT_3_5_TurboSchema = so;
exports.GPT_3_5_Turbo_0125 = he;
exports.GPT_3_5_Turbo_0125Literal = Ze;
exports.GPT_3_5_Turbo_0125Options = Ot;
exports.GPT_3_5_Turbo_0125Schema = eo;
exports.GPT_3_5_Turbo_1106 = ue;
exports.GPT_3_5_Turbo_1106Literal = oo;
exports.GPT_3_5_Turbo_1106Options = Ct;
exports.GPT_3_5_Turbo_1106Schema = to;
exports.GPT_4 = Ce;
exports.GPT_4Literal = go;
exports.GPT_4Options = Rt;
exports.GPT_4Schema = yo;
exports.GPT_4_0125_Preview = _e;
exports.GPT_4_0125_PreviewLiteral = ao;
exports.GPT_4_0125_PreviewOptions = Pt;
exports.GPT_4_0125_PreviewSchema = io;
exports.GPT_4_0613 = Te;
exports.GPT_4_0613Literal = ro;
exports.GPT_4_0613Options = It;
exports.GPT_4_0613Schema = lo;
exports.GPT_4_1106_Preview = ge;
exports.GPT_4_1106_PreviewLiteral = po;
exports.GPT_4_1106_PreviewOptions = St;
exports.GPT_4_1106_PreviewSchema = mo;
exports.GPT_4_Turbo = Oe;
exports.GPT_4_TurboLiteral = _o;
exports.GPT_4_TurboOptions = Et;
exports.GPT_4_TurboSchema = To;
exports.GPT_4_Turbo_2024_04_09 = ye;
exports.GPT_4_Turbo_2024_04_09Literal = co;
exports.GPT_4_Turbo_2024_04_09Options = xt;
exports.GPT_4_Turbo_2024_04_09Schema = ho;
exports.GPT_4_Turbo_Preview = Me;
exports.GPT_4_Turbo_PreviewLiteral = uo;
exports.GPT_4_Turbo_PreviewOptions = At;
exports.GPT_4_Turbo_PreviewSchema = fo;
exports.GPT_4o = xe;
exports.GPT_4oLiteral = Ao;
exports.GPT_4oOptions = kt;
exports.GPT_4oSchema = Eo;
exports.GPT_4o_2024_05_13 = be;
exports.GPT_4o_2024_05_13Literal = Mo;
exports.GPT_4o_2024_05_13Options = wt;
exports.GPT_4o_2024_05_13Schema = Oo;
exports.GPT_4o_2024_08_06 = Pe;
exports.GPT_4o_2024_08_06Literal = Co;
exports.GPT_4o_2024_08_06Options = Gt;
exports.GPT_4o_2024_08_06Schema = bo;
exports.GPT_4o_Mini = Se;
exports.GPT_4o_MiniLiteral = So;
exports.GPT_4o_MiniOptions = qt;
exports.GPT_4o_MiniSchema = xo;
exports.GPT_4o_Mini_2024_07_18 = Ie;
exports.GPT_4o_Mini_2024_07_18Literal = Po;
exports.GPT_4o_Mini_2024_07_18Options = vt;
exports.GPT_4o_Mini_2024_07_18Schema = Io;
exports.O1 = Ge;
exports.O1Literal = Bo;
exports.O1Options = Ft;
exports.O1Schema = jo;
exports.O1_2024_12_17 = Ae;
exports.O1_2024_12_17Literal = Ro;
exports.O1_2024_12_17Options = Lt;
exports.O1_2024_12_17Schema = wo;
exports.O1_Mini = Re;
exports.O1_MiniLiteral = qo;
exports.O1_MiniOptions = Bt;
exports.O1_MiniSchema = ko;
exports.O1_Mini_2024_09_12 = Ee;
exports.O1_Mini_2024_09_12Literal = Go;
exports.O1_Mini_2024_09_12Options = zt;
exports.O1_Mini_2024_09_12Schema = vo;
exports.O1_Preview = we;
exports.O1_PreviewLiteral = Lo;
exports.O1_PreviewOptions = jt;
exports.O1_PreviewSchema = zo;
exports.OpenAI = B;
exports.OpenAIChatModelConfigs = m;
exports.OpenAIChatModelModalities = b;
exports.OpenAIChatModelModalitiesEnum = P;
exports.OpenAIChatModelOSSeriesRoles = $;
exports.OpenAIChatModelOSSeriesRolesMap = U;
exports.OpenAIChatModelRoles = _;
exports.OpenAIChatModelRolesMap = T;
exports.OpenAIChatModelTextModalities = V;
exports.OpenAIChatModelTextModalitiesEnum = K;
exports.OpenAIChatModelTextToolModalities = S;
exports.OpenAIChatModelTextToolModalitiesEnum = x;
exports.OpenAIChatOSeriesRequest = yt;
exports.OpenAIChatRequest = ce;
exports.OpenAIChatRequestAssistantMessage = En;
exports.OpenAIChatRequestImageContent = In;
exports.OpenAIChatRequestMessage = wn;
exports.OpenAIChatRequestResponseFormat = Pn;
exports.OpenAIChatRequestSystemMessage = xn;
exports.OpenAIChatRequestTextContent = Qe;
exports.OpenAIChatRequestTool = On;
exports.OpenAIChatRequestToolCallContent = Sn;
exports.OpenAIChatRequestToolChoiceEnum = Cn;
exports.OpenAIChatRequestToolChoiceFunction = bn;
exports.OpenAIChatRequestToolMessage = Rn;
exports.OpenAIChatRequestUserMessage = An;
exports.OpenAICompleteChatResponse = Tt;
exports.OpenAIEmbeddingModelConfigs = q;
exports.OpenAIEmbeddingModelModalities = W;
exports.OpenAIEmbeddingModelModalitiesEnum = Y;
exports.OpenAIEmbeddingRequest = Yt;
exports.OpenAIEmbeddingRequestInput = qs;
exports.OpenAIGetEmbeddingsResponse = Wt;
exports.OpenAIStreamChatResponse = gt;
exports.OpenAIToolCallsCompleteChatResponse = yn;
exports.OpenAIToolCallsStreamChatResponse = Mn;
exports.ProviderLiteral = vn;
exports.Text_Embedding_3_Large = ke;
exports.Text_Embedding_3_LargeLiteral = Uo;
exports.Text_Embedding_3_LargeSchema = Ho;
exports.Text_Embedding_3_Large_Options = $t;
exports.Text_Embedding_3_Small = qe;
exports.Text_Embedding_3_SmallLiteral = No;
exports.Text_Embedding_3_SmallSchema = $o;
exports.Text_Embedding_3_Small_Options = Nt;
exports.Text_Embedding_Ada002 = ve;
exports.Text_Embedding_Ada002Literal = Fo;
exports.Text_Embedding_Ada002Schema = Do;
exports.Text_Embedding_Ada002_Options = Dt;
exports.dimensions = Ye;
exports.encodingFormat = We;
exports.frequencyPenalty = $e;
exports.logProbs = Ve;
exports.maxTokens = Fe;
exports.presencePenalty = Ue;
exports.seed = He;
exports.stop = De;
exports.temperature = je;
exports.toolChoice = Je;
exports.topLogProbs = Ke;
exports.topP = Ne;
//# sourceMappingURL=index.js.map
//# sourceMappingURL=index.js.map